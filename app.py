import io
import re
import tempfile
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from scipy import stats
import statsmodels.formula.api as smf


# =========================
# App config
# =========================
st.set_page_config(
    page_title="H·ªó tr·ª£ nghi√™n c·ª©u cho b√°c sƒ© gia ƒë√¨nh",
    page_icon="üî¨",
    layout="wide",
)

APP_TITLE = "H·ªó tr·ª£ nghi√™n c·ª©u cho b√°c sƒ© gia ƒë√¨nh"


# =========================
# Helpers: safe name / hash
# =========================
def _safe_name(name: str) -> str:
    return re.sub(r"[^a-zA-Z0-9_]+", "_", str(name).strip())[:80] or "file"


def _file_sha256(raw: bytes) -> str:
    return hashlib.sha256(raw).hexdigest()


def _df_sha256(df: pd.DataFrame) -> str:
    """
    Hash n·ªôi dung DataFrame (·ªïn ƒë·ªãnh theo d·ªØ li·ªáu).
    D√πng ƒë·ªÉ ch·ªëng nh·∫≠p tr√πng sheet/object.
    """
    h = pd.util.hash_pandas_object(df, index=True).values.tobytes()
    return hashlib.sha256(h).hexdigest()


# =========================
# Helpers: file reading
# =========================
def read_csv_safely(uploaded_file) -> pd.DataFrame:
    raw = uploaded_file.getvalue()
    encodings = ["utf-8-sig", "utf-8", "cp1258", "cp1252", "latin1"]
    last_err = None
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(raw), encoding=enc)
        except Exception as e:
            last_err = e
    raise last_err


def read_file_safely(uploaded_file) -> Dict[str, pd.DataFrame]:
    """
    Return dict {table_name: df}
    - CSV: {"data": df}
    - XLSX/XLS: {sheet: df}
    - SPSS: {"data": df}
    - STATA: {"data": df}
    - RDS: {object: df}
    """
    name = uploaded_file.name
    ext = Path(name).suffix.lower()
    raw = uploaded_file.getvalue()

    if ext == ".csv":
        df = read_csv_safely(uploaded_file)
        return {"data": df}

    if ext == ".xlsx":
        xls = pd.ExcelFile(io.BytesIO(raw), engine="openpyxl")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh)  # engine from ExcelFile
        return out

    if ext == ".xls":
        # .xls c·∫ßn xlrd>=2.0.1
        xls = pd.ExcelFile(io.BytesIO(raw), engine="xlrd")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh, engine="xlrd")
        return out

    if ext in [".sav", ".zsav"]:
        df = pd.read_spss(io.BytesIO(raw))
        return {"data": df}

    if ext == ".dta":
        df = pd.read_stata(io.BytesIO(raw))
        return {"data": df}

    if ext == ".rds":
        try:
            import pyreadr  # type: ignore
        except Exception as e:
            raise RuntimeError("Thi·∫øu th∆∞ vi·ªán pyreadr ƒë·ªÉ ƒë·ªçc .rds. H√£y c√†i: pip install pyreadr") from e

        with tempfile.NamedTemporaryFile(suffix=".rds", delete=False) as tmp:
            tmp.write(raw)
            tmp_path = tmp.name

        res = pyreadr.read_r(tmp_path)
        out: Dict[str, pd.DataFrame] = {}
        for k, v in res.items():
            if isinstance(v, pd.DataFrame):
                out[str(k) if k else "data"] = v

        if not out:
            raise RuntimeError("File .rds kh√¥ng ch·ª©a DataFrame (ho·∫∑c object kh√¥ng h·ªó tr·ª£).")
        return out

    raise RuntimeError(f"ƒê·ªãnh d·∫°ng {ext} ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£.")


# =========================
# Helpers: type detection
# =========================
def is_categorical(s: pd.Series) -> bool:
    if pd.api.types.is_bool_dtype(s) or pd.api.types.is_object_dtype(s) or pd.api.types.is_categorical_dtype(s):
        return True
    if pd.api.types.is_numeric_dtype(s):
        nunique = s.dropna().nunique()
        if nunique <= 10:
            return True
    return False


def coerce_numeric(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")


def var_kind(s: pd.Series, forced: str = "T·ª± ƒë·ªông") -> str:
    if forced == "ƒê·ªãnh l∆∞·ª£ng (numeric)":
        return "num"
    if forced == "Ph√¢n lo·∫°i (categorical)":
        return "cat"
    return "cat" if is_categorical(s) else "num"


# =========================
# Summaries
# =========================
def summarize_variable(df: pd.DataFrame, col: str) -> Dict[str, str]:
    s = df[col]
    miss = int(s.isna().sum())
    n = int(len(s))
    nunique = int(s.dropna().nunique())

    if is_categorical(s):
        vc = s.astype("string").value_counts(dropna=True).head(3)
        top = ", ".join([f"{idx} ({val})" for idx, val in vc.items()]) if len(vc) else "-"
        return {
            "T√™n bi·∫øn": col,
            "ƒê·∫∑c t√≠nh bi·∫øn": f"Ph√¢n lo·∫°i | m·ª©c={nunique} | thi·∫øu={miss}/{n} | top: {top}",
        }

    x = coerce_numeric(s)
    x_non = x.dropna()
    if len(x_non) == 0:
        return {"T√™n bi·∫øn": col, "ƒê·∫∑c t√≠nh bi·∫øn": f"ƒê·ªãnh l∆∞·ª£ng | thi·∫øu={miss}/{n} | (kh√¥ng ƒë·ªçc ƒë∆∞·ª£c s·ªë)"}

    mean = float(x_non.mean())
    sd = float(x_non.std(ddof=1)) if len(x_non) >= 2 else float("nan")
    med = float(x_non.median())
    q1 = float(x_non.quantile(0.25))
    q3 = float(x_non.quantile(0.75))
    return {
        "T√™n bi·∫øn": col,
        "ƒê·∫∑c t√≠nh bi·∫øn": f"ƒê·ªãnh l∆∞·ª£ng | thi·∫øu={miss}/{n} | mean={mean:.2f}, SD={sd:.2f} | median={med:.2f} (IQR {q1:.2f}-{q3:.2f})",
    }


def overall_summary(df: pd.DataFrame) -> Dict[str, int]:
    n_rows = int(df.shape[0])
    n_cols = int(df.shape[1])
    missing_cells = int(df.isna().sum().sum())
    numeric_cols = sum([pd.api.types.is_numeric_dtype(df[c]) and (not is_categorical(df[c])) for c in df.columns])
    cat_cols = n_cols - numeric_cols
    return {
        "S·ªë d√≤ng": n_rows,
        "S·ªë bi·∫øn": n_cols,
        "Bi·∫øn ƒë·ªãnh l∆∞·ª£ng": int(numeric_cols),
        "Bi·∫øn ph√¢n lo·∫°i": int(cat_cols),
        "√î thi·∫øu (NA)": missing_cells,
    }


# =========================
# Single-X test: suggest + run
# =========================
def suggest_single_x_test(
    df: pd.DataFrame,
    y: str,
    x: str,
    y_forced: str = "T·ª± ƒë·ªông",
    x_forced: str = "T·ª± ƒë·ªông",
) -> Tuple[str, str, str]:
    yk = var_kind(df[y], y_forced)
    xk = var_kind(df[x], x_forced)

    tmp = df[[y, x]].dropna()
    if tmp.shape[0] < 3:
        return ("Kh√¥ng ƒë·ªß d·ªØ li·ªáu", "Sau khi lo·∫°i NA, s·ªë d√≤ng qu√° √≠t ƒë·ªÉ ki·ªÉm ƒë·ªãnh.", "none")

    if yk == "cat" and xk == "cat":
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape == (2, 2) and (tab.values < 5).any():
            return ("Fisher exact (2x2)", "B·∫£ng 2x2 v√† c√≥ √¥ nh·ªè ‚Üí ∆∞u ti√™n Fisher exact.", "fisher_2x2")
        return ("Chi-b√¨nh ph∆∞∆°ng (Chi-square)", "X v√† Y ƒë·ªÅu ph√¢n lo·∫°i ‚Üí ki·ªÉm ƒë·ªãnh ƒë·ªôc l·∫≠p b·∫±ng Chi-square.", "chisq")

    if yk == "num" and xk == "cat":
        n_levels = tmp[x].astype(str).nunique()
        if n_levels == 2:
            return ("t-test ƒë·ªôc l·∫≠p (Welch)", "X c√≥ 2 nh√≥m, Y ƒë·ªãnh l∆∞·ª£ng ‚Üí so s√°nh trung b√¨nh Y gi·ªØa 2 nh√≥m.", "ttest_xgroup_ynum")
        return ("ANOVA m·ªôt y·∫øu t·ªë", f"X c√≥ {n_levels} nh√≥m, Y ƒë·ªãnh l∆∞·ª£ng ‚Üí so s√°nh trung b√¨nh Y gi·ªØa nhi·ªÅu nh√≥m.", "anova_xgroup_ynum")

    if yk == "cat" and xk == "num":
        n_levels = tmp[y].astype(str).nunique()
        if n_levels == 2:
            return ("t-test ƒë·ªôc l·∫≠p (Welch)", "Y c√≥ 2 nh√≥m, X ƒë·ªãnh l∆∞·ª£ng ‚Üí so s√°nh trung b√¨nh X gi·ªØa 2 nh√≥m.", "ttest_ygroup_xnum")
        return ("ANOVA m·ªôt y·∫øu t·ªë", f"Y c√≥ {n_levels} nh√≥m, X ƒë·ªãnh l∆∞·ª£ng ‚Üí so s√°nh trung b√¨nh X gi·ªØa nhi·ªÅu nh√≥m.", "anova_ygroup_xnum")

    if yk == "num" and xk == "num":
        return ("T∆∞∆°ng quan Pearson", "X v√† Y ƒë·ªÅu ƒë·ªãnh l∆∞·ª£ng ‚Üí ƒë√°nh gi√° li√™n quan tuy·∫øn t√≠nh (Pearson).", "corr_pearson")

    return ("Kh√¥ng x√°c ƒë·ªãnh", "Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ph√©p ki·ªÉm ph√π h·ª£p t·ª´ ki·ªÉu bi·∫øn hi·ªán t·∫°i.", "none")


def _cohens_d(a: np.ndarray, b: np.ndarray) -> float:
    a = a[~np.isnan(a)]
    b = b[~np.isnan(b)]
    if len(a) < 2 or len(b) < 2:
        return float("nan")
    va = np.var(a, ddof=1)
    vb = np.var(b, ddof=1)
    sp = np.sqrt(((len(a) - 1) * va + (len(b) - 1) * vb) / (len(a) + len(b) - 2))
    if sp == 0:
        return float("nan")
    return (np.mean(a) - np.mean(b)) / sp


def _cramers_v(tab: pd.DataFrame) -> float:
    chi2, p, dof, exp = stats.chi2_contingency(tab.values)
    n = tab.values.sum()
    if n == 0:
        return float("nan")
    r, k = tab.shape
    return np.sqrt(chi2 / (n * (min(r, k) - 1))) if min(r, k) > 1 else float("nan")


def run_single_x_test(df: pd.DataFrame, y: str, x: str, test_kind: str) -> Tuple[pd.DataFrame, str]:
    tmp = df[[y, x]].dropna().copy()

    if test_kind in ("ttest_xgroup_ynum", "anova_xgroup_ynum"):
        tmp[y] = coerce_numeric(tmp[y])
        tmp = tmp.dropna()
        groups = tmp[x].astype(str)

        if test_kind == "ttest_xgroup_ynum":
            levels = sorted(groups.unique().tolist())
            if len(levels) != 2:
                raise ValueError("t-test c·∫ßn ƒë√∫ng 2 nh√≥m.")
            a = tmp.loc[groups == levels[0], y].to_numpy()
            b = tmp.loc[groups == levels[1], y].to_numpy()
            tstat, p = stats.ttest_ind(a, b, equal_var=False, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame(
                {
                    "Ch·ªâ s·ªë": ["n nh√≥m 1", "n nh√≥m 2", "Mean nh√≥m 1", "Mean nh√≥m 2", "t (Welch)", "p-value", "Cohen's d"],
                    "Gi√° tr·ªã": [len(a), len(b), np.nanmean(a), np.nanmean(b), tstat, p, d],
                }
            )
            interp = (
                "Di·ªÖn gi·∫£i: p-value nh·ªè (v√≠ d·ª• <0.05) g·ª£i √Ω trung b√¨nh Y kh√°c nhau gi·ªØa 2 nh√≥m X. "
                "Cohen‚Äôs d ƒë√°nh gi√° ƒë·ªô l·ªõn kh√°c bi·ªát (‚âà0.2 nh·ªè, 0.5 v·ª´a, 0.8 l·ªõn)."
            )
            return out, interp

        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, y].to_numpy() for lv in levels]
        fstat, p = stats.f_oneway(*arrays)
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["S·ªë nh√≥m", "F", "p-value"], "Gi√° tr·ªã": [len(levels), fstat, p]})
        interp = (
            "Di·ªÖn gi·∫£i: p-value nh·ªè g·ª£i √Ω c√≥ √≠t nh·∫•t 1 nh√≥m kh√°c trung b√¨nh. "
            "N·∫øu c√≥ √Ω nghƒ©a, n√™n l√†m post-hoc ƒë·ªÉ bi·∫øt nh√≥m n√†o kh√°c nh√≥m n√†o."
        )
        return out, interp

    if test_kind in ("ttest_ygroup_xnum", "anova_ygroup_xnum"):
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        groups = tmp[y].astype(str)

        if test_kind == "ttest_ygroup_xnum":
            levels = sorted(groups.unique().tolist())
            if len(levels) != 2:
                raise ValueError("t-test c·∫ßn ƒë√∫ng 2 nh√≥m.")
            a = tmp.loc[groups == levels[0], x].to_numpy()
            b = tmp.loc[groups == levels[1], x].to_numpy()
            tstat, p = stats.ttest_ind(a, b, equal_var=False, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame(
                {
                    "Ch·ªâ s·ªë": ["n nh√≥m 1", "n nh√≥m 2", "Mean nh√≥m 1", "Mean nh√≥m 2", "t (Welch)", "p-value", "Cohen's d"],
                    "Gi√° tr·ªã": [len(a), len(b), np.nanmean(a), np.nanmean(b), tstat, p, d],
                }
            )
            interp = (
                "Di·ªÖn gi·∫£i: p-value nh·ªè g·ª£i √Ω trung b√¨nh X kh√°c nhau gi·ªØa 2 nh√≥m Y. "
                "Cohen‚Äôs d ƒë√°nh gi√° ƒë·ªô l·ªõn kh√°c bi·ªát."
            )
            return out, interp

        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, x].to_numpy() for lv in levels]
        fstat, p = stats.f_oneway(*arrays)
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["S·ªë nh√≥m", "F", "p-value"], "Gi√° tr·ªã": [len(levels), fstat, p]})
        interp = (
            "Di·ªÖn gi·∫£i: p-value nh·ªè g·ª£i √Ω c√≥ √≠t nh·∫•t 1 nh√≥m kh√°c trung b√¨nh. "
            "N·∫øu c√≥ √Ω nghƒ©a, n√™n l√†m post-hoc."
        )
        return out, interp

    if test_kind == "chisq":
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        chi2, p, dof, exp = stats.chi2_contingency(tab.values)
        v = _cramers_v(tab)
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["Chi2", "df", "p-value", "Cramer's V"], "Gi√° tr·ªã": [chi2, dof, p, v]})
        interp = (
            "Di·ªÖn gi·∫£i: p-value nh·ªè g·ª£i √Ω X v√† Y c√≥ li√™n quan. "
            "Cramer's V cho bi·∫øt ƒë·ªô m·∫°nh li√™n quan (‚âà0.1 nh·ªè, 0.3 v·ª´a, 0.5 l·ªõn ‚Äì tu·ª≥ b·ªëi c·∫£nh)."
        )
        return out, interp

    if test_kind == "fisher_2x2":
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape != (2, 2):
            raise ValueError("Fisher exact ch·ªâ √°p d·ª•ng b·∫£ng 2x2.")
        oddsratio, p = stats.fisher_exact(tab.values)
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["Odds ratio", "p-value"], "Gi√° tr·ªã": [oddsratio, p]})
        interp = (
            "Di·ªÖn gi·∫£i: p-value nh·ªè g·ª£i √Ω c√≥ li√™n quan gi·ªØa 2 bi·∫øn ph√¢n lo·∫°i. "
            "Odds ratio >1 cho th·∫•y odds cao h∆°n ·ªü m·ªôt nh√≥m (xem nh√≥m tham chi·∫øu t·ª´ b·∫£ng 2x2)."
        )
        return out, interp

    if test_kind == "corr_pearson":
        tmp[y] = coerce_numeric(tmp[y])
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        r, p = stats.pearsonr(tmp[x].to_numpy(), tmp[y].to_numpy())
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["Pearson r", "p-value", "n"], "Gi√° tr·ªã": [r, p, tmp.shape[0]]})
        interp = (
            "Di·ªÖn gi·∫£i: r cho bi·∫øt li√™n quan tuy·∫øn t√≠nh (g·∫ßn 0: y·∫øu; g·∫ßn ¬±1: m·∫°nh). "
            "p-value nh·ªè g·ª£i √Ω li√™n quan tuy·∫øn t√≠nh c√≥ √Ω nghƒ©a th·ªëng k√™."
        )
        return out, interp

    raise ValueError("Kh√¥ng c√≥ ki·ªÉm ƒë·ªãnh ph√π h·ª£p (test_kind=none).")


# =========================
# Model: suggest + build + run
# =========================
def suggest_model(df: pd.DataFrame, y: str, xs: List[str]) -> Tuple[str, str]:
    y_s = df[y]
    if is_categorical(y_s):
        n_levels = int(y_s.dropna().nunique())
        if n_levels <= 1:
            return ("Kh√¥ng ƒë·ªß d·ªØ li·ªáu", "Bi·∫øn ph·ª• thu·ªôc ch·ªâ c√≥ 0‚Äì1 m·ª©c sau khi lo·∫°i thi·∫øu. H√£y ki·ªÉm tra d·ªØ li·ªáu.")
        if n_levels == 2:
            return (
                "H·ªìi quy Logistic nh·ªã ph√¢n (Binary Logistic)",
                "Y ph√¢n lo·∫°i 2 m·ª©c ‚Üí ph√π h·ª£p logistic nh·ªã ph√¢n ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng OR v√† p-value khi c√≥ nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p.",
            )
        return (
            "H·ªìi quy Logistic ƒëa danh (Multinomial Logistic)",
            f"Y ph√¢n lo·∫°i >2 m·ª©c (m·ª©c={n_levels}) ‚Üí ph√π h·ª£p logistic ƒëa danh.",
        )
    return ("H·ªìi quy tuy·∫øn t√≠nh (OLS)", "Y ƒë·ªãnh l∆∞·ª£ng ‚Üí ph√π h·ª£p h·ªìi quy tuy·∫øn t√≠nh (OLS).")


def build_formula(
    df: pd.DataFrame,
    y: str,
    xs: List[str],
    y_binary_event: str | None = None,
) -> Tuple[str, pd.DataFrame, str]:
    tmp = df[[y] + xs].copy().dropna()

    if is_categorical(tmp[y]):
        n_levels = int(tmp[y].nunique())

        if n_levels == 2:
            y_cat = tmp[y].astype("category")
            cats = list(y_cat.cat.categories)
            event = y_binary_event if (y_binary_event in cats) else cats[1]
            tmp["_y01_"] = (tmp[y] == event).astype(int)

            terms = []
            for x in xs:
                terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

            formula = "_y01_ ~ " + " + ".join(terms)
            return formula, tmp, f"logit||Logistic nh·ªã ph√¢n: s·ª± ki·ªán (Y=1)='{event}'"

        tmp["_ycat_"] = tmp[y].astype("category")
        tmp["_ycode_"] = tmp["_ycat_"].cat.codes

        terms = []
        for x in xs:
            terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

        formula = "_ycode_ ~ " + " + ".join(terms)
        return formula, tmp, "mnlogit||Multinomial: h·ªá s·ªë theo nh√≥m tham chi·∫øu (m√£ ho√° category)"

    tmp[y] = coerce_numeric(tmp[y])
    tmp = tmp.dropna()

    terms = []
    for x in xs:
        terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

    formula = f"Q('{y}') ~ " + " + ".join(terms)
    return formula, tmp, "ols||OLS"


def run_model(formula: str, data_used: pd.DataFrame, model_kind: str):
    kind, note = model_kind.split("||", 1)
    if kind == "ols":
        return smf.ols(formula=formula, data=data_used).fit(), note
    if kind == "logit":
        return smf.logit(formula=formula, data=data_used).fit(disp=0), note
    if kind == "mnlogit":
        return smf.mnlogit(formula=formula, data=data_used).fit(disp=0), note
    raise ValueError("Unknown model kind")


def ols_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame({"H·ªá s·ªë": fit.params, "CI 2.5%": conf[0], "CI 97.5%": conf[1], "p-value": fit.pvalues})
    out.index.name = "Bi·∫øn"
    return out.sort_values("p-value")


def logit_or_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame(
        {
            "OR": np.exp(fit.params),
            "CI 2.5%": np.exp(conf[0]),
            "CI 97.5%": np.exp(conf[1]),
            "p-value": fit.pvalues,
        }
    )
    out.index.name = "Bi·∫øn"
    return out.sort_values("p-value")


# =========================
# Session state (ch·ªëng duplicate)
# =========================
if "datasets" not in st.session_state:
    st.session_state["datasets"] = {}  # key -> df

if "active_name" not in st.session_state:
    st.session_state["active_name"] = None

# pending (Excel/RDS nhi·ªÅu b·∫£ng)
if "pending_tables" not in st.session_state:
    st.session_state["pending_tables"] = None
if "pending_fname" not in st.session_state:
    st.session_state["pending_fname"] = None
if "pending_file_hash" not in st.session_state:
    st.session_state["pending_file_hash"] = None

# ch·ªëng duplicate:
# hash_to_key: hash -> dataset key
# key_to_hashes: dataset key -> set(hash)
if "hash_to_key" not in st.session_state:
    st.session_state["hash_to_key"] = {}
if "key_to_hashes" not in st.session_state:
    st.session_state["key_to_hashes"] = {}
if "last_upload_hash" not in st.session_state:
    st.session_state["last_upload_hash"] = None


def _register_dataset(key: str, df: pd.DataFrame, hashes: List[str]):
    st.session_state["datasets"][key] = df
    st.session_state["active_name"] = key

    st.session_state["key_to_hashes"].setdefault(key, set())
    for h in hashes:
        st.session_state["hash_to_key"][h] = key
        st.session_state["key_to_hashes"][key].add(h)


def _delete_dataset(key: str):
    st.session_state["datasets"].pop(key, None)
    hashes = st.session_state["key_to_hashes"].pop(key, set())
    for h in list(hashes):
        if st.session_state["hash_to_key"].get(h) == key:
            st.session_state["hash_to_key"].pop(h, None)


# =========================
# UI: Header
# =========================
st.markdown(
    f"""
    <div style="padding: 0.25rem 0 0.5rem 0;">
      <h1 style="margin:0;">{APP_TITLE}</h1>
      <div style="color:#6b7280;">Upload d·ªØ li·ªáu ‚Üí ch·ªçn bi·∫øn ‚Üí (1 X: ki·ªÉm ƒë·ªãnh) | (nhi·ªÅu X: m√¥ h√¨nh h·ªìi quy)</div>
    </div>
    """,
    unsafe_allow_html=True,
)
st.divider()


# =========================
# Top row: Overview | Upload | File list
# =========================
col_left, col_mid, col_right = st.columns([2.2, 1.6, 2.2], gap="large")

with col_mid:
    st.subheader("‚¨ÜÔ∏è Upload file")
    up = st.file_uploader(
        "T·∫£i l√™n d·ªØ li·ªáu",
        type=["csv", "xlsx", "xls", "sav", "zsav", "dta", "rds"],
        accept_multiple_files=False,
    )

    # --- Handle upload (ch·ªëng duplicate) ---
    if up is not None:
        try:
            raw = up.getvalue()
            file_hash = _file_sha256(raw)

            # N·∫øu rerun m√† v·∫´n ƒë√∫ng file ƒë√≥ ‚Üí b·ªè qua ƒë·ªÉ tr√°nh add l·∫°i
            if st.session_state["last_upload_hash"] != file_hash:
                st.session_state["last_upload_hash"] = file_hash

                # N·∫øu file gi·ªëng h·ªát ƒë√£ upload tr∆∞·ªõc ƒë√≥ ‚Üí ch·ªâ chuy·ªÉn active
                if file_hash in st.session_state["hash_to_key"]:
                    existed_key = st.session_state["hash_to_key"][file_hash]
                    st.session_state["active_name"] = existed_key
                    st.info(f"File n√†y ƒë√£ ƒë∆∞·ª£c upload tr∆∞·ªõc ƒë√≥ ‚Üí chuy·ªÉn sang: {existed_key}")
                else:
                    tables = read_file_safely(up)

                    # Nhi·ªÅu b·∫£ng (Excel/RDS) -> pending ƒë·ªÉ ch·ªçn
                    if len(tables) > 1:
                        st.session_state["pending_tables"] = tables
                        st.session_state["pending_fname"] = up.name
                        st.session_state["pending_file_hash"] = file_hash
                        st.info(f"File c√≥ {len(tables)} b·∫£ng (sheet/object). Ch·ªçn 1 b·∫£ng ƒë·ªÉ nh·∫≠p.")
                    else:
                        df_new = list(tables.values())[0]

                        base = _safe_name(Path(up.name).stem)
                        key = base
                        i = 2
                        while key in st.session_state["datasets"]:
                            key = f"{base}_{i}"
                            i += 1

                        # register: l∆∞u hash file + hash df
                        df_hash = _df_sha256(df_new)
                        _register_dataset(key, df_new, hashes=[file_hash, df_hash])

                        st.success(f"ƒê√£ t·∫£i: {key} (rows={df_new.shape[0]}, cols={df_new.shape[1]})")

        except Exception as e:
            st.error(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {e}")

    # --- Pending: ch·ªçn sheet/object ƒë·ªÉ nh·∫≠p ---
    if st.session_state["pending_tables"] is not None:
        tables = st.session_state["pending_tables"]
        fname = st.session_state["pending_fname"] or "file"
        pending_file_hash = st.session_state["pending_file_hash"]

        chosen_table = st.selectbox("Ch·ªçn sheet/object", options=list(tables.keys()))
        c1, c2 = st.columns([1, 1])

        with c1:
            if st.button("‚úÖ Nh·∫≠p b·∫£ng ƒë√£ ch·ªçn", use_container_width=True):
                df_new = tables[chosen_table]
                table_hash = _df_sha256(df_new)

                # N·∫øu b·∫£ng ƒë√£ nh·∫≠p tr∆∞·ªõc ƒë√≥ ‚Üí ch·ªâ chuy·ªÉn active
                if table_hash in st.session_state["hash_to_key"]:
                    existed_key = st.session_state["hash_to_key"][table_hash]
                    st.session_state["active_name"] = existed_key
                    st.info(f"B·∫£ng n√†y ƒë√£ ƒë∆∞·ª£c nh·∫≠p tr∆∞·ªõc ƒë√≥ ‚Üí chuy·ªÉn sang: {existed_key}")
                else:
                    base = _safe_name(Path(fname).stem)
                    sh = _safe_name(chosen_table)
                    key_base = f"{base}__{sh}"
                    key = key_base
                    i = 2
                    while key in st.session_state["datasets"]:
                        key = f"{key_base}_{i}"
                        i += 1

                    hashes = [table_hash]
                    if pending_file_hash:
                        hashes.append(pending_file_hash)

                    _register_dataset(key, df_new, hashes=hashes)
                    st.success(f"ƒê√£ nh·∫≠p: {key} (rows={df_new.shape[0]}, cols={df_new.shape[1]})")

                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

        with c2:
            if st.button("‚ùå Hu·ª∑", use_container_width=True):
                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

with col_right:
    st.subheader("üìÅ Danh s√°ch file ƒë√£ upload")
    names = list(st.session_state["datasets"].keys())
    if len(names) == 0:
        st.info("Ch∆∞a c√≥ file n√†o. H√£y upload ·ªü c·ªôt gi·ªØa.")
    else:
        active = st.session_state["active_name"] or names[0]
        chosen = st.radio(
            "Click ƒë·ªÉ ch·ªçn file",
            options=names,
            index=names.index(active) if active in names else 0,
            label_visibility="collapsed",
        )
        st.session_state["active_name"] = chosen

        c1, c2 = st.columns([1, 1])
        with c1:
            if st.button("üóëÔ∏è X√≥a file ƒëang ch·ªçn", use_container_width=True):
                _delete_dataset(chosen)
                remaining = list(st.session_state["datasets"].keys())
                st.session_state["active_name"] = remaining[0] if remaining else None
                st.rerun()
        with c2:
            if st.button("üßπ X√≥a t·∫•t c·∫£", use_container_width=True):
                st.session_state["datasets"] = {}
                st.session_state["active_name"] = None
                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.session_state["hash_to_key"] = {}
                st.session_state["key_to_hashes"] = {}
                st.session_state["last_upload_hash"] = None
                st.rerun()

with col_left:
    st.subheader("üìå T·ªïng quan d·ªØ li·ªáu")
    if st.session_state["active_name"] is None:
        st.info("Upload v√† ch·ªçn 1 file ƒë·ªÉ xem t·ªïng quan.")
    else:
        df = st.session_state["datasets"][st.session_state["active_name"]]
        summ = overall_summary(df)
        st.write(
            f"- **S·ªë d√≤ng:** {summ['S·ªë d√≤ng']}\n"
            f"- **S·ªë bi·∫øn:** {summ['S·ªë bi·∫øn']}\n"
            f"- **Bi·∫øn ƒë·ªãnh l∆∞·ª£ng:** {summ['Bi·∫øn ƒë·ªãnh l∆∞·ª£ng']}\n"
            f"- **Bi·∫øn ph√¢n lo·∫°i:** {summ['Bi·∫øn ph√¢n lo·∫°i']}\n"
            f"- **√î thi·∫øu (NA):** {summ['√î thi·∫øu (NA)']}"
        )

st.divider()


# =========================
# Main area
# =========================
if st.session_state["active_name"] is None:
    st.stop()

df = st.session_state["datasets"][st.session_state["active_name"]]
cols = df.columns.tolist()

main_left, main_right = st.columns([2.4, 1.6], gap="large")

with main_left:
    st.subheader("üßæ Li·ªát k√™ bi·∫øn & ƒë·∫∑c t√≠nh")
    var_rows = [summarize_variable(df, c) for c in cols]
    var_df = pd.DataFrame(var_rows)

    q = st.text_input("T√¨m nhanh t√™n bi·∫øn", value="")
    if q.strip():
        mask = var_df["T√™n bi·∫øn"].str.contains(q.strip(), case=False, na=False)
        var_df = var_df.loc[mask].copy()

    st.dataframe(var_df, use_container_width=True, height=420)

with main_right:
    st.subheader("üéØ Ch·ªçn bi·∫øn ph√¢n t√≠ch")
    y = st.selectbox("Ch·ªçn bi·∫øn ph·ª• thu·ªôc (Y)", options=cols, index=0)
    x = st.multiselect("Ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p (c√≥ th·ªÉ ch·ªçn nhi·ªÅu bi·∫øn)", options=[c for c in cols if c != y])

    st.markdown("**√âp ki·ªÉu n·∫øu c·∫ßn** (ƒë·ªÉ tr√°nh nh·∫≠n sai 0/1 th√†nh s·ªë ƒëo):")
    force_opts = ["T·ª± ƒë·ªông", "ƒê·ªãnh l∆∞·ª£ng (numeric)", "Ph√¢n lo·∫°i (categorical)"]
    y_force = st.selectbox("Ki·ªÉu Y", options=force_opts, index=0)

    x_force = "T·ª± ƒë·ªông"
    if len(x) == 1:
        x_force = st.selectbox("Ki·ªÉu X (ch·ªâ √°p d·ª•ng khi ch·ªçn 1 bi·∫øn X)", options=force_opts, index=0)

    # Logistic event selection n·∫øu Y nh·ªã ph√¢n
    y_is_cat = var_kind(df[y], y_force) == "cat"
    y_event = None
    if y_is_cat:
        levels = sorted(df[y].dropna().astype(str).unique().tolist())
        if len(levels) == 2:
            y_event = st.selectbox("Ch·ªçn m·ª©c coi l√† 'S·ª± ki·ªán' (Y=1) cho logistic", options=levels, index=1)

    if len(x) == 0:
        st.info("Ch·ªçn √≠t nh·∫•t 1 bi·∫øn ƒë·ªôc l·∫≠p ƒë·ªÉ ph·∫ßn m·ªÅm g·ª£i √Ω v√† ch·∫°y k·∫øt qu·∫£.")
        st.stop()

    # Decide mode
    if len(x) == 1:
        suggestion, explanation, test_kind = suggest_single_x_test(df, y, x[0], y_forced=y_force, x_forced=x_force)
        analysis_mode = "test"
    else:
        tmp_for_suggest = df.copy()
        if y_force == "ƒê·ªãnh l∆∞·ª£ng (numeric)":
            tmp_for_suggest[y] = coerce_numeric(tmp_for_suggest[y])
        elif y_force == "Ph√¢n lo·∫°i (categorical)":
            tmp_for_suggest[y] = tmp_for_suggest[y].astype("string")

        suggestion, explanation = suggest_model(tmp_for_suggest, y, x)
        test_kind = "none"
        analysis_mode = "model"

    st.divider()
    st.subheader("‚úÖ Ph√©p ki·ªÉm / m√¥ h√¨nh g·ª£i √Ω")
    st.write("**Ch·∫ø ƒë·ªô:** " + ("Ki·ªÉm ƒë·ªãnh (1 bi·∫øn ƒë·ªôc l·∫≠p)" if analysis_mode == "test" else "M√¥ h√¨nh h·ªìi quy (nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p)"))
    st.write(f"**G·ª£i √Ω:** {suggestion}")

    with st.expander("Gi·∫£i th√≠ch t·∫°i sao ch·ªçn ph∆∞∆°ng ph√°p n√†y"):
        st.write(explanation)
        st.write(
            "- N·∫øu ch·ªâ ch·ªçn **1 bi·∫øn ƒë·ªôc l·∫≠p**, app ∆∞u ti√™n **ph√©p ki·ªÉm ƒë·ªãnh** ph√π h·ª£p v·ªõi ki·ªÉu bi·∫øn.\n"
            "- N·∫øu ch·ªçn **nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p**, app ∆∞u ti√™n **m√¥ h√¨nh h·ªìi quy** ƒë·ªÉ **hi·ªáu ch·ªânh (adjust)** ƒë·ªìng th·ªùi.\n"
            "- D·ªØ li·ªáu d√πng ƒë·ªÉ ch·∫°y s·∫Ω **lo·∫°i d√≤ng thi·∫øu (NA)** theo c√°c bi·∫øn ƒë√£ ch·ªçn."
        )

    model_formula = None
    model_data_used = None
    model_kind = None

    if analysis_mode == "model":
        df_model = df.copy()
        if y_force == "ƒê·ªãnh l∆∞·ª£ng (numeric)":
            df_model[y] = coerce_numeric(df_model[y])
        elif y_force == "Ph√¢n lo·∫°i (categorical)":
            df_model[y] = df_model[y].astype("string")

        model_formula, model_data_used, model_kind = build_formula(df_model, y, x, y_binary_event=y_event)

        with st.expander("Xem c√¥ng th·ª©c m√¥ h√¨nh (formula)"):
            st.code(model_formula)
            st.caption(f"S·ªë d√≤ng d√πng cho m√¥ h√¨nh (sau khi lo·∫°i NA): {model_data_used.shape[0]}")

    run = st.button("‚ñ∂Ô∏è Ch·∫°y ki·ªÉm ƒë·ªãnh / m√¥ h√¨nh", type="primary", use_container_width=True)


# =========================
# Results area
# =========================
st.divider()
res_left, res_right = st.columns([1.35, 1.0], gap="large")

with res_left:
    st.subheader("üìå K·∫øt qu·∫£")
    if not run:
        st.info("Nh·∫•n **Ch·∫°y ki·ªÉm ƒë·ªãnh / m√¥ h√¨nh** ƒë·ªÉ xem k·∫øt qu·∫£.")
    else:
        try:
            if analysis_mode == "test":
                x1 = x[0]
                result_df, interp = run_single_x_test(df, y, x1, test_kind=test_kind)
                st.dataframe(result_df, use_container_width=True)
                st.write("üîé **G·ª£i √Ω di·ªÖn gi·∫£i:**")
                st.write(interp)
            else:
                fit, note = run_model(model_formula, model_data_used, model_kind)
                kind = model_kind.split("||", 1)[0]
                st.caption(note)

                if kind == "ols":
                    out = ols_table(fit)
                    st.dataframe(out, use_container_width=True)
                    st.write(
                        "üîé **G·ª£i √Ω di·ªÖn gi·∫£i:**\n"
                        "- H·ªá s·ªë > 0: Y tƒÉng khi X tƒÉng (gi·ªØ c√°c bi·∫øn kh√°c kh√¥ng ƒë·ªïi).\n"
                        "- p-value < 0.05: li√™n quan c√≥ √Ω nghƒ©a th·ªëng k√™ (tu·ª≥ ng∆∞·ª°ng nghi√™n c·ª©u).\n"
                        "- CI 95% kh√¥ng ch·ª©a 0: th∆∞·ªùng t∆∞∆°ng ·ª©ng c√≥ √Ω nghƒ©a."
                    )
                elif kind == "logit":
                    out = logit_or_table(fit)
                    st.dataframe(out, use_container_width=True)
                    st.write(
                        "üîé **G·ª£i √Ω di·ªÖn gi·∫£i:**\n"
                        "- OR > 1: tƒÉng odds x·∫£y ra s·ª± ki·ªán (Y=1).\n"
                        "- OR < 1: gi·∫£m odds.\n"
                        "- p-value < 0.05 v√† CI 95% kh√¥ng ch·ª©a 1: th∆∞·ªùng c√≥ √Ω nghƒ©a."
                    )
                else:
                    st.write(fit.summary())
                    st.write(
                        "üîé **G·ª£i √Ω di·ªÖn gi·∫£i (Multinomial):**\n"
                        "- H·ªá s·ªë ƒë∆∞·ª£c ∆∞·ªõc l∆∞·ª£ng theo **nh√≥m tham chi·∫øu**.\n"
                        "- N·∫øu b·∫°n mu·ªën b·∫£ng RRR = exp(coef) theo t·ª´ng nh√≥m, c√≥ th·ªÉ b·ªï sung."
                    )

        except Exception as e:
            st.error(f"L·ªói khi ch·∫°y: {e}")
            st.info("M·∫πo: ki·ªÉm tra d·ªØ li·ªáu (NA), bi·∫øn ph√¢n lo·∫°i qu√° nhi·ªÅu m·ª©c, ho·∫∑c c·ª° m·∫´u qu√° nh·ªè.")

with res_right:
    st.subheader("üìà Bi·ªÉu ƒë·ªì minh ho·∫°")
    if not run:
        st.info("Ch·∫°y xong app s·∫Ω v·∫Ω bi·ªÉu ƒë·ªì minh ho·∫°.")
    else:
        try:
            if analysis_mode == "test":
                x1 = x[0]
                yk = var_kind(df[y], y_force)
                xk = var_kind(df[x1], x_force)

                tmp = df[[y, x1]].dropna().copy()
                if tmp.shape[0] < 3:
                    st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
                else:
                    if yk == "num" and xk == "cat":
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=x1, y=y, points="all", title=f"{y} theo nh√≥m {x1}")
                        st.plotly_chart(fig, use_container_width=True)
                    elif yk == "cat" and xk == "num":
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=y, y=x1, points="all", title=f"{x1} theo nh√≥m {y}")
                        st.plotly_chart(fig, use_container_width=True)
                    elif yk == "cat" and xk == "cat":
                        tab = pd.crosstab(tmp[y].astype(str), tmp[x1].astype(str))
                        tab2 = tab.div(tab.sum(axis=1), axis=0).reset_index().melt(id_vars=[y], var_name=x1, value_name="T·ª∑ l·ªá")
                        fig = px.bar(tab2, x=y, y="T·ª∑ l·ªá", color=x1, barmode="stack", title=f"T·ª∑ l·ªá {x1} theo {y}")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.scatter(tmp, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1} (scatter + trendline)")
                        st.plotly_chart(fig, use_container_width=True)

            else:
                kind = model_kind.split("||", 1)[0]
                fit, _ = run_model(model_formula, model_data_used, model_kind)

                if kind == "ols":
                    x1 = x[0]
                    if (not is_categorical(model_data_used[x1])) and (not is_categorical(model_data_used[y])):
                        fig = px.scatter(model_data_used, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1} (k√®m trendline)")
                    else:
                        fig = px.box(model_data_used, x=x1, y=y, points="all", title=f"{y} theo nh√≥m {x1}") if is_categorical(model_data_used[x1]) else px.scatter(model_data_used, x=x1, y=y, title=f"{y} theo {x1}")
                    st.plotly_chart(fig, use_container_width=True)

                    pred = fit.fittedvalues
                    tmp_plot = pd.DataFrame({"Th·ª±c t·∫ø": model_data_used[y], "D·ª± ƒëo√°n": pred})
                    fig2 = px.scatter(tmp_plot, x="Th·ª±c t·∫ø", y="D·ª± ƒëo√°n", title="D·ª± ƒëo√°n vs Th·ª±c t·∫ø")
                    st.plotly_chart(fig2, use_container_width=True)

                elif kind == "logit":
                    p = fit.predict()
                    fig = px.histogram(p, nbins=25, title="Ph√¢n b·ªë x√°c su·∫•t d·ª± ƒëo√°n (p)")
                    st.plotly_chart(fig, use_container_width=True)

                    y_true = model_data_used["_y01_"].astype(int)
                    y_pred = (p >= 0.5).astype(int)
                    tp = int(((y_true == 1) & (y_pred == 1)).sum())
                    tn = int(((y_true == 0) & (y_pred == 0)).sum())
                    fp = int(((y_true == 0) & (y_pred == 1)).sum())
                    fn = int(((y_true == 1) & (y_pred == 0)).sum())
                    st.write("**B·∫£ng nh·∫ßm l·∫´n (ng∆∞·ª°ng 0.5):**")
                    st.table(pd.DataFrame({"D·ª± ƒëo√°n 0": [tn, fn], "D·ª± ƒëo√°n 1": [fp, tp]}, index=["Th·ª±c t·∫ø 0", "Th·ª±c t·∫ø 1"]))

                else:
                    st.info("Multinomial: bi·ªÉu ƒë·ªì minh ho·∫° c√≥ th·ªÉ b·ªï sung theo nhu c·∫ßu (RRR, x√°c su·∫•t d·ª± ƒëo√°n).")

        except Exception as e:
            st.warning(f"Kh√¥ng v·∫Ω ƒë∆∞·ª£c bi·ªÉu ƒë·ªì: {e}")

st.divider()
st.caption(
    "‚ö†Ô∏è L∆∞u √Ω: C√¥ng c·ª• h·ªó tr·ª£ g·ª£i √Ω v√† ch·∫°y ki·ªÉm ƒë·ªãnh/m√¥ h√¨nh c∆° b·∫£n. "
    "Ng∆∞·ªùi d√πng c·∫ßn ki·ªÉm tra gi·∫£ ƒë·ªãnh, thi·∫øt k·∫ø nghi√™n c·ª©u v√† c√°ch m√£ ho√° bi·∫øn ƒë·ªÉ di·ªÖn gi·∫£i ƒë√∫ng."
)
