import io
import re
import tempfile
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from scipy import stats
import statsmodels.formula.api as smf


# =========================
# App config
# =========================
st.set_page_config(
    page_title="H·ªó tr·ª£ nghi√™n c·ª©u cho b√°c sƒ© gia ƒë√¨nh",
    page_icon="üî¨",
    layout="wide",
)

APP_TITLE = "H·ªó tr·ª£ nghi√™n c·ª©u cho b√°c sƒ© gia ƒë√¨nh"


# =========================
# FullHD compact UI + FIX title cut/overlay
# =========================
st.markdown(
    """
    <style>
    /* ======= FIX: Safe top area to avoid Streamlit toolbar overlay ======= */
    :root { --app-top-safe: 64px; }  /* n·∫øu v·∫´n che, tƒÉng 72px */

    /* ======= Layout width + padding ======= */
    .block-container{
        padding-top: calc(var(--app-top-safe) + 0.75rem) !important; /* FIX: kh√¥ng b·ªã che */
        padding-bottom: 0.60rem !important;
        padding-left: 0.90rem !important;
        padding-right: 0.90rem !important;
        max-width: 1600px !important;      /* Full HD */
    }

    /* ======= Typography (g·ªçn h∆°n ~80%) ======= */
    h1 {
        font-size: 1.70rem !important;
        margin: 0.0rem 0 0.10rem 0 !important;
        line-height: 2.05rem !important;
    }
    h2 { font-size: 1.25rem !important; margin: 0.35rem 0 0.20rem 0 !important; }
    h3 { font-size: 1.05rem !important; margin: 0.35rem 0 0.20rem 0 !important; }
    p, li, label, div { font-size: 0.95rem; }

    /* ======= Reduce gaps ======= */
    div[data-testid="stVerticalBlock"] { gap: 0.28rem; }
    .stMarkdown { margin-bottom: 0.10rem !important; }
    .stCaptionContainer { margin-top: -0.18rem !important; }

    /* ======= Widgets spacing ======= */
    .stSelectbox, .stMultiSelect, .stTextInput, .stFileUploader, .stRadio, .stCheckbox {
        margin-bottom: 0.15rem !important;
    }

    /* ======= Divider ======= */
    hr { margin: 0.40rem 0 !important; }

    /* ======= Buttons (g·ªçn h∆°n) ======= */
    div.stButton > button{
        width: 100%;
        padding: 8px 10px !important;
        border-radius: 12px !important;
        font-size: 14px !important;
        font-weight: 780 !important;
        border: 1px solid rgba(0,0,0,0.10) !important;
        box-shadow: 0 1px 5px rgba(0,0,0,0.06) !important;
    }

    /* ======= Sidebar compact ======= */
    section[data-testid="stSidebar"] .block-container{
        padding-top: 0.55rem !important;
        padding-left: 0.75rem !important;
        padding-right: 0.75rem !important;
    }
    section[data-testid="stSidebar"] p,
    section[data-testid="stSidebar"] label,
    section[data-testid="stSidebar"] div{
        font-size: 0.90rem !important;
    }

    /* ======= Dataframes ======= */
    .stDataFrame { margin-top: 0.10rem !important; }

    /* ======= Caption d∆∞·ªõi stepper g·ªçn ======= */
    [data-testid="stCaptionContainer"] {
        font-size: 0.80rem !important;
        line-height: 1.05rem !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


# =========================
# Helpers: safe name + hashing
# =========================
def _safe_name(name: str) -> str:
    return re.sub(r"[^a-zA-Z0-9_]+", "_", str(name).strip())[:80] or "file"


def _file_sha256(raw: bytes) -> str:
    return hashlib.sha256(raw).hexdigest()


def _df_sha256(df: pd.DataFrame) -> str:
    h = pd.util.hash_pandas_object(df, index=True).values.tobytes()
    return hashlib.sha256(h).hexdigest()


# =========================
# Read files safely
# =========================
def read_csv_safely(uploaded_file) -> pd.DataFrame:
    raw = uploaded_file.getvalue()
    encodings = ["utf-8-sig", "utf-8", "cp1258", "cp1252", "latin1"]
    last_err = None
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(raw), encoding=enc)
        except Exception as e:
            last_err = e
    raise last_err


def _read_via_tempfile(raw: bytes, suffix: str, reader_fn):
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(raw)
            tmp_path = tmp.name
        return reader_fn(tmp_path)
    finally:
        if tmp_path:
            try:
                Path(tmp_path).unlink(missing_ok=True)
            except Exception:
                pass


def read_file_safely(uploaded_file) -> Dict[str, pd.DataFrame]:
    name = uploaded_file.name
    ext = Path(name).suffix.lower()
    raw = uploaded_file.getvalue()

    if ext == ".csv":
        return {"data": read_csv_safely(uploaded_file)}

    if ext == ".xlsx":
        xls = pd.ExcelFile(io.BytesIO(raw), engine="openpyxl")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh)
        return out

    if ext == ".xls":
        # c·∫ßn xlrd>=2.0.1
        xls = pd.ExcelFile(io.BytesIO(raw), engine="xlrd")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh, engine="xlrd")
        return out

    if ext in [".sav", ".zsav"]:
        # FIX l·ªói BytesIO: ƒë·ªçc qua file t·∫°m
        df = _read_via_tempfile(raw, ext, pd.read_spss)
        return {"data": df}

    if ext == ".dta":
        df = _read_via_tempfile(raw, ".dta", pd.read_stata)
        return {"data": df}

    if ext == ".rds":
        try:
            import pyreadr  # type: ignore
        except Exception as e:
            raise RuntimeError("Thi·∫øu pyreadr ƒë·ªÉ ƒë·ªçc .rds. C√†i: pip install pyreadr") from e

        def _read_rds(path: str):
            res = pyreadr.read_r(path)
            out: Dict[str, pd.DataFrame] = {}
            for k, v in res.items():
                if isinstance(v, pd.DataFrame):
                    out[str(k) if k else "data"] = v
            return out

        out = _read_via_tempfile(raw, ".rds", _read_rds)
        if not out:
            raise RuntimeError("File .rds kh√¥ng ch·ª©a DataFrame (ho·∫∑c object kh√¥ng h·ªó tr·ª£).")
        return out

    raise RuntimeError(f"ƒê·ªãnh d·∫°ng {ext} ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£.")


# =========================
# Type detection
# =========================
def is_categorical(s: pd.Series) -> bool:
    if pd.api.types.is_bool_dtype(s) or pd.api.types.is_object_dtype(s) or pd.api.types.is_categorical_dtype(s):
        return True
    if pd.api.types.is_numeric_dtype(s):
        nunique = s.dropna().nunique()
        if nunique <= 10:
            return True
    return False


def coerce_numeric(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")


def var_kind(s: pd.Series, forced: str = "T·ª± ƒë·ªông") -> str:
    if forced == "ƒê·ªãnh l∆∞·ª£ng (numeric)":
        return "num"
    if forced == "Ph√¢n lo·∫°i (categorical)":
        return "cat"
    return "cat" if is_categorical(s) else "num"


# =========================
# Summaries
# =========================
def summarize_variable(df: pd.DataFrame, col: str) -> Dict[str, str]:
    s = df[col]
    miss = int(s.isna().sum())
    n = int(len(s))
    nunique = int(s.dropna().nunique())

    if is_categorical(s):
        vc = s.astype("string").value_counts(dropna=True).head(3)
        top = ", ".join([f"{idx} ({val})" for idx, val in vc.items()]) if len(vc) else "-"
        return {"T√™n bi·∫øn": col, "ƒê·∫∑c t√≠nh bi·∫øn": f"Ph√¢n lo·∫°i | m·ª©c={nunique} | thi·∫øu={miss}/{n} | top: {top}"}

    x = coerce_numeric(s)
    x_non = x.dropna()
    if len(x_non) == 0:
        return {"T√™n bi·∫øn": col, "ƒê·∫∑c t√≠nh bi·∫øn": f"ƒê·ªãnh l∆∞·ª£ng | thi·∫øu={miss}/{n} | (kh√¥ng ƒë·ªçc ƒë∆∞·ª£c s·ªë)"}

    mean = float(x_non.mean())
    sd = float(x_non.std(ddof=1)) if len(x_non) >= 2 else float("nan")
    med = float(x_non.median())
    q1 = float(x_non.quantile(0.25))
    q3 = float(x_non.quantile(0.75))
    return {
        "T√™n bi·∫øn": col,
        "ƒê·∫∑c t√≠nh bi·∫øn": f"ƒê·ªãnh l∆∞·ª£ng | thi·∫øu={miss}/{n} | mean={mean:.2f}, SD={sd:.2f} | median={med:.2f} (IQR {q1:.2f}-{q3:.2f})",
    }


def overall_summary(df: pd.DataFrame) -> Dict[str, int]:
    n_rows = int(df.shape[0])
    n_cols = int(df.shape[1])
    missing_cells = int(df.isna().sum().sum())
    numeric_cols = sum([pd.api.types.is_numeric_dtype(df[c]) and (not is_categorical(df[c])) for c in df.columns])
    cat_cols = n_cols - numeric_cols
    return {
        "S·ªë d√≤ng": n_rows,
        "S·ªë bi·∫øn": n_cols,
        "Bi·∫øn ƒë·ªãnh l∆∞·ª£ng": int(numeric_cols),
        "Bi·∫øn ph√¢n lo·∫°i": int(cat_cols),
        "√î thi·∫øu (NA)": missing_cells,
    }


# =========================
# Assumptions: normality & homogeneity
# =========================
def normality_pvalue(x: np.ndarray) -> float:
    x = x[~np.isnan(x)]
    n = len(x)
    if n < 3:
        return float("nan")
    try:
        if n <= 5000:
            return float(stats.shapiro(x).pvalue)
        return float(stats.normaltest(x).pvalue)
    except Exception:
        return float("nan")


def variance_homogeneity_pvalue(groups: List[np.ndarray]) -> float:
    clean = [g[~np.isnan(g)] for g in groups if len(g[~np.isnan(g)]) >= 2]
    if len(clean) < 2:
        return float("nan")
    try:
        return float(stats.levene(*clean, center="median").pvalue)
    except Exception:
        return float("nan")


def assumption_report_num_by_group(df: pd.DataFrame, y_num: str, group_cat: str) -> dict:
    tmp = df[[y_num, group_cat]].dropna().copy()
    tmp[y_num] = pd.to_numeric(tmp[y_num], errors="coerce")
    tmp = tmp.dropna()

    levels = sorted(tmp[group_cat].astype(str).unique().tolist())
    arrays = []
    norm_p = {}
    ns = {}

    for lv in levels:
        a = tmp.loc[tmp[group_cat].astype(str) == lv, y_num].to_numpy()
        a = a[~np.isnan(a)]
        arrays.append(a)
        ns[lv] = int(len(a))
        norm_p[lv] = normality_pvalue(a)

    lev_p = variance_homogeneity_pvalue(arrays)
    return {"levels": levels, "n": ns, "normality_p": norm_p, "levene_p": lev_p, "total_n": int(tmp.shape[0])}


def _norm_ok(report: dict, alpha: float = 0.05) -> bool:
    for lv, n in report["n"].items():
        if n < 3:
            return False
        p = report["normality_p"].get(lv, float("nan"))
        if np.isnan(p) or p < alpha:
            return False
    return True


def _var_ok(report: dict, alpha: float = 0.05) -> bool:
    p = report.get("levene_p", float("nan"))
    return (not np.isnan(p)) and (p >= alpha)


def _assumption_text(rep: dict) -> str:
    norm = ", ".join(
        [
            f"{k}: p={rep['normality_p'][k]:.4f}" if not np.isnan(rep["normality_p"][k]) else f"{k}: p=NA"
            for k in rep["levels"]
        ]
    )
    lev = rep.get("levene_p", float("nan"))
    lev_s = f"{lev:.4f}" if not np.isnan(lev) else "NA"
    return f"Gi·∫£ ƒë·ªãnh: Shapiro theo nh√≥m [{norm}]; Levene p={lev_s}."


# =========================
# Single-X: suggest + run
# =========================
def suggest_single_x_test(
    df: pd.DataFrame,
    y: str,
    x: str,
    y_forced: str = "T·ª± ƒë·ªông",
    x_forced: str = "T·ª± ƒë·ªông",
) -> Tuple[str, str, str]:
    yk = var_kind(df[y], y_forced)
    xk = var_kind(df[x], x_forced)

    tmp = df[[y, x]].dropna()
    if tmp.shape[0] < 3:
        return ("Kh√¥ng ƒë·ªß d·ªØ li·ªáu", "Sau khi lo·∫°i NA, s·ªë d√≤ng qu√° √≠t ƒë·ªÉ ki·ªÉm ƒë·ªãnh.", "none")

    # cat vs cat
    if yk == "cat" and xk == "cat":
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape == (2, 2) and (tab.values < 5).any():
            return ("Fisher exact (2x2)", "B·∫£ng 2x2 c√≥ √¥ nh·ªè ‚Üí ∆∞u ti√™n Fisher.", "fisher_2x2")
        return ("Chi-b√¨nh ph∆∞∆°ng (Chi-square)", "X v√† Y ƒë·ªÅu ph√¢n lo·∫°i ‚Üí Chi-square.", "chisq")

    # y numeric by group x categorical
    if yk == "num" and xk == "cat":
        rep = assumption_report_num_by_group(df, y_num=y, group_cat=x)
        n_levels = len(rep["levels"])
        norm_ok = _norm_ok(rep)
        var_ok = _var_ok(rep)

        if n_levels == 2:
            if norm_ok and var_ok:
                return ("t-test (Student)", "2 nh√≥m, ƒë·∫°t chu·∫©n & ph∆∞∆°ng sai t∆∞∆°ng ƒë∆∞∆°ng ‚Üí Student.", "ttest_student")
            if norm_ok and (not var_ok):
                return ("t-test (Welch)", "2 nh√≥m, chu·∫©n nh∆∞ng ph∆∞∆°ng sai kh√°c ‚Üí Welch.", "ttest_welch")
            return ("Mann‚ÄìWhitney U", "2 nh√≥m, kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh chu·∫©n ‚Üí Mann‚ÄìWhitney.", "mwu")

        if norm_ok and var_ok:
            return ("ANOVA m·ªôt y·∫øu t·ªë", "Nhi·ªÅu nh√≥m, ƒë·∫°t chu·∫©n & ƒë·ªìng nh·∫•t ph∆∞∆°ng sai ‚Üí ANOVA.", "anova")
        return ("Kruskal‚ÄìWallis", "Nhi·ªÅu nh√≥m, kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh ‚Üí Kruskal.", "kruskal")

    # x numeric by group y categorical (swap)
    if yk == "cat" and xk == "num":
        rep = assumption_report_num_by_group(df, y_num=x, group_cat=y)
        n_levels = len(rep["levels"])
        norm_ok = _norm_ok(rep)
        var_ok = _var_ok(rep)

        if n_levels == 2:
            if norm_ok and var_ok:
                return ("t-test (Student)", "2 nh√≥m, ƒë·∫°t chu·∫©n & ph∆∞∆°ng sai t∆∞∆°ng ƒë∆∞∆°ng ‚Üí Student.", "ttest_student_swapped")
            if norm_ok and (not var_ok):
                return ("t-test (Welch)", "2 nh√≥m, chu·∫©n nh∆∞ng ph∆∞∆°ng sai kh√°c ‚Üí Welch.", "ttest_welch_swapped")
            return ("Mann‚ÄìWhitney U", "2 nh√≥m, kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh chu·∫©n ‚Üí Mann‚ÄìWhitney.", "mwu_swapped")

        if norm_ok and var_ok:
            return ("ANOVA m·ªôt y·∫øu t·ªë", "Nhi·ªÅu nh√≥m, ƒë·∫°t chu·∫©n & ƒë·ªìng nh·∫•t ph∆∞∆°ng sai ‚Üí ANOVA.", "anova_swapped")
        return ("Kruskal‚ÄìWallis", "Nhi·ªÅu nh√≥m, kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh ‚Üí Kruskal.", "kruskal_swapped")

    # num vs num: correlation
    if yk == "num" and xk == "num":
        tmp2 = df[[y, x]].copy()
        tmp2[y] = coerce_numeric(tmp2[y])
        tmp2[x] = coerce_numeric(tmp2[x])
        tmp2 = tmp2.dropna()
        if tmp2.shape[0] < 3:
            return ("Kh√¥ng ƒë·ªß d·ªØ li·ªáu", "Kh√¥ng ƒë·ªß d√≤ng s·ªë ƒë·ªÉ t√≠nh t∆∞∆°ng quan.", "none")

        pny = normality_pvalue(tmp2[y].to_numpy())
        pnx = normality_pvalue(tmp2[x].to_numpy())
        if (not np.isnan(pny)) and (not np.isnan(pnx)) and (pny >= 0.05) and (pnx >= 0.05):
            return ("T∆∞∆°ng quan Pearson", "X v√† Y g·∫ßn chu·∫©n ‚Üí Pearson.", "corr_pearson")
        return ("T∆∞∆°ng quan Spearman", "X ho·∫∑c Y kh√¥ng chu·∫©n/ordinal ‚Üí Spearman.", "corr_spearman")

    return ("Kh√¥ng x√°c ƒë·ªãnh", "Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ph√©p ki·ªÉm ph√π h·ª£p.", "none")


def _cohens_d(a: np.ndarray, b: np.ndarray) -> float:
    a = a[~np.isnan(a)]
    b = b[~np.isnan(b)]
    if len(a) < 2 or len(b) < 2:
        return float("nan")
    va = np.var(a, ddof=1)
    vb = np.var(b, ddof=1)
    sp = np.sqrt(((len(a) - 1) * va + (len(b) - 1) * vb) / (len(a) + len(b) - 2))
    if sp == 0:
        return float("nan")
    return (np.mean(a) - np.mean(b)) / sp


def _cramers_v(tab: pd.DataFrame) -> float:
    chi2, p, dof, exp = stats.chi2_contingency(tab.values)
    n = tab.values.sum()
    if n == 0:
        return float("nan")
    r, k = tab.shape
    return np.sqrt(chi2 / (n * (min(r, k) - 1))) if min(r, k) > 1 else float("nan")


def run_single_x_test(df: pd.DataFrame, y: str, x: str, test_kind: str) -> Tuple[pd.DataFrame, str]:
    if test_kind == "chisq":
        tmp = df[[y, x]].dropna()
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        chi2, p, dof, exp = stats.chi2_contingency(tab.values)
        v = _cramers_v(tab)
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["Chi2", "df", "p-value", "Cramer's V"], "Gi√° tr·ªã": [chi2, dof, p, v]})
        interp = "Di·ªÖn gi·∫£i: p nh·ªè ‚Üí g·ª£i √Ω c√≥ li√™n quan. Cramer's V ƒë√°nh gi√° ƒë·ªô m·∫°nh li√™n quan."
        return out, interp

    if test_kind == "fisher_2x2":
        tmp = df[[y, x]].dropna()
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape != (2, 2):
            raise ValueError("Fisher exact ch·ªâ √°p d·ª•ng b·∫£ng 2x2.")
        oddsratio, p = stats.fisher_exact(tab.values)
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["Odds ratio", "p-value"], "Gi√° tr·ªã": [oddsratio, p]})
        interp = "Di·ªÖn gi·∫£i: p nh·ªè ‚Üí g·ª£i √Ω li√™n quan. OR di·ªÖn gi·∫£i theo nh√≥m tham chi·∫øu."
        return out, interp

    if test_kind in ("ttest_student", "ttest_welch", "mwu", "anova", "kruskal"):
        tmp = df[[y, x]].dropna().copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp = tmp.dropna()
        groups = tmp[x].astype(str)
        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, y].to_numpy() for lv in levels]
        rep = assumption_report_num_by_group(df, y_num=y, group_cat=x)
        assump = _assumption_text(rep)

        if test_kind in ("ttest_student", "ttest_welch"):
            if len(levels) != 2:
                raise ValueError("t-test c·∫ßn ƒë√∫ng 2 nh√≥m.")
            a, b = arrays[0], arrays[1]
            equal_var = (test_kind == "ttest_student")
            tstat, p = stats.ttest_ind(a, b, equal_var=equal_var, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["t", "p-value", "Cohen's d"], "Gi√° tr·ªã": [tstat, p, d]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: p nh·ªè ‚Üí trung b√¨nh kh√°c nhau gi·ªØa 2 nh√≥m. Cohen‚Äôs d l√† effect size."
            return out, interp

        if test_kind == "mwu":
            if len(levels) != 2:
                raise ValueError("Mann‚ÄìWhitney c·∫ßn ƒë√∫ng 2 nh√≥m.")
            a, b = arrays[0], arrays[1]
            u, p = stats.mannwhitneyu(a, b, alternative="two-sided")
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["U", "p-value"], "Gi√° tr·ªã": [u, p]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: d√πng khi kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh chu·∫©n."
            return out, interp

        if test_kind == "anova":
            f, p = stats.f_oneway(*arrays)
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["F", "p-value"], "Gi√° tr·ªã": [f, p]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: p nh·ªè ‚Üí c√≥ √≠t nh·∫•t 1 nh√≥m kh√°c trung b√¨nh; n√™n l√†m post-hoc."
            return out, interp

        if test_kind == "kruskal":
            h, p = stats.kruskal(*arrays)
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["H (Kruskal)", "p-value"], "Gi√° tr·ªã": [h, p]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: d√πng khi kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh; n·∫øu c√≥ √Ω nghƒ©a n√™n post-hoc."
            return out, interp

    if test_kind.endswith("_swapped"):
        tmp = df[[y, x]].dropna().copy()
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        groups = tmp[y].astype(str)
        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, x].to_numpy() for lv in levels]
        rep = assumption_report_num_by_group(df, y_num=x, group_cat=y)
        assump = _assumption_text(rep)
        base = test_kind.replace("_swapped", "")

        if base in ("ttest_student", "ttest_welch"):
            if len(levels) != 2:
                raise ValueError("t-test c·∫ßn ƒë√∫ng 2 nh√≥m.")
            a, b = arrays[0], arrays[1]
            equal_var = (base == "ttest_student")
            tstat, p = stats.ttest_ind(a, b, equal_var=equal_var, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["t", "p-value", "Cohen's d"], "Gi√° tr·ªã": [tstat, p, d]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: p nh·ªè ‚Üí trung b√¨nh kh√°c nhau gi·ªØa 2 nh√≥m (theo Y)."
            return out, interp

        if base == "mwu":
            if len(levels) != 2:
                raise ValueError("Mann‚ÄìWhitney c·∫ßn ƒë√∫ng 2 nh√≥m.")
            a, b = arrays[0], arrays[1]
            u, p = stats.mannwhitneyu(a, b, alternative="two-sided")
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["U", "p-value"], "Gi√° tr·ªã": [u, p]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: d√πng khi kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh chu·∫©n."
            return out, interp

        if base == "anova":
            f, p = stats.f_oneway(*arrays)
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["F", "p-value"], "Gi√° tr·ªã": [f, p]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: p nh·ªè ‚Üí c√≥ √≠t nh·∫•t 1 nh√≥m kh√°c trung b√¨nh; n√™n l√†m post-hoc."
            return out, interp

        if base == "kruskal":
            h, p = stats.kruskal(*arrays)
            out = pd.DataFrame({"Ch·ªâ s·ªë": ["H (Kruskal)", "p-value"], "Gi√° tr·ªã": [h, p]})
            interp = f"{assump}\nDi·ªÖn gi·∫£i: d√πng khi kh√¥ng ƒë·∫°t gi·∫£ ƒë·ªãnh; n·∫øu c√≥ √Ω nghƒ©a n√™n post-hoc."
            return out, interp

    if test_kind == "corr_pearson":
        tmp = df[[y, x]].copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        r, p = stats.pearsonr(tmp[x].to_numpy(), tmp[y].to_numpy())
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["Pearson r", "p-value", "n"], "Gi√° tr·ªã": [r, p, tmp.shape[0]]})
        interp = "Di·ªÖn gi·∫£i: r g·∫ßn 0 ‚Üí y·∫øu; g·∫ßn ¬±1 ‚Üí m·∫°nh. p nh·ªè ‚Üí li√™n quan tuy·∫øn t√≠nh c√≥ √Ω nghƒ©a."
        return out, interp

    if test_kind == "corr_spearman":
        tmp = df[[y, x]].copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        rho, p = stats.spearmanr(tmp[x].to_numpy(), tmp[y].to_numpy())
        out = pd.DataFrame({"Ch·ªâ s·ªë": ["Spearman rho", "p-value", "n"], "Gi√° tr·ªã": [rho, p, tmp.shape[0]]})
        interp = "Di·ªÖn gi·∫£i: Spearman ƒë√°nh gi√° li√™n quan ƒë∆°n ƒëi·ªáu, ph√π h·ª£p khi d·ªØ li·ªáu kh√¥ng chu·∫©n/ordinal."
        return out, interp

    raise ValueError("Kh√¥ng c√≥ ki·ªÉm ƒë·ªãnh ph√π h·ª£p (test_kind=none).")


# =========================
# Model: suggest + build + run
# =========================
def suggest_model(df: pd.DataFrame, y: str, xs: List[str]) -> Tuple[str, str]:
    y_s = df[y]
    if is_categorical(y_s):
        n_levels = int(y_s.dropna().nunique())
        if n_levels <= 1:
            return ("Kh√¥ng ƒë·ªß d·ªØ li·ªáu", "Y ch·ªâ c√≥ 0‚Äì1 m·ª©c sau khi lo·∫°i thi·∫øu. H√£y ki·ªÉm tra d·ªØ li·ªáu.")
        if n_levels == 2:
            return ("H·ªìi quy Logistic nh·ªã ph√¢n (Binary Logistic)", "Y ph√¢n lo·∫°i 2 m·ª©c ‚Üí logistic nh·ªã ph√¢n ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng OR.")
        return ("H·ªìi quy Logistic ƒëa danh (Multinomial Logistic)", f"Y >2 m·ª©c (m·ª©c={n_levels}) ‚Üí logistic ƒëa danh.")
    return ("H·ªìi quy tuy·∫øn t√≠nh (OLS)", "Y ƒë·ªãnh l∆∞·ª£ng ‚Üí h·ªìi quy tuy·∫øn t√≠nh (OLS).")


def build_formula(
    df: pd.DataFrame,
    y: str,
    xs: List[str],
    y_binary_event: Optional[str] = None,
) -> Tuple[str, pd.DataFrame, str]:
    tmp = df[[y] + xs].copy().dropna()

    if is_categorical(tmp[y]):
        n_levels = int(tmp[y].nunique())

        if n_levels == 2:
            y_cat = tmp[y].astype("category")
            cats = list(y_cat.cat.categories)
            event = y_binary_event if (y_binary_event in cats) else cats[1]
            tmp["_y01_"] = (tmp[y] == event).astype(int)

            terms = []
            for x in xs:
                terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

            formula = "_y01_ ~ " + " + ".join(terms)
            return formula, tmp, f"logit||Logistic nh·ªã ph√¢n: s·ª± ki·ªán (Y=1)='{event}'"

        tmp["_ycat_"] = tmp[y].astype("category")
        tmp["_ycode_"] = tmp["_ycat_"].cat.codes

        terms = []
        for x in xs:
            terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

        formula = "_ycode_ ~ " + " + ".join(terms)
        return formula, tmp, "mnlogit||Multinomial: h·ªá s·ªë theo nh√≥m tham chi·∫øu"

    tmp[y] = coerce_numeric(tmp[y])
    tmp = tmp.dropna()

    terms = []
    for x in xs:
        terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

    formula = f"Q('{y}') ~ " + " + ".join(terms)
    return formula, tmp, "ols||OLS"


def run_model(formula: str, data_used: pd.DataFrame, model_kind: str):
    kind, note = model_kind.split("||", 1)

    if kind == "ols":
        return smf.ols(formula=formula, data=data_used).fit(), note

    if kind == "logit":
        return smf.logit(formula=formula, data=data_used).fit(disp=0), note

    if kind == "mnlogit":
        return smf.mnlogit(formula=formula, data=data_used).fit(disp=0), note

    raise ValueError("Unknown model kind")


def ols_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame(
        {"H·ªá s·ªë": fit.params, "CI 2.5%": conf[0], "CI 97.5%": conf[1], "p-value": fit.pvalues}
    )
    out.index.name = "Bi·∫øn"
    return out.sort_values("p-value")


def logit_or_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame(
        {
            "OR": np.exp(fit.params),
            "CI 2.5%": np.exp(conf[0]),
            "CI 97.5%": np.exp(conf[1]),
            "p-value": fit.pvalues,
        }
    )
    out.index.name = "Bi·∫øn"
    return out.sort_values("p-value")


# =========================
# OLS equation + detailed interpretation
# =========================
def format_ols_equation(fit, y_name: str) -> str:
    params = fit.params.to_dict()
    parts = []
    b0 = float(params.get("Intercept", 0.0))
    parts.append(f"{b0:.4f}")

    for term, b in params.items():
        if term == "Intercept":
            continue

        m_num = re.match(r"Q\('(.+)'\)", term)
        if m_num:
            var = m_num.group(1)
            parts.append(f"{float(b):+.4f}*{var}")
            continue

        m_cat = re.match(r"C\(Q\('(.+)'\)\)\[T\.(.+)\]", term)
        if m_cat:
            var = m_cat.group(1)
            lv = m_cat.group(2)
            parts.append(f"{float(b):+.4f}*I({var}={lv})")
            continue

        parts.append(f"{float(b):+.4f}*({term})")

    return f"**Ph∆∞∆°ng tr√¨nh (OLS):**  ≈∂({y_name}) = " + " ".join(parts)


def explain_ols_effects(fit, y_name: str, alpha: float = 0.05) -> List[str]:
    conf = fit.conf_int()
    lines: List[str] = []
    for term in fit.params.index:
        if term == "Intercept":
            continue
        b = float(fit.params[term])
        p = float(fit.pvalues[term])
        lo = float(conf.loc[term, 0])
        hi = float(conf.loc[term, 1])
        sig = "c√≥ √Ω nghƒ©a th·ªëng k√™" if p < alpha else "ch∆∞a ƒë·ªß √Ω nghƒ©a th·ªëng k√™"

        m_num = re.match(r"Q\('(.+)'\)", term)
        if m_num:
            var = m_num.group(1)
            direction = "tƒÉng" if b > 0 else "gi·∫£m"
            lines.append(
                f"- **{var}**: tƒÉng 1 ƒë∆°n v·ªã ‚Üí **{y_name} {direction} {abs(b):.4f} ƒë∆°n v·ªã** (ƒë√£ hi·ªáu ch·ªânh). "
                f"p={p:.4g}, CI95%=[{lo:.4f}; {hi:.4f}] ‚Üí {sig}."
            )
            continue

        m_cat = re.match(r"C\(Q\('(.+)'\)\)\[T\.(.+)\]", term)
        if m_cat:
            var = m_cat.group(1)
            lv = m_cat.group(2)
            direction = "cao h∆°n" if b > 0 else "th·∫•p h∆°n"
            lines.append(
                f"- **{var}={lv}** (so v·ªõi nh√≥m tham chi·∫øu): **{y_name} {direction} {abs(b):.4f} ƒë∆°n v·ªã** (ƒë√£ hi·ªáu ch·ªânh). "
                f"p={p:.4g}, CI95%=[{lo:.4f}; {hi:.4f}] ‚Üí {sig}."
            )
            continue

        lines.append(
            f"- **{term}**: coef={b:.4f}, p={p:.4g}, CI95%=[{lo:.4f}; {hi:.4f}] ‚Üí {sig}."
        )
    return lines or ["- Kh√¥ng c√≥ bi·∫øn gi·∫£i th√≠ch (ch·ªâ intercept)."]


# =========================
# Session state
# =========================
if "datasets" not in st.session_state:
    st.session_state["datasets"] = {}
if "active_name" not in st.session_state:
    st.session_state["active_name"] = None

if "pending_tables" not in st.session_state:
    st.session_state["pending_tables"] = None
if "pending_fname" not in st.session_state:
    st.session_state["pending_fname"] = None
if "pending_file_hash" not in st.session_state:
    st.session_state["pending_file_hash"] = None

if "hash_to_key" not in st.session_state:
    st.session_state["hash_to_key"] = {}
if "key_to_hashes" not in st.session_state:
    st.session_state["key_to_hashes"] = {}

if "last_upload_hash" not in st.session_state:
    st.session_state["last_upload_hash"] = None

if "last_result" not in st.session_state:
    st.session_state["last_result"] = None
if "last_run_meta" not in st.session_state:
    st.session_state["last_run_meta"] = None

if "active_step" not in st.session_state:
    st.session_state["active_step"] = 1


def _register_dataset(key: str, df: pd.DataFrame, hashes: List[str]):
    st.session_state["datasets"][key] = df
    st.session_state["active_name"] = key
    st.session_state["key_to_hashes"].setdefault(key, set())
    for h in hashes:
        st.session_state["hash_to_key"][h] = key
        st.session_state["key_to_hashes"][key].add(h)


def _delete_dataset(key: str):
    st.session_state["datasets"].pop(key, None)
    hashes = st.session_state["key_to_hashes"].pop(key, set())
    for h in list(hashes):
        if st.session_state["hash_to_key"].get(h) == key:
            st.session_state["hash_to_key"].pop(h, None)


# =========================
# Header (compact, safe top)
# =========================
st.markdown(
    f"""
    <div style="padding:0.10rem 0 0.10rem 0; margin-top:0.20rem;">
      <h1 style="margin:0;">{APP_TITLE}</h1>
      <div style="color:#6b7280; font-size:0.88rem; margin-top:0.08rem;">
        Upload d·ªØ li·ªáu ‚Üí ch·ªçn bi·∫øn ‚Üí ki·ªÉm ƒë·ªãnh (1 X) ho·∫∑c m√¥ h√¨nh (nhi·ªÅu X) ‚Üí k·∫øt qu·∫£ + gi·∫£i th√≠ch
      </div>
    </div>
    """,
    unsafe_allow_html=True,
)


# =========================
# Sidebar
# =========================
with st.sidebar:
    st.markdown("## ‚¨ÜÔ∏è Upload")
    up = st.file_uploader(
        "T·∫£i l√™n d·ªØ li·ªáu (CSV/XLSX/XLS/SAV/ZsAV/DTA/RDS)",
        type=["csv", "xlsx", "xls", "sav", "zsav", "dta", "rds"],
        accept_multiple_files=False,
    )

    if up is not None:
        try:
            raw = up.getvalue()
            file_hash = _file_sha256(raw)

            # ch·ªëng x·ª≠ l√Ω l·∫°i c√πng 1 upload
            if st.session_state["last_upload_hash"] != file_hash:
                st.session_state["last_upload_hash"] = file_hash

                # n·∫øu file ƒë√£ t·ª´ng import ‚Üí ch·ªçn l·∫°i dataset c≈© (tr√°nh duplicate)
                if file_hash in st.session_state["hash_to_key"]:
                    existed_key = st.session_state["hash_to_key"][file_hash]
                    st.session_state["active_name"] = existed_key
                    st.info(f"ƒê√£ c√≥ tr∆∞·ªõc ƒë√≥ ‚Üí {existed_key}")
                else:
                    tables = read_file_safely(up)

                    # file nhi·ªÅu sheet/object
                    if len(tables) > 1:
                        st.session_state["pending_tables"] = tables
                        st.session_state["pending_fname"] = up.name
                        st.session_state["pending_file_hash"] = file_hash
                        st.info("File c√≥ nhi·ªÅu b·∫£ng ‚Üí ch·ªçn 1 b·∫£ng ƒë·ªÉ nh·∫≠p.")
                    else:
                        df_new = list(tables.values())[0]
                        base = _safe_name(Path(up.name).stem)
                        key = base
                        i = 2
                        while key in st.session_state["datasets"]:
                            key = f"{base}_{i}"
                            i += 1

                        df_hash = _df_sha256(df_new)
                        _register_dataset(key, df_new, hashes=[file_hash, df_hash])
                        st.session_state["active_step"] = 1
                        st.success(f"ƒê√£ t·∫£i: {key}")

        except Exception as e:
            st.error(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file: {e}")

    # ch·ªçn sheet/object khi file c√≥ nhi·ªÅu b·∫£ng
    if st.session_state["pending_tables"] is not None:
        st.markdown("### Ch·ªçn sheet/object")
        tables = st.session_state["pending_tables"]
        fname = st.session_state["pending_fname"] or "file"
        pending_file_hash = st.session_state["pending_file_hash"]

        chosen_table = st.selectbox("Sheet/Object", options=list(tables.keys()))
        c1, c2 = st.columns([1, 1], gap="small")
        with c1:
            if st.button("Nh·∫≠p", use_container_width=True):
                df_new = tables[chosen_table]
                table_hash = _df_sha256(df_new)

                if table_hash in st.session_state["hash_to_key"]:
                    existed_key = st.session_state["hash_to_key"][table_hash]
                    st.session_state["active_name"] = existed_key
                    st.info(f"ƒê√£ nh·∫≠p tr∆∞·ªõc ƒë√≥ ‚Üí {existed_key}")
                else:
                    base = _safe_name(Path(fname).stem)
                    sh = _safe_name(chosen_table)
                    key_base = f"{base}__{sh}"
                    key = key_base
                    i = 2
                    while key in st.session_state["datasets"]:
                        key = f"{key_base}_{i}"
                        i += 1

                    hashes = [table_hash]
                    if pending_file_hash:
                        hashes.append(pending_file_hash)

                    _register_dataset(key, df_new, hashes=hashes)
                    st.session_state["active_step"] = 1
                    st.success(f"ƒê√£ nh·∫≠p: {key}")

                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

        with c2:
            if st.button("Hu·ª∑", use_container_width=True):
                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

    st.markdown("---")
    st.markdown("## üìÅ Dataset")

    names_all = list(st.session_state["datasets"].keys())
    if not names_all:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")
        st.stop()

    ds_q = st.text_input("T√¨m dataset", value="", placeholder="g√µ t√™n dataset...")
    if ds_q.strip():
        names = [n for n in names_all if ds_q.lower() in n.lower()] or names_all
    else:
        names = names_all

    active = st.session_state["active_name"] or names_all[0]
    if active not in names_all:
        active = names_all[0]
        st.session_state["active_name"] = active

    chosen = st.selectbox("Ch·ªçn dataset", options=names, index=names.index(active) if active in names else 0)
    st.session_state["active_name"] = chosen

    with st.expander("‚úèÔ∏è ƒê·ªïi t√™n dataset"):
        new_name = st.text_input("T√™n m·ªõi", value=chosen)
        if st.button("L∆∞u t√™n", use_container_width=True):
            new_name = _safe_name(new_name)
            if (new_name != chosen) and (new_name in st.session_state["datasets"]):
                st.error("T√™n ƒë√£ t·ªìn t·∫°i.")
            else:
                df_tmp = st.session_state["datasets"].pop(chosen)
                st.session_state["datasets"][new_name] = df_tmp

                hashes = st.session_state["key_to_hashes"].pop(chosen, set())
                st.session_state["key_to_hashes"][new_name] = hashes
                for h in list(hashes):
                    if st.session_state["hash_to_key"].get(h) == chosen:
                        st.session_state["hash_to_key"][h] = new_name

                st.session_state["active_name"] = new_name
                st.success("ƒê√£ ƒë·ªïi t√™n.")
                st.rerun()

    df_active = st.session_state["datasets"][st.session_state["active_name"]]
    summ_side = overall_summary(df_active)
    st.caption(f"rows={summ_side['S·ªë d√≤ng']} | bi·∫øn={summ_side['S·ªë bi·∫øn']} | thi·∫øu={summ_side['√î thi·∫øu (NA)']}")

    c1, c2 = st.columns([1, 1], gap="small")
    with c1:
        if st.button("Xo√°", use_container_width=True):
            _delete_dataset(chosen)
            remaining = list(st.session_state["datasets"].keys())
            st.session_state["active_name"] = remaining[0] if remaining else None
            st.session_state["last_result"] = None
            st.session_state["last_run_meta"] = None
            st.session_state["active_step"] = 1
            st.rerun()

    with c2:
        if st.button("Xo√° h·∫øt", use_container_width=True):
            st.session_state["datasets"] = {}
            st.session_state["active_name"] = None
            st.session_state["pending_tables"] = None
            st.session_state["pending_fname"] = None
            st.session_state["pending_file_hash"] = None
            st.session_state["hash_to_key"] = {}
            st.session_state["key_to_hashes"] = {}
            st.session_state["last_upload_hash"] = None
            st.session_state["last_result"] = None
            st.session_state["last_run_meta"] = None
            st.session_state["active_step"] = 1
            st.rerun()


# =========================
# Main data
# =========================
df = st.session_state["datasets"][st.session_state["active_name"]]
cols = df.columns.tolist()


# =========================
# Stepper
# =========================
st.markdown("## üß≠ C√°c b∆∞·ªõc")
b1, b2, b3 = st.columns(3, gap="small")

with b1:
    t = "primary" if st.session_state["active_step"] == 1 else "secondary"
    if st.button("1) üìÑ D·ªØ li·ªáu", type=t, use_container_width=True):
        st.session_state["active_step"] = 1
        st.rerun()
    st.caption("T·ªïng quan ‚Ä¢ xem b·∫£ng ‚Ä¢ danh s√°ch bi·∫øn")

with b2:
    t = "primary" if st.session_state["active_step"] == 2 else "secondary"
    if st.button("2) üéØ Ch·ªçn bi·∫øn", type=t, use_container_width=True):
        st.session_state["active_step"] = 2
        st.rerun()
    st.caption("Ch·ªçn Y/X ‚Ä¢ g·ª£i √Ω ‚Ä¢ b·∫•m Run")

with b3:
    t = "primary" if st.session_state["active_step"] == 3 else "secondary"
    if st.button("3) üìå K·∫øt qu·∫£", type=t, use_container_width=True):
        st.session_state["active_step"] = 3
        st.rerun()
    st.caption("B·∫£ng ‚Ä¢ bi·ªÉu ƒë·ªì ‚Ä¢ di·ªÖn gi·∫£i")

st.divider()


# =========================
# Compute & store results
# =========================
def _compute_and_store(y: str, xs: List[str], y_force: str, x_force: str, y_event: Optional[str]):
    # 1 X -> test
    if len(xs) == 1:
        suggestion, explanation, test_kind = suggest_single_x_test(df, y, xs[0], y_forced=y_force, x_forced=x_force)
        result_df, interp = run_single_x_test(df, y, xs[0], test_kind=test_kind)

        st.session_state["last_run_meta"] = {
            "dataset": st.session_state["active_name"],
            "mode": "test",
            "y": y,
            "xs": xs,
            "suggestion": suggestion,
            "explanation": explanation,
            "test_kind": test_kind,
            "y_force": y_force,
            "x_force": x_force,
        }
        st.session_state["last_result"] = {"table": result_df, "interp": interp}
        return

    # many X -> model
    tmp_for_suggest = df.copy()
    if y_force == "ƒê·ªãnh l∆∞·ª£ng (numeric)":
        tmp_for_suggest[y] = coerce_numeric(tmp_for_suggest[y])
    elif y_force == "Ph√¢n lo·∫°i (categorical)":
        tmp_for_suggest[y] = tmp_for_suggest[y].astype("string")

    suggestion, explanation = suggest_model(tmp_for_suggest, y, xs)

    df_model = df.copy()
    if y_force == "ƒê·ªãnh l∆∞·ª£ng (numeric)":
        df_model[y] = coerce_numeric(df_model[y])
    elif y_force == "Ph√¢n lo·∫°i (categorical)":
        df_model[y] = df_model[y].astype("string")

    formula, data_used, model_kind = build_formula(df_model, y, xs, y_binary_event=y_event)
    fit, note = run_model(formula, data_used, model_kind)
    kind = model_kind.split("||", 1)[0]

    table = None
    if kind == "ols":
        table = ols_table(fit)
    elif kind == "logit":
        table = logit_or_table(fit)

    st.session_state["last_run_meta"] = {
        "dataset": st.session_state["active_name"],
        "mode": "model",
        "y": y,
        "xs": xs,
        "suggestion": suggestion,
        "explanation": explanation,
        "formula": formula,
        "n_used": int(data_used.shape[0]),
        "model_kind": model_kind,
        "note": note,
        "y_force": y_force,
        "x_force": x_force,
        "y_event": y_event,
    }
    st.session_state["last_result"] = {"fit": fit, "kind": kind, "table": table, "data_used": data_used}


# =========================
# STEP 1: Data
# =========================
if st.session_state["active_step"] == 1:
    st.subheader("üìÑ D·ªØ li·ªáu")

    summ = overall_summary(df)
    m1, m2, m3, m4, m5 = st.columns(5, gap="small")
    m1.metric("D√≤ng", summ["S·ªë d√≤ng"])
    m2.metric("Bi·∫øn", summ["S·ªë bi·∫øn"])
    m3.metric("ƒê·ªãnh l∆∞·ª£ng", summ["Bi·∫øn ƒë·ªãnh l∆∞·ª£ng"])
    m4.metric("Ph√¢n lo·∫°i", summ["Bi·∫øn ph√¢n lo·∫°i"])
    m5.metric("NA", summ["√î thi·∫øu (NA)"])

    cL, cR = st.columns([1.2, 1.0], gap="small")
    with cL:
        st.markdown("### üëÄ Xem nhanh")
        st.dataframe(df.head(25), use_container_width=True, height=240)

    with cR:
        st.markdown("### üßæ Danh s√°ch bi·∫øn")
        q = st.text_input("T√¨m bi·∫øn", value="", placeholder="vd: age, weight...")
        filter_opt = st.selectbox("L·ªçc", ["T·∫•t c·∫£", "Ch·ªâ ƒë·ªãnh l∆∞·ª£ng", "Ch·ªâ ph√¢n lo·∫°i"], index=0)

        var_rows = [summarize_variable(df, c) for c in cols]
        var_df = pd.DataFrame(var_rows)

        if q.strip():
            var_df = var_df[var_df["T√™n bi·∫øn"].str.contains(q.strip(), case=False, na=False)].copy()

        if filter_opt == "Ch·ªâ ƒë·ªãnh l∆∞·ª£ng":
            var_df = var_df[var_df["ƒê·∫∑c t√≠nh bi·∫øn"].str.contains("ƒê·ªãnh l∆∞·ª£ng", na=False)]
        elif filter_opt == "Ch·ªâ ph√¢n lo·∫°i":
            var_df = var_df[var_df["ƒê·∫∑c t√≠nh bi·∫øn"].str.contains("Ph√¢n lo·∫°i", na=False)]

        st.dataframe(var_df, use_container_width=True, height=240)

    st.info("üëâ Sang **2) Ch·ªçn bi·∫øn** ƒë·ªÉ ch·ªçn Y/X v√† b·∫•m Run.")


# =========================
# STEP 2: Choose variables
# =========================
elif st.session_state["active_step"] == 2:
    st.subheader("üéØ Ch·ªçn bi·∫øn")

    left, right = st.columns([2.0, 1.0], gap="small")

    with left:
        vq = st.text_input("T√¨m bi·∫øn (tu·ª≥ ch·ªçn)", value="", placeholder="g√µ ƒë·ªÉ l·ªçc danh s√°ch...")
        cols_show = [c for c in cols if vq.lower() in c.lower()] if vq.strip() else cols
        if not cols_show:
            cols_show = cols

        y = st.selectbox("Bi·∫øn ph·ª• thu·ªôc (Y)", options=cols_show, index=0)
        xs = st.multiselect("Bi·∫øn ƒë·ªôc l·∫≠p (X)", options=[c for c in cols_show if c != y])

        force_opts = ["T·ª± ƒë·ªông", "ƒê·ªãnh l∆∞·ª£ng (numeric)", "Ph√¢n lo·∫°i (categorical)"]
        y_force = st.selectbox("Ki·ªÉu Y", options=force_opts, index=0)

        x_force = "T·ª± ƒë·ªông"
        if len(xs) == 1:
            x_force = st.selectbox("Ki·ªÉu X (ch·ªâ khi 1 X)", options=force_opts, index=0)

        y_event = None
        if var_kind(df[y], y_force) == "cat":
            levels = sorted(df[y].dropna().astype(str).unique().tolist())
            if len(levels) == 2:
                y_event = st.selectbox("S·ª± ki·ªán (Y=1) cho logistic", options=levels, index=1)

        st.markdown("### ‚úÖ G·ª£i √Ω")
        if len(xs) == 0:
            st.info("Ch·ªçn √≠t nh·∫•t 1 bi·∫øn X.")
        else:
            if len(xs) == 1:
                suggestion, explanation, _ = suggest_single_x_test(df, y, xs[0], y_forced=y_force, x_forced=x_force)
                mode_label = "Ki·ªÉm ƒë·ªãnh"
            else:
                tmp_for_suggest = df.copy()
                if y_force == "ƒê·ªãnh l∆∞·ª£ng (numeric)":
                    tmp_for_suggest[y] = coerce_numeric(tmp_for_suggest[y])
                elif y_force == "Ph√¢n lo·∫°i (categorical)":
                    tmp_for_suggest[y] = tmp_for_suggest[y].astype("string")
                suggestion, explanation = suggest_model(tmp_for_suggest, y, xs)
                mode_label = "M√¥ h√¨nh"

            st.write(f"**Ch·∫ø ƒë·ªô:** {mode_label}")
            st.write(f"**G·ª£i √Ω:** {suggestion}")
            with st.expander("Gi·∫£i th√≠ch"):
                st.write(explanation)

    with right:
        st.markdown("### üìå T√≥m t·∫Øt")
        st.write(f"**Dataset:** {st.session_state['active_name']}")
        st.write(f"**Bi·∫øn ph·ª• thu·ªôc (Y):** {y}")
        st.write(f"**Bi·∫øn ƒë·ªôc l·∫≠p (X):** {', '.join(xs) if xs else '-'}")

        st.markdown("---")
        if st.button("‚ñ∂Ô∏è Run", type="primary", use_container_width=True, disabled=(len(xs) == 0)):
            try:
                _compute_and_store(y=y, xs=xs, y_force=y_force, x_force=x_force, y_event=y_event)
                st.session_state["active_step"] = 3
                st.rerun()
            except Exception as e:
                st.error(f"L·ªói khi ch·∫°y: {e}")


# =========================
# STEP 3: Results
# =========================
else:
    st.subheader("üìå K·∫øt qu·∫£")

    meta = st.session_state.get("last_run_meta")
    res = st.session_state.get("last_result")

    if not meta or not res:
        st.info("Ch∆∞a c√≥ k·∫øt qu·∫£. V√†o **2) Ch·ªçn bi·∫øn** ‚Üí ch·ªçn Y/X ‚Üí b·∫•m **Run**.")
    else:
        y_name = meta.get("y", "-")
        x_list = meta.get("xs", [])
        x_text = ", ".join(x_list) if x_list else "-"

        st.markdown(
            f"""
            <div style="border:1px solid rgba(0,0,0,0.08); border-radius:12px; padding:10px;">
              <div style="display:flex; gap:12px; flex-wrap:wrap;">
                <div style="min-width:200px;">
                  <div style="color:#6b7280; font-size:12px;">Dataset</div>
                  <div style="font-size:15px; font-weight:800;">{meta.get('dataset','-')}</div>
                </div>
                <div style="min-width:220px;">
                  <div style="color:#6b7280; font-size:12px;">Bi·∫øn ph·ª• thu·ªôc (Y)</div>
                  <div style="font-size:15px; font-weight:800;">{y_name}</div>
                </div>
                <div style="min-width:320px; flex:1;">
                  <div style="color:#6b7280; font-size:12px;">Bi·∫øn ƒë·ªôc l·∫≠p (X)</div>
                  <div style="font-size:15px; font-weight:800;">{x_text}</div>
                </div>
              </div>
              <div style="margin-top:6px; color:#6b7280; font-size:12px;">G·ª£i √Ω</div>
              <div style="font-size:15px; font-weight:800;">{meta.get('suggestion','-')}</div>
            </div>
            """,
            unsafe_allow_html=True,
        )

        st.divider()

        left, right = st.columns([1.45, 1.0], gap="small")

        with left:
            if meta["mode"] == "test":
                st.markdown("### üìä K·∫øt qu·∫£ ki·ªÉm ƒë·ªãnh")
                st.dataframe(res["table"], use_container_width=True, height=260)

                st.markdown("### üîé Di·ªÖn gi·∫£i")
                st.write(res["interp"])

            else:
                kind = res["kind"]
                fit = res["fit"]
                table = res["table"]
                st.caption(meta.get("note", ""))

                if kind == "ols" and table is not None:
                    st.markdown("### üìä B·∫£ng k·∫øt qu·∫£ m√¥ h√¨nh (OLS)")
                    st.dataframe(table, use_container_width=True, height=270)

                    st.markdown("### üßÆ Ph∆∞∆°ng tr√¨nh h·ªìi quy")
                    st.write(format_ols_equation(fit, y_name))

                    st.markdown("### üîé Di·ªÖn gi·∫£i chi ti·∫øt (m·ªói bi·∫øn)")
                    st.write("\n".join(explain_ols_effects(fit, y_name, alpha=0.05)))

                elif kind == "logit" and table is not None:
                    st.markdown("### üìä B·∫£ng k·∫øt qu·∫£ logistic (OR)")
                    st.dataframe(table, use_container_width=True, height=270)
                    st.write(
                        "üîé **G·ª£i √Ω di·ªÖn gi·∫£i:**\n"
                        "- OR > 1: tƒÉng odds x·∫£y ra s·ª± ki·ªán (Y=1)\n"
                        "- OR < 1: gi·∫£m odds\n"
                        "- p-value < 0.05 v√† CI 95% kh√¥ng ch·ª©a 1: th∆∞·ªùng c√≥ √Ω nghƒ©a"
                    )

                else:
                    st.markdown("### üìÑ MNLogit Summary")
                    st.write(fit.summary())
                    st.info("Multinomial: n·∫øu b·∫°n mu·ªën b·∫£ng RRR = exp(coef) theo t·ª´ng nh√≥m, m√¨nh c√≥ th·ªÉ b·ªï sung ti·∫øp.")

        with right:
            st.markdown("### üìà Bi·ªÉu ƒë·ªì minh ho·∫°")
            try:
                if meta["mode"] == "test":
                    y = meta["y"]
                    x1 = meta["xs"][0]
                    y_force = meta.get("y_force", "T·ª± ƒë·ªông")
                    x_force = meta.get("x_force", "T·ª± ƒë·ªông")

                    yk = var_kind(df[y], y_force)
                    xk = var_kind(df[x1], x_force)
                    tmp = df[[y, x1]].dropna().copy()

                    if yk == "num" and xk == "cat":
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=x1, y=y, points="all", title=f"{y} theo nh√≥m {x1}", height=320)
                        st.plotly_chart(fig, use_container_width=True)

                    elif yk == "cat" and xk == "num":
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=y, y=x1, points="all", title=f"{x1} theo nh√≥m {y}", height=320)
                        st.plotly_chart(fig, use_container_width=True)

                    elif yk == "cat" and xk == "cat":
                        tab = pd.crosstab(tmp[y].astype(str), tmp[x1].astype(str))
                        tab2 = tab.div(tab.sum(axis=1), axis=0).reset_index().melt(
                            id_vars=[y], var_name=x1, value_name="T·ª∑ l·ªá"
                        )
                        fig = px.bar(tab2, x=y, y="T·ª∑ l·ªá", color=x1, barmode="stack", title="T·ª∑ l·ªá theo nh√≥m", height=320)
                        st.plotly_chart(fig, use_container_width=True)

                    else:
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.scatter(tmp, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1}", height=320)
                        st.plotly_chart(fig, use_container_width=True)

                else:
                    kind = res["kind"]
                    data_used = res["data_used"]
                    y = meta["y"]
                    xs = meta["xs"]

                    if kind == "ols":
                        x1 = xs[0]
                        if (not is_categorical(data_used[x1])) and (not is_categorical(data_used[y])):
                            fig = px.scatter(data_used, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1}", height=320)
                        else:
                            fig = (
                                px.box(data_used, x=x1, y=y, points="all", title=f"{y} theo nh√≥m {x1}", height=320)
                                if is_categorical(data_used[x1])
                                else px.scatter(data_used, x=x1, y=y, title=f"{y} theo {x1}", height=320)
                            )
                        st.plotly_chart(fig, use_container_width=True)

                    elif kind == "logit":
                        p = res["fit"].predict()
                        fig = px.histogram(p, nbins=22, title="X√°c su·∫•t d·ª± ƒëo√°n (p)", height=320)
                        st.plotly_chart(fig, use_container_width=True)

                    else:
                        st.info("Multinomial: bi·ªÉu ƒë·ªì s·∫Ω ƒë∆∞·ª£c b·ªï sung theo nhu c·∫ßu.")
            except Exception as e:
                st.warning(f"Kh√¥ng v·∫Ω ƒë∆∞·ª£c bi·ªÉu ƒë·ªì: {e}")

    st.divider()
    st.caption(
        "‚ö†Ô∏è L∆∞u √Ω: C√¥ng c·ª• h·ªó tr·ª£ g·ª£i √Ω v√† ch·∫°y ki·ªÉm ƒë·ªãnh/m√¥ h√¨nh c∆° b·∫£n. "
        "Ng∆∞·ªùi d√πng c·∫ßn ki·ªÉm tra gi·∫£ ƒë·ªãnh, thi·∫øt k·∫ø nghi√™n c·ª©u v√† m√£ ho√° bi·∫øn ƒë·ªÉ di·ªÖn gi·∫£i ƒë√∫ng."
    )
