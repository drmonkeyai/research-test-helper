import io
import re
import tempfile
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from scipy import stats
import statsmodels.formula.api as smf


# =========================
# App config
# =========================
st.set_page_config(
    page_title="Há»— trá»£ nghiÃªn cá»©u cho bÃ¡c sÄ© gia Ä‘Ã¬nh",
    page_icon="ğŸ”¬",
    layout="wide",
)
APP_TITLE = "Há»— trá»£ nghiÃªn cá»©u cho bÃ¡c sÄ© gia Ä‘Ã¬nh"


# =========================
# UI CSS: big step buttons
# =========================
st.markdown(
    """
    <style>
    /* LÃ m nÃºt to hÆ¡n */
    div.stButton > button {
        width: 100%;
        padding: 16px 14px !important;
        border-radius: 14px !important;
        font-size: 18px !important;
        font-weight: 700 !important;
        border: 1px solid rgba(0,0,0,0.12) !important;
        box-shadow: 0 1px 8px rgba(0,0,0,0.06) !important;
    }
    /* Caption nhá» dÆ°á»›i nÃºt */
    .step-caption {
        color: #6b7280;
        font-size: 13px;
        margin-top: -6px;
        margin-bottom: 4px;
        line-height: 1.25rem;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


# =========================
# Helpers: safe name + hashing
# =========================
def _safe_name(name: str) -> str:
    return re.sub(r"[^a-zA-Z0-9_]+", "_", str(name).strip())[:80] or "file"


def _file_sha256(raw: bytes) -> str:
    return hashlib.sha256(raw).hexdigest()


def _df_sha256(df: pd.DataFrame) -> str:
    h = pd.util.hash_pandas_object(df, index=True).values.tobytes()
    return hashlib.sha256(h).hexdigest()


# =========================
# Helpers: read files
# =========================
def read_csv_safely(uploaded_file) -> pd.DataFrame:
    raw = uploaded_file.getvalue()
    encodings = ["utf-8-sig", "utf-8", "cp1258", "cp1252", "latin1"]
    last_err = None
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(raw), encoding=enc)
        except Exception as e:
            last_err = e
    raise last_err


def _read_via_tempfile(raw: bytes, suffix: str, reader_fn):
    """
    Nhiá»u hÃ m (read_spss/read_stata/pyreadr) cáº§n path -> dÃ¹ng file táº¡m.
    """
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(raw)
            tmp_path = tmp.name
        return reader_fn(tmp_path)
    finally:
        if tmp_path:
            try:
                Path(tmp_path).unlink(missing_ok=True)
            except Exception:
                pass


def read_file_safely(uploaded_file) -> Dict[str, pd.DataFrame]:
    """
    Return dict {table_name: df}

    Supported:
      - .csv
      - .xlsx (openpyxl)
      - .xls  (xlrd)
      - .sav/.zsav (SPSS) via pandas.read_spss(path)
      - .dta (STATA) via pandas.read_stata(path)
      - .rds (R) via pyreadr (optional)
    """
    name = uploaded_file.name
    ext = Path(name).suffix.lower()
    raw = uploaded_file.getvalue()

    if ext == ".csv":
        return {"data": read_csv_safely(uploaded_file)}

    if ext == ".xlsx":
        xls = pd.ExcelFile(io.BytesIO(raw), engine="openpyxl")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh)
        return out

    if ext == ".xls":
        xls = pd.ExcelFile(io.BytesIO(raw), engine="xlrd")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh, engine="xlrd")
        return out

    if ext in [".sav", ".zsav"]:
        df = _read_via_tempfile(raw, ext, pd.read_spss)
        return {"data": df}

    if ext == ".dta":
        df = _read_via_tempfile(raw, ".dta", pd.read_stata)
        return {"data": df}

    if ext == ".rds":
        try:
            import pyreadr  # type: ignore
        except Exception as e:
            raise RuntimeError("Thiáº¿u thÆ° viá»‡n pyreadr Ä‘á»ƒ Ä‘á»c .rds. HÃ£y cÃ i: pip install pyreadr") from e

        def _read_rds(path: str):
            res = pyreadr.read_r(path)
            out: Dict[str, pd.DataFrame] = {}
            for k, v in res.items():
                if isinstance(v, pd.DataFrame):
                    out[str(k) if k else "data"] = v
            return out

        out = _read_via_tempfile(raw, ".rds", _read_rds)
        if not out:
            raise RuntimeError("File .rds khÃ´ng chá»©a DataFrame (hoáº·c object khÃ´ng há»— trá»£).")
        return out

    raise RuntimeError(f"Äá»‹nh dáº¡ng {ext} chÆ°a Ä‘Æ°á»£c há»— trá»£.")


# =========================
# Helpers: type detection
# =========================
def is_categorical(s: pd.Series) -> bool:
    if pd.api.types.is_bool_dtype(s) or pd.api.types.is_object_dtype(s) or pd.api.types.is_categorical_dtype(s):
        return True
    if pd.api.types.is_numeric_dtype(s):
        nunique = s.dropna().nunique()
        if nunique <= 10:
            return True
    return False


def coerce_numeric(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")


def var_kind(s: pd.Series, forced: str = "Tá»± Ä‘á»™ng") -> str:
    if forced == "Äá»‹nh lÆ°á»£ng (numeric)":
        return "num"
    if forced == "PhÃ¢n loáº¡i (categorical)":
        return "cat"
    return "cat" if is_categorical(s) else "num"


# =========================
# Summaries
# =========================
def summarize_variable(df: pd.DataFrame, col: str) -> Dict[str, str]:
    s = df[col]
    miss = int(s.isna().sum())
    n = int(len(s))
    nunique = int(s.dropna().nunique())

    if is_categorical(s):
        vc = s.astype("string").value_counts(dropna=True).head(3)
        top = ", ".join([f"{idx} ({val})" for idx, val in vc.items()]) if len(vc) else "-"
        return {
            "TÃªn biáº¿n": col,
            "Äáº·c tÃ­nh biáº¿n": f"PhÃ¢n loáº¡i | má»©c={nunique} | thiáº¿u={miss}/{n} | top: {top}",
        }

    x = coerce_numeric(s)
    x_non = x.dropna()
    if len(x_non) == 0:
        return {"TÃªn biáº¿n": col, "Äáº·c tÃ­nh biáº¿n": f"Äá»‹nh lÆ°á»£ng | thiáº¿u={miss}/{n} | (khÃ´ng Ä‘á»c Ä‘Æ°á»£c sá»‘)"}

    mean = float(x_non.mean())
    sd = float(x_non.std(ddof=1)) if len(x_non) >= 2 else float("nan")
    med = float(x_non.median())
    q1 = float(x_non.quantile(0.25))
    q3 = float(x_non.quantile(0.75))
    return {
        "TÃªn biáº¿n": col,
        "Äáº·c tÃ­nh biáº¿n": f"Äá»‹nh lÆ°á»£ng | thiáº¿u={miss}/{n} | mean={mean:.2f}, SD={sd:.2f} | median={med:.2f} (IQR {q1:.2f}-{q3:.2f})",
    }


def overall_summary(df: pd.DataFrame) -> Dict[str, int]:
    n_rows = int(df.shape[0])
    n_cols = int(df.shape[1])
    missing_cells = int(df.isna().sum().sum())
    numeric_cols = sum([pd.api.types.is_numeric_dtype(df[c]) and (not is_categorical(df[c])) for c in df.columns])
    cat_cols = n_cols - numeric_cols
    return {
        "Sá»‘ dÃ²ng": n_rows,
        "Sá»‘ biáº¿n": n_cols,
        "Biáº¿n Ä‘á»‹nh lÆ°á»£ng": int(numeric_cols),
        "Biáº¿n phÃ¢n loáº¡i": int(cat_cols),
        "Ã” thiáº¿u (NA)": missing_cells,
    }


# =========================
# Assumptions: normality & homogeneity
# =========================
def normality_pvalue(x: np.ndarray) -> float:
    x = x[~np.isnan(x)]
    n = len(x)
    if n < 3:
        return float("nan")
    try:
        if n <= 5000:
            return float(stats.shapiro(x).pvalue)
        return float(stats.normaltest(x).pvalue)
    except Exception:
        return float("nan")


def variance_homogeneity_pvalue(groups: List[np.ndarray]) -> float:
    clean = [g[~np.isnan(g)] for g in groups if len(g[~np.isnan(g)]) >= 2]
    if len(clean) < 2:
        return float("nan")
    try:
        return float(stats.levene(*clean, center="median").pvalue)
    except Exception:
        return float("nan")


def assumption_report_num_by_group(df: pd.DataFrame, y_num: str, group_cat: str) -> dict:
    tmp = df[[y_num, group_cat]].dropna().copy()
    tmp[y_num] = pd.to_numeric(tmp[y_num], errors="coerce")
    tmp = tmp.dropna()

    levels = sorted(tmp[group_cat].astype(str).unique().tolist())
    arrays = []
    norm_p = {}
    ns = {}

    for lv in levels:
        a = tmp.loc[tmp[group_cat].astype(str) == lv, y_num].to_numpy()
        a = a[~np.isnan(a)]
        arrays.append(a)
        ns[lv] = int(len(a))
        norm_p[lv] = normality_pvalue(a)

    lev_p = variance_homogeneity_pvalue(arrays)
    return {
        "levels": levels,
        "n": ns,
        "normality_p": norm_p,
        "levene_p": lev_p,
        "total_n": int(tmp.shape[0]),
    }


def _norm_ok(report: dict, alpha: float = 0.05) -> bool:
    for lv, n in report["n"].items():
        if n < 3:
            return False
        p = report["normality_p"].get(lv, float("nan"))
        if np.isnan(p) or p < alpha:
            return False
    return True


def _var_ok(report: dict, alpha: float = 0.05) -> bool:
    p = report.get("levene_p", float("nan"))
    return (not np.isnan(p)) and (p >= alpha)


def _assumption_text(rep: dict) -> str:
    norm = ", ".join(
        [
            f"{k}: p={rep['normality_p'][k]:.4f}" if not np.isnan(rep["normality_p"][k]) else f"{k}: p=NA"
            for k in rep["levels"]
        ]
    )
    lev = rep.get("levene_p", float("nan"))
    lev_s = f"{lev:.4f}" if not np.isnan(lev) else "NA"
    return f"Giáº£ Ä‘á»‹nh: Shapiro theo nhÃ³m [{norm}]; Levene p={lev_s}."


# =========================
# Single-X: suggest + run
# =========================
def suggest_single_x_test(
    df: pd.DataFrame,
    y: str,
    x: str,
    y_forced: str = "Tá»± Ä‘á»™ng",
    x_forced: str = "Tá»± Ä‘á»™ng",
) -> Tuple[str, str, str]:
    yk = var_kind(df[y], y_forced)
    xk = var_kind(df[x], x_forced)

    tmp = df[[y, x]].dropna()
    if tmp.shape[0] < 3:
        return ("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u", "Sau khi loáº¡i NA, sá»‘ dÃ²ng quÃ¡ Ã­t Ä‘á»ƒ kiá»ƒm Ä‘á»‹nh.", "none")

    # cat-cat
    if yk == "cat" and xk == "cat":
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape == (2, 2) and (tab.values < 5).any():
            return ("Fisher exact (2x2)", "Báº£ng 2x2 vÃ  cÃ³ Ã´ nhá» â†’ Æ°u tiÃªn Fisher exact.", "fisher_2x2")
        return ("Chi-bÃ¬nh phÆ°Æ¡ng (Chi-square)", "X vÃ  Y Ä‘á»u phÃ¢n loáº¡i â†’ kiá»ƒm Ä‘á»‹nh Ä‘á»™c láº­p báº±ng Chi-square.", "chisq")

    # y num, x cat
    if yk == "num" and xk == "cat":
        rep = assumption_report_num_by_group(df, y_num=y, group_cat=x)
        n_levels = len(rep["levels"])
        norm_ok = _norm_ok(rep)
        var_ok = _var_ok(rep)

        if n_levels == 2:
            if norm_ok and var_ok:
                return ("t-test (Student)", "2 nhÃ³m, Ä‘áº¡t chuáº©n & phÆ°Æ¡ng sai tÆ°Æ¡ng Ä‘Æ°Æ¡ng â†’ Student t-test.", "ttest_student")
            if norm_ok and (not var_ok):
                return ("t-test (Welch)", "2 nhÃ³m, chuáº©n nhÆ°ng phÆ°Æ¡ng sai khÃ¡c â†’ Welch t-test.", "ttest_welch")
            return ("Mannâ€“Whitney U", "2 nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh chuáº©n â†’ Mannâ€“Whitney.", "mwu")

        if norm_ok and var_ok:
            return ("ANOVA má»™t yáº¿u tá»‘", "Nhiá»u nhÃ³m, Ä‘áº¡t chuáº©n & Ä‘á»“ng nháº¥t phÆ°Æ¡ng sai â†’ one-way ANOVA.", "anova")
        return ("Kruskalâ€“Wallis", "Nhiá»u nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh â†’ Kruskalâ€“Wallis.", "kruskal")

    # y cat, x num (swap)
    if yk == "cat" and xk == "num":
        rep = assumption_report_num_by_group(df, y_num=x, group_cat=y)
        n_levels = len(rep["levels"])
        norm_ok = _norm_ok(rep)
        var_ok = _var_ok(rep)

        if n_levels == 2:
            if norm_ok and var_ok:
                return ("t-test (Student)", "2 nhÃ³m, Ä‘áº¡t chuáº©n & phÆ°Æ¡ng sai tÆ°Æ¡ng Ä‘Æ°Æ¡ng â†’ Student t-test.", "ttest_student_swapped")
            if norm_ok and (not var_ok):
                return ("t-test (Welch)", "2 nhÃ³m, chuáº©n nhÆ°ng phÆ°Æ¡ng sai khÃ¡c â†’ Welch t-test.", "ttest_welch_swapped")
            return ("Mannâ€“Whitney U", "2 nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh chuáº©n â†’ Mannâ€“Whitney.", "mwu_swapped")

        if norm_ok and var_ok:
            return ("ANOVA má»™t yáº¿u tá»‘", "Nhiá»u nhÃ³m, Ä‘áº¡t chuáº©n & Ä‘á»“ng nháº¥t phÆ°Æ¡ng sai â†’ one-way ANOVA.", "anova_swapped")
        return ("Kruskalâ€“Wallis", "Nhiá»u nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh â†’ Kruskalâ€“Wallis.", "kruskal_swapped")

    # num-num: Pearson vs Spearman
    if yk == "num" and xk == "num":
        tmp2 = df[[y, x]].copy()
        tmp2[y] = coerce_numeric(tmp2[y])
        tmp2[x] = coerce_numeric(tmp2[x])
        tmp2 = tmp2.dropna()
        if tmp2.shape[0] < 3:
            return ("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u", "KhÃ´ng Ä‘á»§ dÃ²ng sá»‘ Ä‘á»ƒ tÃ­nh tÆ°Æ¡ng quan.", "none")

        pny = normality_pvalue(tmp2[y].to_numpy())
        pnx = normality_pvalue(tmp2[x].to_numpy())
        if (not np.isnan(pny)) and (not np.isnan(pnx)) and (pny >= 0.05) and (pnx >= 0.05):
            return ("TÆ°Æ¡ng quan Pearson", "X vÃ  Y gáº§n chuáº©n â†’ Pearson correlation.", "corr_pearson")
        return ("TÆ°Æ¡ng quan Spearman", "X hoáº·c Y khÃ´ng chuáº©n/ordinal â†’ Spearman correlation.", "corr_spearman")

    return ("KhÃ´ng xÃ¡c Ä‘á»‹nh", "KhÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c phÃ©p kiá»ƒm phÃ¹ há»£p tá»« kiá»ƒu biáº¿n hiá»‡n táº¡i.", "none")


def _cohens_d(a: np.ndarray, b: np.ndarray) -> float:
    a = a[~np.isnan(a)]
    b = b[~np.isnan(b)]
    if len(a) < 2 or len(b) < 2:
        return float("nan")
    va = np.var(a, ddof=1)
    vb = np.var(b, ddof=1)
    sp = np.sqrt(((len(a) - 1) * va + (len(b) - 1) * vb) / (len(a) + len(b) - 2))
    if sp == 0:
        return float("nan")
    return (np.mean(a) - np.mean(b)) / sp


def _cramers_v(tab: pd.DataFrame) -> float:
    chi2, p, dof, exp = stats.chi2_contingency(tab.values)
    n = tab.values.sum()
    if n == 0:
        return float("nan")
    r, k = tab.shape
    return np.sqrt(chi2 / (n * (min(r, k) - 1))) if min(r, k) > 1 else float("nan")


def run_single_x_test(df: pd.DataFrame, y: str, x: str, test_kind: str) -> Tuple[pd.DataFrame, str]:
    # cat-cat
    if test_kind == "chisq":
        tmp = df[[y, x]].dropna()
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        chi2, p, dof, exp = stats.chi2_contingency(tab.values)
        v = _cramers_v(tab)
        out = pd.DataFrame({"Chá»‰ sá»‘": ["Chi2", "df", "p-value", "Cramer's V"], "GiÃ¡ trá»‹": [chi2, dof, p, v]})
        interp = "Diá»…n giáº£i: p-value nhá» gá»£i Ã½ X vÃ  Y cÃ³ liÃªn quan. Cramer's V Ä‘Ã¡nh giÃ¡ Ä‘á»™ máº¡nh liÃªn quan."
        return out, interp

    if test_kind == "fisher_2x2":
        tmp = df[[y, x]].dropna()
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape != (2, 2):
            raise ValueError("Fisher exact chá»‰ Ã¡p dá»¥ng báº£ng 2x2.")
        oddsratio, p = stats.fisher_exact(tab.values)
        out = pd.DataFrame({"Chá»‰ sá»‘": ["Odds ratio", "p-value"], "GiÃ¡ trá»‹": [oddsratio, p]})
        interp = "Diá»…n giáº£i: p-value nhá» gá»£i Ã½ cÃ³ liÃªn quan giá»¯a 2 biáº¿n phÃ¢n loáº¡i. Odds ratio diá»…n giáº£i theo nhÃ³m tham chiáº¿u."
        return out, interp

    # y numeric, x categorical
    if test_kind in ("ttest_student", "ttest_welch", "mwu", "anova", "kruskal"):
        tmp = df[[y, x]].dropna().copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp = tmp.dropna()
        groups = tmp[x].astype(str)
        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, y].to_numpy() for lv in levels]
        rep = assumption_report_num_by_group(df, y_num=y, group_cat=x)
        assump = _assumption_text(rep)

        if test_kind in ("ttest_student", "ttest_welch"):
            if len(levels) != 2:
                raise ValueError("t-test cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            equal_var = (test_kind == "ttest_student")
            tstat, p = stats.ttest_ind(a, b, equal_var=equal_var, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["t", "p-value", "Cohen's d"], "GiÃ¡ trá»‹": [tstat, p, d]})
            interp = f"{assump}\nDiá»…n giáº£i: p-value nhá» gá»£i Ã½ trung bÃ¬nh Y khÃ¡c nhau giá»¯a 2 nhÃ³m. Cohenâ€™s d lÃ  effect size."
            return out, interp

        if test_kind == "mwu":
            if len(levels) != 2:
                raise ValueError("Mannâ€“Whitney cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            u, p = stats.mannwhitneyu(a, b, alternative="two-sided")
            out = pd.DataFrame({"Chá»‰ sá»‘": ["U", "p-value"], "GiÃ¡ trá»‹": [u, p]})
            interp = f"{assump}\nDiá»…n giáº£i: Mannâ€“Whitney dÃ¹ng khi dá»¯ liá»‡u khÃ´ng Ä‘áº¡t chuáº©n."
            return out, interp

        if test_kind == "anova":
            f, p = stats.f_oneway(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["F", "p-value"], "GiÃ¡ trá»‹": [f, p]})
            interp = f"{assump}\nDiá»…n giáº£i: p-value nhá» gá»£i Ã½ cÃ³ Ã­t nháº¥t 1 nhÃ³m khÃ¡c trung bÃ¬nh; nÃªn lÃ m post-hoc."
            return out, interp

        if test_kind == "kruskal":
            h, p = stats.kruskal(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["H (Kruskal)", "p-value"], "GiÃ¡ trá»‹": [h, p]})
            interp = f"{assump}\nDiá»…n giáº£i: Kruskalâ€“Wallis dÃ¹ng khi khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh; náº¿u cÃ³ Ã½ nghÄ©a nÃªn lÃ m post-hoc."
            return out, interp

    # swapped: x numeric by y groups
    if test_kind in ("ttest_student_swapped", "ttest_welch_swapped", "mwu_swapped", "anova_swapped", "kruskal_swapped"):
        tmp = df[[y, x]].dropna().copy()
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        groups = tmp[y].astype(str)
        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, x].to_numpy() for lv in levels]
        rep = assumption_report_num_by_group(df, y_num=x, group_cat=y)
        assump = _assumption_text(rep)

        base_kind = test_kind.replace("_swapped", "")
        if base_kind in ("ttest_student", "ttest_welch"):
            if len(levels) != 2:
                raise ValueError("t-test cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            equal_var = (base_kind == "ttest_student")
            tstat, p = stats.ttest_ind(a, b, equal_var=equal_var, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["t", "p-value", "Cohen's d"], "GiÃ¡ trá»‹": [tstat, p, d]})
            interp = f"{assump}\nDiá»…n giáº£i: p-value nhá» gá»£i Ã½ trung bÃ¬nh X khÃ¡c nhau giá»¯a 2 nhÃ³m Y."
            return out, interp

        if base_kind == "mwu":
            if len(levels) != 2:
                raise ValueError("Mannâ€“Whitney cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            u, p = stats.mannwhitneyu(a, b, alternative="two-sided")
            out = pd.DataFrame({"Chá»‰ sá»‘": ["U", "p-value"], "GiÃ¡ trá»‹": [u, p]})
            interp = f"{assump}\nDiá»…n giáº£i: Mannâ€“Whitney dÃ¹ng khi dá»¯ liá»‡u khÃ´ng Ä‘áº¡t chuáº©n."
            return out, interp

        if base_kind == "anova":
            f, p = stats.f_oneway(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["F", "p-value"], "GiÃ¡ trá»‹": [f, p]})
            interp = f"{assump}\nDiá»…n giáº£i: p-value nhá» gá»£i Ã½ cÃ³ Ã­t nháº¥t 1 nhÃ³m khÃ¡c trung bÃ¬nh; nÃªn lÃ m post-hoc."
            return out, interp

        if base_kind == "kruskal":
            h, p = stats.kruskal(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["H (Kruskal)", "p-value"], "GiÃ¡ trá»‹": [h, p]})
            interp = f"{assump}\nDiá»…n giáº£i: Kruskalâ€“Wallis dÃ¹ng khi khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh; nÃªn lÃ m post-hoc."
            return out, interp

    # correlation
    if test_kind == "corr_pearson":
        tmp = df[[y, x]].copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        r, p = stats.pearsonr(tmp[x].to_numpy(), tmp[y].to_numpy())
        pny = normality_pvalue(tmp[y].to_numpy())
        pnx = normality_pvalue(tmp[x].to_numpy())
        out = pd.DataFrame(
            {"Chá»‰ sá»‘": ["Pearson r", "p-value", "n", "Shapiro p(Y)", "Shapiro p(X)"], "GiÃ¡ trá»‹": [r, p, tmp.shape[0], pny, pnx]}
        )
        interp = "Diá»…n giáº£i: r gáº§n 0 â†’ yáº¿u; gáº§n Â±1 â†’ máº¡nh. p-value nhá» gá»£i Ã½ liÃªn quan tuyáº¿n tÃ­nh cÃ³ Ã½ nghÄ©a."
        return out, interp

    if test_kind == "corr_spearman":
        tmp = df[[y, x]].copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        rho, p = stats.spearmanr(tmp[x].to_numpy(), tmp[y].to_numpy())
        pny = normality_pvalue(tmp[y].to_numpy())
        pnx = normality_pvalue(tmp[x].to_numpy())
        out = pd.DataFrame(
            {"Chá»‰ sá»‘": ["Spearman rho", "p-value", "n", "Shapiro p(Y)", "Shapiro p(X)"], "GiÃ¡ trá»‹": [rho, p, tmp.shape[0], pny, pnx]}
        )
        interp = "Diá»…n giáº£i: Spearman Ä‘Ã¡nh giÃ¡ liÃªn quan Ä‘Æ¡n Ä‘iá»‡u (khÃ´ng cáº§n chuáº©n), phÃ¹ há»£p khi dá»¯ liá»‡u khÃ´ng chuáº©n/ordinal."
        return out, interp

    raise ValueError("KhÃ´ng cÃ³ kiá»ƒm Ä‘á»‹nh phÃ¹ há»£p (test_kind=none).")


# =========================
# Model: suggest + build + run
# =========================
def suggest_model(df: pd.DataFrame, y: str, xs: List[str]) -> Tuple[str, str]:
    y_s = df[y]
    if is_categorical(y_s):
        n_levels = int(y_s.dropna().nunique())
        if n_levels <= 1:
            return ("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u", "Biáº¿n phá»¥ thuá»™c chá»‰ cÃ³ 0â€“1 má»©c sau khi loáº¡i thiáº¿u. HÃ£y kiá»ƒm tra dá»¯ liá»‡u.")
        if n_levels == 2:
            return (
                "Há»“i quy Logistic nhá»‹ phÃ¢n (Binary Logistic)",
                "Y phÃ¢n loáº¡i 2 má»©c â†’ logistic nhá»‹ phÃ¢n Ä‘á»ƒ Æ°á»›c lÆ°á»£ng OR vÃ  p-value khi cÃ³ nhiá»u biáº¿n Ä‘á»™c láº­p.",
            )
        return (
            "Há»“i quy Logistic Ä‘a danh (Multinomial Logistic)",
            f"Y phÃ¢n loáº¡i >2 má»©c (má»©c={n_levels}) â†’ logistic Ä‘a danh (multinomial).",
        )
    return ("Há»“i quy tuyáº¿n tÃ­nh (OLS)", "Y Ä‘á»‹nh lÆ°á»£ng â†’ há»“i quy tuyáº¿n tÃ­nh (OLS).")


def build_formula(
    df: pd.DataFrame,
    y: str,
    xs: List[str],
    y_binary_event: Optional[str] = None,
) -> Tuple[str, pd.DataFrame, str]:
    tmp = df[[y] + xs].copy().dropna()

    if is_categorical(tmp[y]):
        n_levels = int(tmp[y].nunique())

        if n_levels == 2:
            y_cat = tmp[y].astype("category")
            cats = list(y_cat.cat.categories)
            event = y_binary_event if (y_binary_event in cats) else cats[1]
            tmp["_y01_"] = (tmp[y] == event).astype(int)

            terms = []
            for x in xs:
                terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

            formula = "_y01_ ~ " + " + ".join(terms)
            return formula, tmp, f"logit||Logistic nhá»‹ phÃ¢n: sá»± kiá»‡n (Y=1)='{event}'"

        tmp["_ycat_"] = tmp[y].astype("category")
        tmp["_ycode_"] = tmp["_ycat_"].cat.codes

        terms = []
        for x in xs:
            terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

        formula = "_ycode_ ~ " + " + ".join(terms)
        return formula, tmp, "mnlogit||Multinomial: há»‡ sá»‘ theo nhÃ³m tham chiáº¿u"

    tmp[y] = coerce_numeric(tmp[y])
    tmp = tmp.dropna()

    terms = []
    for x in xs:
        terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

    formula = f"Q('{y}') ~ " + " + ".join(terms)
    return formula, tmp, "ols||OLS"


def run_model(formula: str, data_used: pd.DataFrame, model_kind: str):
    kind, note = model_kind.split("||", 1)
    if kind == "ols":
        return smf.ols(formula=formula, data=data_used).fit(), note
    if kind == "logit":
        return smf.logit(formula=formula, data=data_used).fit(disp=0), note
    if kind == "mnlogit":
        return smf.mnlogit(formula=formula, data=data_used).fit(disp=0), note
    raise ValueError("Unknown model kind")


def ols_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame({"Há»‡ sá»‘": fit.params, "CI 2.5%": conf[0], "CI 97.5%": conf[1], "p-value": fit.pvalues})
    out.index.name = "Biáº¿n"
    return out.sort_values("p-value")


def logit_or_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame(
        {"OR": np.exp(fit.params), "CI 2.5%": np.exp(conf[0]), "CI 97.5%": np.exp(conf[1]), "p-value": fit.pvalues}
    )
    out.index.name = "Biáº¿n"
    return out.sort_values("p-value")


# =========================
# Session state: datasets + dedupe + stepper
# =========================
if "datasets" not in st.session_state:
    st.session_state["datasets"] = {}  # key -> df
if "active_name" not in st.session_state:
    st.session_state["active_name"] = None

if "pending_tables" not in st.session_state:
    st.session_state["pending_tables"] = None
if "pending_fname" not in st.session_state:
    st.session_state["pending_fname"] = None
if "pending_file_hash" not in st.session_state:
    st.session_state["pending_file_hash"] = None

if "hash_to_key" not in st.session_state:
    st.session_state["hash_to_key"] = {}  # hash -> dataset key
if "key_to_hashes" not in st.session_state:
    st.session_state["key_to_hashes"] = {}  # dataset key -> set(hashes)
if "last_upload_hash" not in st.session_state:
    st.session_state["last_upload_hash"] = None

if "last_result" not in st.session_state:
    st.session_state["last_result"] = None
if "last_run_meta" not in st.session_state:
    st.session_state["last_run_meta"] = None

if "active_step" not in st.session_state:
    st.session_state["active_step"] = 1  # 1=Data,2=Choose,3=Results


def _register_dataset(key: str, df: pd.DataFrame, hashes: List[str]):
    st.session_state["datasets"][key] = df
    st.session_state["active_name"] = key
    st.session_state["key_to_hashes"].setdefault(key, set())
    for h in hashes:
        st.session_state["hash_to_key"][h] = key
        st.session_state["key_to_hashes"][key].add(h)


def _delete_dataset(key: str):
    st.session_state["datasets"].pop(key, None)
    hashes = st.session_state["key_to_hashes"].pop(key, set())
    for h in list(hashes):
        if st.session_state["hash_to_key"].get(h) == key:
            st.session_state["hash_to_key"].pop(h, None)


# =========================
# UI Header
# =========================
st.markdown(
    f"""
    <div style="padding: 0.25rem 0 0.5rem 0;">
      <h1 style="margin:0;">{APP_TITLE}</h1>
      <div style="color:#6b7280;">
        Upload dá»¯ liá»‡u â†’ chá»n biáº¿n â†’ kiá»ƒm Ä‘á»‹nh (1 X) hoáº·c mÃ´ hÃ¬nh (nhiá»u X) â†’ káº¿t quáº£ + giáº£i thÃ­ch
      </div>
    </div>
    """,
    unsafe_allow_html=True,
)


# =========================
# Sidebar: Upload & Dataset manager
# =========================
with st.sidebar:
    st.markdown("## ğŸ§ª Dá»¯ liá»‡u")

    up = st.file_uploader(
        "â¬†ï¸ Upload dá»¯ liá»‡u",
        type=["csv", "xlsx", "xls", "sav", "zsav", "dta", "rds"],
        accept_multiple_files=False,
    )

    if up is not None:
        try:
            raw = up.getvalue()
            file_hash = _file_sha256(raw)

            # trÃ¡nh rerun add láº¡i
            if st.session_state["last_upload_hash"] != file_hash:
                st.session_state["last_upload_hash"] = file_hash

                # file Ä‘Ã£ cÃ³
                if file_hash in st.session_state["hash_to_key"]:
                    existed_key = st.session_state["hash_to_key"][file_hash]
                    st.session_state["active_name"] = existed_key
                    st.info(f"ÄÃ£ cÃ³ trÆ°á»›c Ä‘Ã³ â†’ chuyá»ƒn sang: {existed_key}")
                else:
                    tables = read_file_safely(up)

                    # nhiá»u sheet/object
                    if len(tables) > 1:
                        st.session_state["pending_tables"] = tables
                        st.session_state["pending_fname"] = up.name
                        st.session_state["pending_file_hash"] = file_hash
                        st.info(f"File cÃ³ {len(tables)} báº£ng. Chá»n 1 báº£ng Ä‘á»ƒ nháº­p.")
                    else:
                        df_new = list(tables.values())[0]
                        base = _safe_name(Path(up.name).stem)
                        key = base
                        i = 2
                        while key in st.session_state["datasets"]:
                            key = f"{base}_{i}"
                            i += 1

                        df_hash = _df_sha256(df_new)
                        _register_dataset(key, df_new, hashes=[file_hash, df_hash])
                        st.session_state["active_step"] = 1
                        st.success(f"ÄÃ£ táº£i: {key} ({df_new.shape[0]}x{df_new.shape[1]})")

        except Exception as e:
            st.error(f"KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file: {e}")

    # pending sheet/object
    if st.session_state["pending_tables"] is not None:
        st.markdown("### Chá»n sheet/object")
        tables = st.session_state["pending_tables"]
        fname = st.session_state["pending_fname"] or "file"
        pending_file_hash = st.session_state["pending_file_hash"]

        chosen_table = st.selectbox("Sheet/Object", options=list(tables.keys()))
        c1, c2 = st.columns([1, 1])
        with c1:
            if st.button("âœ… Nháº­p", use_container_width=True):
                df_new = tables[chosen_table]
                table_hash = _df_sha256(df_new)

                if table_hash in st.session_state["hash_to_key"]:
                    existed_key = st.session_state["hash_to_key"][table_hash]
                    st.session_state["active_name"] = existed_key
                    st.info(f"Báº£ng Ä‘Ã£ nháº­p â†’ {existed_key}")
                else:
                    base = _safe_name(Path(fname).stem)
                    sh = _safe_name(chosen_table)
                    key_base = f"{base}__{sh}"
                    key = key_base
                    i = 2
                    while key in st.session_state["datasets"]:
                        key = f"{key_base}_{i}"
                        i += 1

                    hashes = [table_hash]
                    if pending_file_hash:
                        hashes.append(pending_file_hash)

                    _register_dataset(key, df_new, hashes=hashes)
                    st.session_state["active_step"] = 1
                    st.success(f"ÄÃ£ nháº­p: {key} ({df_new.shape[0]}x{df_new.shape[1]})")

                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

        with c2:
            if st.button("âŒ Huá»·", use_container_width=True):
                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

    st.markdown("---")
    st.markdown("## ğŸ“ Dataset")

    names_all = list(st.session_state["datasets"].keys())
    if not names_all:
        st.info("ChÆ°a cÃ³ dá»¯ liá»‡u. Upload Ä‘á»ƒ báº¯t Ä‘áº§u.")
        st.stop()

    ds_q = st.text_input("TÃ¬m dataset", value="", placeholder="gÃµ tÃªn dataset...")
    if ds_q.strip():
        names = [n for n in names_all if ds_q.lower() in n.lower()] or names_all
    else:
        names = names_all

    active = st.session_state["active_name"] or names_all[0]
    if active not in names_all:
        active = names_all[0]
        st.session_state["active_name"] = active

    chosen = st.selectbox("Chá»n dataset", options=names, index=names.index(active) if active in names else 0)
    st.session_state["active_name"] = chosen

    with st.expander("âœï¸ Äá»•i tÃªn dataset"):
        new_name = st.text_input("TÃªn má»›i", value=chosen)
        if st.button("LÆ°u tÃªn", use_container_width=True):
            new_name = _safe_name(new_name)
            if (new_name != chosen) and (new_name in st.session_state["datasets"]):
                st.error("TÃªn Ä‘Ã£ tá»“n táº¡i.")
            else:
                df_tmp = st.session_state["datasets"].pop(chosen)
                st.session_state["datasets"][new_name] = df_tmp

                hashes = st.session_state["key_to_hashes"].pop(chosen, set())
                st.session_state["key_to_hashes"][new_name] = hashes
                for h in list(hashes):
                    if st.session_state["hash_to_key"].get(h) == chosen:
                        st.session_state["hash_to_key"][h] = new_name

                st.session_state["active_name"] = new_name
                st.success("ÄÃ£ Ä‘á»•i tÃªn.")
                st.rerun()

    df_active = st.session_state["datasets"][st.session_state["active_name"]]
    summ = overall_summary(df_active)
    st.caption(f"rows={summ['Sá»‘ dÃ²ng']} | biáº¿n={summ['Sá»‘ biáº¿n']} | thiáº¿u={summ['Ã” thiáº¿u (NA)']}")

    c1, c2 = st.columns([1, 1])
    with c1:
        if st.button("ğŸ—‘ï¸ XoÃ¡ dataset", use_container_width=True):
            _delete_dataset(chosen)
            remaining = list(st.session_state["datasets"].keys())
            st.session_state["active_name"] = remaining[0] if remaining else None
            st.session_state["last_result"] = None
            st.session_state["last_run_meta"] = None
            st.session_state["active_step"] = 1
            st.rerun()

    with c2:
        if st.button("ğŸ§¹ XoÃ¡ táº¥t cáº£", use_container_width=True):
            st.session_state["datasets"] = {}
            st.session_state["active_name"] = None
            st.session_state["pending_tables"] = None
            st.session_state["pending_fname"] = None
            st.session_state["pending_file_hash"] = None
            st.session_state["hash_to_key"] = {}
            st.session_state["key_to_hashes"] = {}
            st.session_state["last_upload_hash"] = None
            st.session_state["last_result"] = None
            st.session_state["last_run_meta"] = None
            st.session_state["active_step"] = 1
            st.rerun()


# =========================
# Data in main
# =========================
df = st.session_state["datasets"][st.session_state["active_name"]]
cols = df.columns.tolist()


# =========================
# Stepper Buttons (BIG)
# =========================
st.markdown("### ğŸ§­ CÃ¡c bÆ°á»›c thao tÃ¡c")

c1, c2, c3 = st.columns(3, gap="medium")

with c1:
    t = "primary" if st.session_state["active_step"] == 1 else "secondary"
    if st.button("1) ğŸ“„ Dá»¯ liá»‡u", type=t, use_container_width=True):
        st.session_state["active_step"] = 1
        st.rerun()
    st.markdown('<div class="step-caption">Tá»•ng quan â€¢ xem báº£ng â€¢ danh sÃ¡ch biáº¿n</div>', unsafe_allow_html=True)

with c2:
    t = "primary" if st.session_state["active_step"] == 2 else "secondary"
    if st.button("2) ğŸ¯ Chá»n biáº¿n", type=t, use_container_width=True):
        st.session_state["active_step"] = 2
        st.rerun()
    st.markdown('<div class="step-caption">Chá»n Y/X â€¢ xem gá»£i Ã½ â€¢ báº¥m Run</div>', unsafe_allow_html=True)

with c3:
    t = "primary" if st.session_state["active_step"] == 3 else "secondary"
    if st.button("3) ğŸ“Œ Káº¿t quáº£", type=t, use_container_width=True):
        st.session_state["active_step"] = 3
        st.rerun()
    st.markdown('<div class="step-caption">Báº£ng káº¿t quáº£ â€¢ biá»ƒu Ä‘á»“ â€¢ diá»…n giáº£i</div>', unsafe_allow_html=True)

st.divider()


# =========================
# Compute and store results
# =========================
def _compute_and_store(y: str, xs: List[str], y_force: str, x_force: str, y_event: Optional[str]):
    if len(xs) == 1:
        suggestion, explanation, test_kind = suggest_single_x_test(df, y, xs[0], y_forced=y_force, x_forced=x_force)
        result_df, interp = run_single_x_test(df, y, xs[0], test_kind=test_kind)

        st.session_state["last_run_meta"] = {
            "dataset": st.session_state["active_name"],
            "mode": "test",
            "y": y,
            "xs": xs,
            "suggestion": suggestion,
            "explanation": explanation,
            "test_kind": test_kind,
            "y_force": y_force,
            "x_force": x_force,
        }
        st.session_state["last_result"] = {"table": result_df, "interp": interp}
        return

    # model
    tmp_for_suggest = df.copy()
    if y_force == "Äá»‹nh lÆ°á»£ng (numeric)":
        tmp_for_suggest[y] = coerce_numeric(tmp_for_suggest[y])
    elif y_force == "PhÃ¢n loáº¡i (categorical)":
        tmp_for_suggest[y] = tmp_for_suggest[y].astype("string")

    suggestion, explanation = suggest_model(tmp_for_suggest, y, xs)

    df_model = df.copy()
    if y_force == "Äá»‹nh lÆ°á»£ng (numeric)":
        df_model[y] = coerce_numeric(df_model[y])
    elif y_force == "PhÃ¢n loáº¡i (categorical)":
        df_model[y] = df_model[y].astype("string")

    formula, data_used, model_kind = build_formula(df_model, y, xs, y_binary_event=y_event)
    fit, note = run_model(formula, data_used, model_kind)
    kind = model_kind.split("||", 1)[0]

    table = None
    if kind == "ols":
        table = ols_table(fit)
    elif kind == "logit":
        table = logit_or_table(fit)

    st.session_state["last_run_meta"] = {
        "dataset": st.session_state["active_name"],
        "mode": "model",
        "y": y,
        "xs": xs,
        "suggestion": suggestion,
        "explanation": explanation,
        "formula": formula,
        "n_used": int(data_used.shape[0]),
        "model_kind": model_kind,
        "note": note,
        "y_force": y_force,
        "x_force": x_force,
        "y_event": y_event,
    }
    st.session_state["last_result"] = {"fit": fit, "kind": kind, "table": table, "data_used": data_used}


# =========================
# STEP 1: Data view
# =========================
if st.session_state["active_step"] == 1:
    st.subheader("ğŸ“„ Dá»¯ liá»‡u")

    summ = overall_summary(df)
    m1, m2, m3, m4, m5 = st.columns(5)
    m1.metric("Sá»‘ dÃ²ng", summ["Sá»‘ dÃ²ng"])
    m2.metric("Sá»‘ biáº¿n", summ["Sá»‘ biáº¿n"])
    m3.metric("Äá»‹nh lÆ°á»£ng", summ["Biáº¿n Ä‘á»‹nh lÆ°á»£ng"])
    m4.metric("PhÃ¢n loáº¡i", summ["Biáº¿n phÃ¢n loáº¡i"])
    m5.metric("Ã” thiáº¿u (NA)", summ["Ã” thiáº¿u (NA)"])

    st.markdown("### ğŸ‘€ Xem nhanh dá»¯ liá»‡u")
    st.dataframe(df.head(30), use_container_width=True, height=260)

    st.markdown("### ğŸ§¾ Liá»‡t kÃª biáº¿n & Ä‘áº·c tÃ­nh")
    var_rows = [summarize_variable(df, c) for c in cols]
    var_df = pd.DataFrame(var_rows)

    v1, v2 = st.columns([1.2, 1.0])
    with v1:
        q = st.text_input("TÃ¬m nhanh tÃªn biáº¿n", value="", placeholder="vd: age, weight...")
    with v2:
        filter_opt = st.selectbox("Lá»c nhanh", ["Táº¥t cáº£", "Chá»‰ Ä‘á»‹nh lÆ°á»£ng", "Chá»‰ phÃ¢n loáº¡i"], index=0)

    if q.strip():
        var_df = var_df[var_df["TÃªn biáº¿n"].str.contains(q.strip(), case=False, na=False)].copy()

    if filter_opt == "Chá»‰ Ä‘á»‹nh lÆ°á»£ng":
        var_df = var_df[var_df["Äáº·c tÃ­nh biáº¿n"].str.contains("Äá»‹nh lÆ°á»£ng", na=False)]
    elif filter_opt == "Chá»‰ phÃ¢n loáº¡i":
        var_df = var_df[var_df["Äáº·c tÃ­nh biáº¿n"].str.contains("PhÃ¢n loáº¡i", na=False)]

    st.dataframe(var_df, use_container_width=True, height=420)

    st.info("ğŸ‘‰ Báº¥m **2) Chá»n biáº¿n** Ä‘á»ƒ chá»n Y/X vÃ  cháº¡y kiá»ƒm Ä‘á»‹nh/mÃ´ hÃ¬nh.")


# =========================
# STEP 2: Choose variables
# =========================
elif st.session_state["active_step"] == 2:
    st.subheader("ğŸ¯ Chá»n biáº¿n phÃ¢n tÃ­ch")

    left, right = st.columns([2.2, 1.0], gap="large")

    with left:
        vq = st.text_input("TÃ¬m biáº¿n", value="", placeholder="gÃµ tÃªn biáº¿n...")
        cols_show = [c for c in cols if vq.lower() in c.lower()] if vq.strip() else cols
        if not cols_show:
            cols_show = cols

        y = st.selectbox("Biáº¿n phá»¥ thuá»™c (Y)", options=cols_show, index=0)
        xs = st.multiselect("Biáº¿n Ä‘á»™c láº­p (X) (cÃ³ thá»ƒ chá»n nhiá»u)", options=[c for c in cols_show if c != y])

        st.markdown("**Ã‰p kiá»ƒu náº¿u cáº§n**")
        force_opts = ["Tá»± Ä‘á»™ng", "Äá»‹nh lÆ°á»£ng (numeric)", "PhÃ¢n loáº¡i (categorical)"]
        y_force = st.selectbox("Kiá»ƒu Y", options=force_opts, index=0)
        x_force = "Tá»± Ä‘á»™ng"
        if len(xs) == 1:
            x_force = st.selectbox("Kiá»ƒu X (chá»‰ Ã¡p dá»¥ng khi chá»n 1 X)", options=force_opts, index=0)

        y_event = None
        if var_kind(df[y], y_force) == "cat":
            levels = sorted(df[y].dropna().astype(str).unique().tolist())
            if len(levels) == 2:
                y_event = st.selectbox("Chá»n má»©c coi lÃ  'Sá»± kiá»‡n' (Y=1) (logistic)", options=levels, index=1)

        st.markdown("#### âœ… Gá»£i Ã½")
        if len(xs) == 0:
            st.info("Chá»n Ã­t nháº¥t 1 biáº¿n X.")
            suggestion = None
            explanation = None
        else:
            if len(xs) == 1:
                suggestion, explanation, _ = suggest_single_x_test(df, y, xs[0], y_forced=y_force, x_forced=x_force)
                mode_label = "Kiá»ƒm Ä‘á»‹nh"
            else:
                tmp_for_suggest = df.copy()
                if y_force == "Äá»‹nh lÆ°á»£ng (numeric)":
                    tmp_for_suggest[y] = coerce_numeric(tmp_for_suggest[y])
                elif y_force == "PhÃ¢n loáº¡i (categorical)":
                    tmp_for_suggest[y] = tmp_for_suggest[y].astype("string")
                suggestion, explanation = suggest_model(tmp_for_suggest, y, xs)
                mode_label = "MÃ´ hÃ¬nh"

            st.write(f"**Cháº¿ Ä‘á»™:** {mode_label}")
            st.write(f"**Gá»£i Ã½:** {suggestion}")
            with st.expander("Giáº£i thÃ­ch"):
                st.write(explanation)

    with right:
        st.markdown("#### TÃ³m táº¯t lá»±a chá»n")
        st.write(f"**Dataset:** {st.session_state['active_name']}")
        st.write(f"**Y:** {y} ({'Ä‘á»‹nh lÆ°á»£ng' if var_kind(df[y], y_force)=='num' else 'phÃ¢n loáº¡i'})")

        if len(xs) == 0:
            st.write("**X:** -")
            st.button("â–¶ï¸ Run", type="primary", use_container_width=True, disabled=True)
        else:
            if len(xs) == 1:
                x1 = xs[0]
                xk = var_kind(df[x1], x_force)
                st.write(f"**X:** {x1} ({'Ä‘á»‹nh lÆ°á»£ng' if xk=='num' else 'phÃ¢n loáº¡i'})")
            else:
                st.write(f"**X:** {len(xs)} biáº¿n")

            st.markdown("---")
            if st.button("â–¶ï¸ Run", type="primary", use_container_width=True):
                try:
                    _compute_and_store(y=y, xs=xs, y_force=y_force, x_force=x_force, y_event=y_event)
                    st.session_state["active_step"] = 3
                    st.rerun()
                except Exception as e:
                    st.error(f"Lá»—i khi cháº¡y: {e}")


# =========================
# STEP 3: Results
# =========================
else:
    st.subheader("ğŸ“Œ Káº¿t quáº£")

    meta = st.session_state.get("last_run_meta")
    res = st.session_state.get("last_result")

    if not meta or not res:
        st.info("ChÆ°a cÃ³ káº¿t quáº£. Báº¥m **2) Chá»n biáº¿n** â†’ chá»n Y/X â†’ báº¥m **Run**.")
    else:
        st.markdown("#### TÃ³m táº¯t láº§n cháº¡y")
        st.write(f"- **Dataset:** {meta.get('dataset')}")
        st.write(f"- **Y:** {meta.get('y')}")
        st.write(f"- **X:** {', '.join(meta.get('xs', []))}")
        st.write(f"- **Gá»£i Ã½:** {meta.get('suggestion')}")
        st.divider()

        left, right = st.columns([1.4, 1.0], gap="large")

        with left:
            if meta["mode"] == "test":
                st.markdown("### ğŸ“Š Káº¿t quáº£ kiá»ƒm Ä‘á»‹nh")
                st.dataframe(res["table"], use_container_width=True)
                st.markdown("### ğŸ” Diá»…n giáº£i")
                st.write(res["interp"])
            else:
                st.caption(meta.get("note", ""))
                kind = res["kind"]
                if kind in ("ols", "logit") and res["table"] is not None:
                    st.markdown("### ğŸ“Š Báº£ng káº¿t quáº£ mÃ´ hÃ¬nh")
                    st.dataframe(res["table"], use_container_width=True)
                    st.markdown("### ğŸ” Diá»…n giáº£i")
                    if kind == "ols":
                        st.write(
                            "- Há»‡ sá»‘ > 0: Y tÄƒng khi X tÄƒng (giá»¯ cÃ¡c biáº¿n khÃ¡c).\n"
                            "- p-value < 0.05: thÆ°á»ng cÃ³ Ã½ nghÄ©a.\n"
                            "- CI 95% khÃ´ng chá»©a 0: thÆ°á»ng cÃ³ Ã½ nghÄ©a."
                        )
                    else:
                        st.write(
                            "- OR > 1: tÄƒng odds sá»± kiá»‡n.\n"
                            "- OR < 1: giáº£m odds.\n"
                            "- CI 95% khÃ´ng chá»©a 1 vÃ  p<0.05: thÆ°á»ng cÃ³ Ã½ nghÄ©a."
                        )
                else:
                    st.markdown("### ğŸ“„ MNLogit Summary")
                    st.write(res["fit"].summary())

        with right:
            st.markdown("### ğŸ“ˆ Biá»ƒu Ä‘á»“ minh hoáº¡")
            try:
                if meta["mode"] == "test":
                    y = meta["y"]
                    x1 = meta["xs"][0]
                    y_force = meta.get("y_force", "Tá»± Ä‘á»™ng")
                    x_force = meta.get("x_force", "Tá»± Ä‘á»™ng")

                    yk = var_kind(df[y], y_force)
                    xk = var_kind(df[x1], x_force)
                    tmp = df[[y, x1]].dropna().copy()

                    if yk == "num" and xk == "cat":
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=x1, y=y, points="all", title=f"{y} theo nhÃ³m {x1}")
                        st.plotly_chart(fig, use_container_width=True)

                    elif yk == "cat" and xk == "num":
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=y, y=x1, points="all", title=f"{x1} theo nhÃ³m {y}")
                        st.plotly_chart(fig, use_container_width=True)

                    elif yk == "cat" and xk == "cat":
                        tab = pd.crosstab(tmp[y].astype(str), tmp[x1].astype(str))
                        tab2 = tab.div(tab.sum(axis=1), axis=0).reset_index().melt(
                            id_vars=[y], var_name=x1, value_name="Tá»· lá»‡"
                        )
                        fig = px.bar(tab2, x=y, y="Tá»· lá»‡", color=x1, barmode="stack", title=f"Tá»· lá»‡ {x1} theo {y}")
                        st.plotly_chart(fig, use_container_width=True)

                    else:
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.scatter(tmp, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1}")
                        st.plotly_chart(fig, use_container_width=True)

                else:
                    kind = res["kind"]
                    data_used = res["data_used"]
                    fit = res["fit"]
                    y = meta["y"]
                    xs = meta["xs"]

                    if kind == "ols":
                        x1 = xs[0]
                        if (not is_categorical(data_used[x1])) and (not is_categorical(data_used[y])):
                            fig = px.scatter(data_used, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1} (trendline)")
                        else:
                            fig = (
                                px.box(data_used, x=x1, y=y, points="all", title=f"{y} theo nhÃ³m {x1}")
                                if is_categorical(data_used[x1])
                                else px.scatter(data_used, x=x1, y=y, title=f"{y} theo {x1}")
                            )
                        st.plotly_chart(fig, use_container_width=True)

                        pred = fit.fittedvalues
                        tmp_plot = pd.DataFrame({"Thá»±c táº¿": data_used[y], "Dá»± Ä‘oÃ¡n": pred})
                        fig2 = px.scatter(tmp_plot, x="Thá»±c táº¿", y="Dá»± Ä‘oÃ¡n", title="Dá»± Ä‘oÃ¡n vs Thá»±c táº¿")
                        st.plotly_chart(fig2, use_container_width=True)

                    elif kind == "logit":
                        p = fit.predict()
                        fig = px.histogram(p, nbins=25, title="PhÃ¢n bá»‘ xÃ¡c suáº¥t dá»± Ä‘oÃ¡n (p)")
                        st.plotly_chart(fig, use_container_width=True)

                    else:
                        st.info("Multinomial: cÃ³ thá»ƒ bá»• sung biá»ƒu Ä‘á»“ RRR / xÃ¡c suáº¥t dá»± Ä‘oÃ¡n theo nhu cáº§u.")
            except Exception as e:
                st.warning(f"KhÃ´ng váº½ Ä‘Æ°á»£c biá»ƒu Ä‘á»“: {e}")

    st.divider()
    st.caption(
        "âš ï¸ LÆ°u Ã½: CÃ´ng cá»¥ há»— trá»£ gá»£i Ã½ vÃ  cháº¡y kiá»ƒm Ä‘á»‹nh/mÃ´ hÃ¬nh cÆ¡ báº£n. "
        "NgÆ°á»i dÃ¹ng cáº§n kiá»ƒm tra giáº£ Ä‘á»‹nh, thiáº¿t káº¿ nghiÃªn cá»©u vÃ  cÃ¡ch mÃ£ hoÃ¡ biáº¿n Ä‘á»ƒ diá»…n giáº£i Ä‘Ãºng."
    )
