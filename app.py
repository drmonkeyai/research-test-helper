import io
import re
import tempfile
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from scipy import stats
import statsmodels.formula.api as smf


# =========================
# App config
# =========================
st.set_page_config(
    page_title="Há»— trá»£ nghiÃªn cá»©u cho bÃ¡c sÄ© gia Ä‘Ã¬nh",
    page_icon="ğŸ”¬",
    layout="wide",
)
APP_TITLE = "Há»— trá»£ nghiÃªn cá»©u cho bÃ¡c sÄ© gia Ä‘Ã¬nh"


# =========================
# Helpers: safe name / hashing
# =========================
def _safe_name(name: str) -> str:
    return re.sub(r"[^a-zA-Z0-9_]+", "_", str(name).strip())[:80] or "file"


def _file_sha256(raw: bytes) -> str:
    return hashlib.sha256(raw).hexdigest()


def _df_sha256(df: pd.DataFrame) -> str:
    h = pd.util.hash_pandas_object(df, index=True).values.tobytes()
    return hashlib.sha256(h).hexdigest()


# =========================
# Helpers: read files
# =========================
def read_csv_safely(uploaded_file) -> pd.DataFrame:
    raw = uploaded_file.getvalue()
    encodings = ["utf-8-sig", "utf-8", "cp1258", "cp1252", "latin1"]
    last_err = None
    for enc in encodings:
        try:
            return pd.read_csv(io.BytesIO(raw), encoding=enc)
        except Exception as e:
            last_err = e
    raise last_err


def _read_via_tempfile(raw: bytes, suffix: str, reader_fn):
    """
    Some readers (SPSS/STATA) may require a file path, not BytesIO.
    """
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(raw)
            tmp_path = tmp.name
        return reader_fn(tmp_path)
    finally:
        if tmp_path:
            try:
                Path(tmp_path).unlink(missing_ok=True)
            except Exception:
                pass


def read_file_safely(uploaded_file) -> Dict[str, pd.DataFrame]:
    """
    Return dict {table_name: df}
    Supported:
      - .csv
      - .xlsx (openpyxl)
      - .xls  (xlrd)
      - .sav/.zsav (SPSS) (pyreadstat backend)
      - .dta (STATA) (pyreadstat backend)
      - .rds (pyreadr)
    """
    name = uploaded_file.name
    ext = Path(name).suffix.lower()
    raw = uploaded_file.getvalue()

    if ext == ".csv":
        return {"data": read_csv_safely(uploaded_file)}

    if ext == ".xlsx":
        xls = pd.ExcelFile(io.BytesIO(raw), engine="openpyxl")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh)
        return out

    if ext == ".xls":
        xls = pd.ExcelFile(io.BytesIO(raw), engine="xlrd")
        out: Dict[str, pd.DataFrame] = {}
        for sh in xls.sheet_names:
            out[str(sh)] = pd.read_excel(xls, sheet_name=sh, engine="xlrd")
        return out

    if ext in [".sav", ".zsav"]:
        df = _read_via_tempfile(raw, ext, pd.read_spss)
        return {"data": df}

    if ext == ".dta":
        df = _read_via_tempfile(raw, ".dta", pd.read_stata)
        return {"data": df}

    if ext == ".rds":
        try:
            import pyreadr  # type: ignore
        except Exception as e:
            raise RuntimeError("Thiáº¿u thÆ° viá»‡n pyreadr Ä‘á»ƒ Ä‘á»c .rds. HÃ£y cÃ i: pip install pyreadr") from e

        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(suffix=".rds", delete=False) as tmp:
                tmp.write(raw)
                tmp_path = tmp.name
            res = pyreadr.read_r(tmp_path)
            out: Dict[str, pd.DataFrame] = {}
            for k, v in res.items():
                if isinstance(v, pd.DataFrame):
                    out[str(k) if k else "data"] = v
            if not out:
                raise RuntimeError("File .rds khÃ´ng chá»©a DataFrame (hoáº·c object khÃ´ng há»— trá»£).")
            return out
        finally:
            if tmp_path:
                try:
                    Path(tmp_path).unlink(missing_ok=True)
                except Exception:
                    pass

    raise RuntimeError(f"Äá»‹nh dáº¡ng {ext} chÆ°a Ä‘Æ°á»£c há»— trá»£.")


# =========================
# Helpers: type detection
# =========================
def is_categorical(s: pd.Series) -> bool:
    if pd.api.types.is_bool_dtype(s) or pd.api.types.is_object_dtype(s) or pd.api.types.is_categorical_dtype(s):
        return True
    if pd.api.types.is_numeric_dtype(s):
        nunique = s.dropna().nunique()
        if nunique <= 10:
            return True
    return False


def coerce_numeric(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")


def var_kind(s: pd.Series, forced: str = "Tá»± Ä‘á»™ng") -> str:
    if forced == "Äá»‹nh lÆ°á»£ng (numeric)":
        return "num"
    if forced == "PhÃ¢n loáº¡i (categorical)":
        return "cat"
    return "cat" if is_categorical(s) else "num"


# =========================
# Summaries
# =========================
def summarize_variable(df: pd.DataFrame, col: str) -> Dict[str, str]:
    s = df[col]
    miss = int(s.isna().sum())
    n = int(len(s))
    nunique = int(s.dropna().nunique())

    if is_categorical(s):
        vc = s.astype("string").value_counts(dropna=True).head(3)
        top = ", ".join([f"{idx} ({val})" for idx, val in vc.items()]) if len(vc) else "-"
        return {
            "TÃªn biáº¿n": col,
            "Äáº·c tÃ­nh biáº¿n": f"PhÃ¢n loáº¡i | má»©c={nunique} | thiáº¿u={miss}/{n} | top: {top}",
        }

    x = coerce_numeric(s)
    x_non = x.dropna()
    if len(x_non) == 0:
        return {"TÃªn biáº¿n": col, "Äáº·c tÃ­nh biáº¿n": f"Äá»‹nh lÆ°á»£ng | thiáº¿u={miss}/{n} | (khÃ´ng Ä‘á»c Ä‘Æ°á»£c sá»‘)"}

    mean = float(x_non.mean())
    sd = float(x_non.std(ddof=1)) if len(x_non) >= 2 else float("nan")
    med = float(x_non.median())
    q1 = float(x_non.quantile(0.25))
    q3 = float(x_non.quantile(0.75))
    return {
        "TÃªn biáº¿n": col,
        "Äáº·c tÃ­nh biáº¿n": f"Äá»‹nh lÆ°á»£ng | thiáº¿u={miss}/{n} | mean={mean:.2f}, SD={sd:.2f} | median={med:.2f} (IQR {q1:.2f}-{q3:.2f})",
    }


def overall_summary(df: pd.DataFrame) -> Dict[str, int]:
    n_rows = int(df.shape[0])
    n_cols = int(df.shape[1])
    missing_cells = int(df.isna().sum().sum())
    numeric_cols = sum([pd.api.types.is_numeric_dtype(df[c]) and (not is_categorical(df[c])) for c in df.columns])
    cat_cols = n_cols - numeric_cols
    return {
        "Sá»‘ dÃ²ng": n_rows,
        "Sá»‘ biáº¿n": n_cols,
        "Biáº¿n Ä‘á»‹nh lÆ°á»£ng": int(numeric_cols),
        "Biáº¿n phÃ¢n loáº¡i": int(cat_cols),
        "Ã” thiáº¿u (NA)": missing_cells,
    }


# =========================
# Assumptions: normality & homogeneity
# =========================
def normality_pvalue(x: np.ndarray) -> float:
    """
    - n < 3: nan
    - n <= 5000: Shapiro-Wilk
    - n > 5000: Dâ€™Agostino K2
    """
    x = x[~np.isnan(x)]
    n = len(x)
    if n < 3:
        return float("nan")
    try:
        if n <= 5000:
            return float(stats.shapiro(x).pvalue)
        return float(stats.normaltest(x).pvalue)
    except Exception:
        return float("nan")


def variance_homogeneity_pvalue(groups: List[np.ndarray]) -> float:
    """
    Levene test (robust)
    """
    clean = [g[~np.isnan(g)] for g in groups if len(g[~np.isnan(g)]) >= 2]
    if len(clean) < 2:
        return float("nan")
    try:
        return float(stats.levene(*clean, center="median").pvalue)
    except Exception:
        return float("nan")


def assumption_report_num_by_group(df: pd.DataFrame, y_num: str, group_cat: str) -> dict:
    tmp = df[[y_num, group_cat]].dropna().copy()
    tmp[y_num] = pd.to_numeric(tmp[y_num], errors="coerce")
    tmp = tmp.dropna()

    levels = sorted(tmp[group_cat].astype(str).unique().tolist())
    arrays = []
    norm_p = {}
    ns = {}

    for lv in levels:
        a = tmp.loc[tmp[group_cat].astype(str) == lv, y_num].to_numpy()
        a = a[~np.isnan(a)]
        arrays.append(a)
        ns[lv] = int(len(a))
        norm_p[lv] = normality_pvalue(a)

    lev_p = variance_homogeneity_pvalue(arrays)
    return {
        "levels": levels,
        "n": ns,
        "normality_p": norm_p,
        "levene_p": lev_p,
        "total_n": int(tmp.shape[0]),
    }


def _norm_ok(report: dict, alpha: float = 0.05) -> bool:
    # if any group has <3, normality can't be assessed -> treat as not ok
    for lv, n in report["n"].items():
        if n < 3:
            return False
        p = report["normality_p"].get(lv, float("nan"))
        if np.isnan(p) or p < alpha:
            return False
    return True


def _var_ok(report: dict, alpha: float = 0.05) -> bool:
    p = report.get("levene_p", float("nan"))
    return (not np.isnan(p)) and (p >= alpha)


# =========================
# Single-X: suggest + run (with assumptions)
# =========================
def suggest_single_x_test(
    df: pd.DataFrame,
    y: str,
    x: str,
    y_forced: str = "Tá»± Ä‘á»™ng",
    x_forced: str = "Tá»± Ä‘á»™ng",
) -> Tuple[str, str, str]:
    """
    Returns (suggestion, explanation, test_kind)
    """
    yk = var_kind(df[y], y_forced)
    xk = var_kind(df[x], x_forced)

    tmp = df[[y, x]].dropna()
    if tmp.shape[0] < 3:
        return ("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u", "Sau khi loáº¡i NA, sá»‘ dÃ²ng quÃ¡ Ã­t Ä‘á»ƒ kiá»ƒm Ä‘á»‹nh.", "none")

    # cat - cat
    if yk == "cat" and xk == "cat":
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape == (2, 2) and (tab.values < 5).any():
            return ("Fisher exact (2x2)", "Báº£ng 2x2 vÃ  cÃ³ Ã´ nhá» â†’ Æ°u tiÃªn Fisher exact.", "fisher_2x2")
        return ("Chi-bÃ¬nh phÆ°Æ¡ng (Chi-square)", "X vÃ  Y Ä‘á»u phÃ¢n loáº¡i â†’ kiá»ƒm Ä‘á»‹nh Ä‘á»™c láº­p báº±ng Chi-square.", "chisq")

    # num - cat: compare numeric across groups
    if yk == "num" and xk == "cat":
        rep = assumption_report_num_by_group(df, y_num=y, group_cat=x)
        n_levels = len(rep["levels"])
        norm_ok = _norm_ok(rep)
        var_ok = _var_ok(rep)

        if n_levels == 2:
            if norm_ok and var_ok:
                return ("t-test Ä‘á»™c láº­p (Student)", "2 nhÃ³m, chuáº©n & phÆ°Æ¡ng sai tÆ°Æ¡ng Ä‘Æ°Æ¡ng â†’ t-test Student.", "ttest_student")
            if norm_ok and (not var_ok):
                return ("t-test Ä‘á»™c láº­p (Welch)", "2 nhÃ³m, chuáº©n nhÆ°ng phÆ°Æ¡ng sai khÃ¡c â†’ Welch t-test.", "ttest_welch")
            return ("Mannâ€“Whitney U", "2 nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh chuáº©n â†’ Mannâ€“Whitney (phi tham sá»‘).", "mwu")

        if norm_ok and var_ok:
            return ("ANOVA má»™t yáº¿u tá»‘", "Nhiá»u nhÃ³m, chuáº©n & Ä‘á»“ng nháº¥t phÆ°Æ¡ng sai â†’ one-way ANOVA.", "anova")
        return ("Kruskalâ€“Wallis", "Nhiá»u nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh â†’ Kruskalâ€“Wallis (phi tham sá»‘).", "kruskal")

    # cat - num: swap roles (compare numeric X across Y groups)
    if yk == "cat" and xk == "num":
        rep = assumption_report_num_by_group(df, y_num=x, group_cat=y)
        n_levels = len(rep["levels"])
        norm_ok = _norm_ok(rep)
        var_ok = _var_ok(rep)

        if n_levels == 2:
            if norm_ok and var_ok:
                return ("t-test Ä‘á»™c láº­p (Student)", "2 nhÃ³m, chuáº©n & phÆ°Æ¡ng sai tÆ°Æ¡ng Ä‘Æ°Æ¡ng â†’ t-test Student.", "ttest_student_swapped")
            if norm_ok and (not var_ok):
                return ("t-test Ä‘á»™c láº­p (Welch)", "2 nhÃ³m, chuáº©n nhÆ°ng phÆ°Æ¡ng sai khÃ¡c â†’ Welch t-test.", "ttest_welch_swapped")
            return ("Mannâ€“Whitney U", "2 nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh chuáº©n â†’ Mannâ€“Whitney (phi tham sá»‘).", "mwu_swapped")

        if norm_ok and var_ok:
            return ("ANOVA má»™t yáº¿u tá»‘", "Nhiá»u nhÃ³m, chuáº©n & Ä‘á»“ng nháº¥t phÆ°Æ¡ng sai â†’ one-way ANOVA.", "anova_swapped")
        return ("Kruskalâ€“Wallis", "Nhiá»u nhÃ³m nhÆ°ng khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh â†’ Kruskalâ€“Wallis (phi tham sá»‘).", "kruskal_swapped")

    # num - num: correlation; choose Pearson if both ~normal else Spearman
    if yk == "num" and xk == "num":
        yv = coerce_numeric(df[y]).dropna().to_numpy()
        xv = coerce_numeric(df[x]).dropna().to_numpy()
        # align quickly with pairwise dropna
        tmp2 = df[[y, x]].copy()
        tmp2[y] = coerce_numeric(tmp2[y])
        tmp2[x] = coerce_numeric(tmp2[x])
        tmp2 = tmp2.dropna()
        if tmp2.shape[0] < 3:
            return ("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u", "KhÃ´ng Ä‘á»§ dÃ²ng sá»‘ Ä‘á»ƒ tÃ­nh tÆ°Æ¡ng quan.", "none")

        pny = normality_pvalue(tmp2[y].to_numpy())
        pnx = normality_pvalue(tmp2[x].to_numpy())
        if (not np.isnan(pny)) and (not np.isnan(pnx)) and (pny >= 0.05) and (pnx >= 0.05):
            return ("TÆ°Æ¡ng quan Pearson", "X vÃ  Y gáº§n chuáº©n â†’ dÃ¹ng Pearson correlation.", "corr_pearson")
        return ("TÆ°Æ¡ng quan Spearman", "X hoáº·c Y khÃ´ng chuáº©n/ordinal â†’ dÃ¹ng Spearman correlation.", "corr_spearman")

    return ("KhÃ´ng xÃ¡c Ä‘á»‹nh", "KhÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c phÃ©p kiá»ƒm phÃ¹ há»£p tá»« kiá»ƒu biáº¿n hiá»‡n táº¡i.", "none")


def _cohens_d(a: np.ndarray, b: np.ndarray) -> float:
    a = a[~np.isnan(a)]
    b = b[~np.isnan(b)]
    if len(a) < 2 or len(b) < 2:
        return float("nan")
    va = np.var(a, ddof=1)
    vb = np.var(b, ddof=1)
    sp = np.sqrt(((len(a) - 1) * va + (len(b) - 1) * vb) / (len(a) + len(b) - 2))
    if sp == 0:
        return float("nan")
    return (np.mean(a) - np.mean(b)) / sp


def _cramers_v(tab: pd.DataFrame) -> float:
    chi2, p, dof, exp = stats.chi2_contingency(tab.values)
    n = tab.values.sum()
    if n == 0:
        return float("nan")
    r, k = tab.shape
    return np.sqrt(chi2 / (n * (min(r, k) - 1))) if min(r, k) > 1 else float("nan")


def _assumption_text(rep: dict) -> str:
    norm = ", ".join([f"{k}: p={rep['normality_p'][k]:.4f}" if not np.isnan(rep['normality_p'][k]) else f"{k}: p=NA"
                      for k in rep["levels"]])
    lev = rep.get("levene_p", float("nan"))
    lev_s = f"{lev:.4f}" if not np.isnan(lev) else "NA"
    return f"Kiá»ƒm tra giáº£ Ä‘á»‹nh: Shapiro theo nhÃ³m [{norm}]; Levene p={lev_s}."


def run_single_x_test(df: pd.DataFrame, y: str, x: str, test_kind: str) -> Tuple[pd.DataFrame, str]:
    """
    Return (result_table, interpretation_text)
    """
    # --- cat-cat ---
    if test_kind == "chisq":
        tmp = df[[y, x]].dropna()
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        chi2, p, dof, exp = stats.chi2_contingency(tab.values)
        v = _cramers_v(tab)
        out = pd.DataFrame({"Chá»‰ sá»‘": ["Chi2", "df", "p-value", "Cramer's V"], "GiÃ¡ trá»‹": [chi2, dof, p, v]})
        interp = (
            "Diá»…n giáº£i: p-value nhá» gá»£i Ã½ X vÃ  Y cÃ³ liÃªn quan (khÃ´ng Ä‘á»™c láº­p). "
            "Cramer's V cho biáº¿t Ä‘á»™ máº¡nh liÃªn quan (â‰ˆ0.1 nhá», 0.3 vá»«a, 0.5 lá»›n â€“ tuá»³ bá»‘i cáº£nh)."
        )
        return out, interp

    if test_kind == "fisher_2x2":
        tmp = df[[y, x]].dropna()
        tab = pd.crosstab(tmp[y].astype(str), tmp[x].astype(str))
        if tab.shape != (2, 2):
            raise ValueError("Fisher exact chá»‰ Ã¡p dá»¥ng báº£ng 2x2.")
        oddsratio, p = stats.fisher_exact(tab.values)
        out = pd.DataFrame({"Chá»‰ sá»‘": ["Odds ratio", "p-value"], "GiÃ¡ trá»‹": [oddsratio, p]})
        interp = (
            "Diá»…n giáº£i: p-value nhá» gá»£i Ã½ cÃ³ liÃªn quan giá»¯a 2 biáº¿n phÃ¢n loáº¡i. "
            "Odds ratio >1 cho tháº¥y odds cao hÆ¡n á»Ÿ má»™t nhÃ³m (xem nhÃ³m tham chiáº¿u tá»« báº£ng 2x2)."
        )
        return out, interp

    # --- num-cat (Y numeric, X group) ---
    if test_kind in ("ttest_student", "ttest_welch", "mwu", "anova", "kruskal"):
        tmp = df[[y, x]].dropna().copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp = tmp.dropna()
        groups = tmp[x].astype(str)
        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, y].to_numpy() for lv in levels]
        rep = assumption_report_num_by_group(df, y_num=y, group_cat=x)
        assump = _assumption_text(rep)

        if test_kind in ("ttest_student", "ttest_welch"):
            if len(levels) != 2:
                raise ValueError("t-test cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            equal_var = (test_kind == "ttest_student")
            tstat, p = stats.ttest_ind(a, b, equal_var=equal_var, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame(
                {"Chá»‰ sá»‘": ["t", "p-value", "Cohen's d"], "GiÃ¡ trá»‹": [tstat, p, d]}
            )
            interp = (
                f"{assump}\n"
                "Diá»…n giáº£i: p-value nhá» gá»£i Ã½ trung bÃ¬nh Y khÃ¡c nhau giá»¯a 2 nhÃ³m. "
                "Cohenâ€™s d: ~0.2 nhá», 0.5 vá»«a, 0.8 lá»›n (tham kháº£o)."
            )
            return out, interp

        if test_kind == "mwu":
            if len(levels) != 2:
                raise ValueError("Mannâ€“Whitney cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            u, p = stats.mannwhitneyu(a, b, alternative="two-sided")
            out = pd.DataFrame({"Chá»‰ sá»‘": ["U", "p-value"], "GiÃ¡ trá»‹": [u, p]})
            interp = (
                f"{assump}\n"
                "Diá»…n giáº£i: Mannâ€“Whitney so sÃ¡nh phÃ¢n bá»‘/median giá»¯a 2 nhÃ³m khi khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh chuáº©n."
            )
            return out, interp

        if test_kind == "anova":
            f, p = stats.f_oneway(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["F", "p-value"], "GiÃ¡ trá»‹": [f, p]})
            interp = (
                f"{assump}\n"
                "Diá»…n giáº£i: p-value nhá» gá»£i Ã½ cÃ³ Ã­t nháº¥t 1 nhÃ³m khÃ¡c trung bÃ¬nh; náº¿u cÃ³ Ã½ nghÄ©a nÃªn lÃ m post-hoc."
            )
            return out, interp

        if test_kind == "kruskal":
            h, p = stats.kruskal(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["H (Kruskal)", "p-value"], "GiÃ¡ trá»‹": [h, p]})
            interp = (
                f"{assump}\n"
                "Diá»…n giáº£i: Kruskalâ€“Wallis dÃ¹ng khi khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh; náº¿u cÃ³ Ã½ nghÄ©a nÃªn lÃ m post-hoc phi tham sá»‘."
            )
            return out, interp

    # --- swapped: X numeric, Y group ---
    if test_kind in ("ttest_student_swapped", "ttest_welch_swapped", "mwu_swapped", "anova_swapped", "kruskal_swapped"):
        # swap y <-> x in the numeric-by-group framework:
        tmp = df[[y, x]].dropna().copy()
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        groups = tmp[y].astype(str)
        levels = sorted(groups.unique().tolist())
        arrays = [tmp.loc[groups == lv, x].to_numpy() for lv in levels]
        rep = assumption_report_num_by_group(df, y_num=x, group_cat=y)
        assump = _assumption_text(rep)

        base_kind = test_kind.replace("_swapped", "")
        if base_kind in ("ttest_student", "ttest_welch"):
            if len(levels) != 2:
                raise ValueError("t-test cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            equal_var = (base_kind == "ttest_student")
            tstat, p = stats.ttest_ind(a, b, equal_var=equal_var, nan_policy="omit")
            d = _cohens_d(a, b)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["t", "p-value", "Cohen's d"], "GiÃ¡ trá»‹": [tstat, p, d]})
            interp = (
                f"{assump}\n"
                "Diá»…n giáº£i: p-value nhá» gá»£i Ã½ trung bÃ¬nh X khÃ¡c nhau giá»¯a 2 nhÃ³m Y."
            )
            return out, interp

        if base_kind == "mwu":
            if len(levels) != 2:
                raise ValueError("Mannâ€“Whitney cáº§n Ä‘Ãºng 2 nhÃ³m.")
            a, b = arrays[0], arrays[1]
            u, p = stats.mannwhitneyu(a, b, alternative="two-sided")
            out = pd.DataFrame({"Chá»‰ sá»‘": ["U", "p-value"], "GiÃ¡ trá»‹": [u, p]})
            interp = f"{assump}\nDiá»…n giáº£i: Mannâ€“Whitney dÃ¹ng khi khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh chuáº©n."
            return out, interp

        if base_kind == "anova":
            f, p = stats.f_oneway(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["F", "p-value"], "GiÃ¡ trá»‹": [f, p]})
            interp = f"{assump}\nDiá»…n giáº£i: p-value nhá» gá»£i Ã½ cÃ³ Ã­t nháº¥t 1 nhÃ³m khÃ¡c trung bÃ¬nh; nÃªn lÃ m post-hoc."
            return out, interp

        if base_kind == "kruskal":
            h, p = stats.kruskal(*arrays)
            out = pd.DataFrame({"Chá»‰ sá»‘": ["H (Kruskal)", "p-value"], "GiÃ¡ trá»‹": [h, p]})
            interp = f"{assump}\nDiá»…n giáº£i: Kruskalâ€“Wallis dÃ¹ng khi khÃ´ng Ä‘áº¡t giáº£ Ä‘á»‹nh; nÃªn lÃ m post-hoc phi tham sá»‘."
            return out, interp

    # --- correlation ---
    if test_kind == "corr_pearson":
        tmp = df[[y, x]].copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        r, p = stats.pearsonr(tmp[x].to_numpy(), tmp[y].to_numpy())
        pny = normality_pvalue(tmp[y].to_numpy())
        pnx = normality_pvalue(tmp[x].to_numpy())
        out = pd.DataFrame({"Chá»‰ sá»‘": ["Pearson r", "p-value", "n", "Shapiro p(Y)", "Shapiro p(X)"], "GiÃ¡ trá»‹": [r, p, tmp.shape[0], pny, pnx]})
        interp = "Diá»…n giáº£i: r gáº§n 0 â†’ yáº¿u; gáº§n Â±1 â†’ máº¡nh. p-value nhá» gá»£i Ã½ liÃªn quan tuyáº¿n tÃ­nh cÃ³ Ã½ nghÄ©a."
        return out, interp

    if test_kind == "corr_spearman":
        tmp = df[[y, x]].copy()
        tmp[y] = coerce_numeric(tmp[y])
        tmp[x] = coerce_numeric(tmp[x])
        tmp = tmp.dropna()
        rho, p = stats.spearmanr(tmp[x].to_numpy(), tmp[y].to_numpy())
        pny = normality_pvalue(tmp[y].to_numpy())
        pnx = normality_pvalue(tmp[x].to_numpy())
        out = pd.DataFrame({"Chá»‰ sá»‘": ["Spearman rho", "p-value", "n", "Shapiro p(Y)", "Shapiro p(X)"], "GiÃ¡ trá»‹": [rho, p, tmp.shape[0], pny, pnx]})
        interp = "Diá»…n giáº£i: Spearman Ä‘Ã¡nh giÃ¡ liÃªn quan Ä‘Æ¡n Ä‘iá»‡u (khÃ´ng cáº§n chuáº©n), phÃ¹ há»£p khi dá»¯ liá»‡u khÃ´ng chuáº©n/ordinal."
        return out, interp

    raise ValueError("KhÃ´ng cÃ³ kiá»ƒm Ä‘á»‹nh phÃ¹ há»£p (test_kind=none).")


# =========================
# Model: suggest + build + run
# =========================
def suggest_model(df: pd.DataFrame, y: str, xs: List[str]) -> Tuple[str, str]:
    y_s = df[y]
    if is_categorical(y_s):
        n_levels = int(y_s.dropna().nunique())
        if n_levels <= 1:
            return ("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u", "Biáº¿n phá»¥ thuá»™c chá»‰ cÃ³ 0â€“1 má»©c sau khi loáº¡i thiáº¿u. HÃ£y kiá»ƒm tra dá»¯ liá»‡u.")
        if n_levels == 2:
            return (
                "Há»“i quy Logistic nhá»‹ phÃ¢n (Binary Logistic)",
                "Y phÃ¢n loáº¡i 2 má»©c â†’ phÃ¹ há»£p logistic nhá»‹ phÃ¢n Ä‘á»ƒ Æ°á»›c lÆ°á»£ng OR vÃ  p-value khi cÃ³ nhiá»u biáº¿n Ä‘á»™c láº­p.",
            )
        return (
            "Há»“i quy Logistic Ä‘a danh (Multinomial Logistic)",
            f"Y phÃ¢n loáº¡i >2 má»©c (má»©c={n_levels}) â†’ phÃ¹ há»£p logistic Ä‘a danh.",
        )
    return ("Há»“i quy tuyáº¿n tÃ­nh (OLS)", "Y Ä‘á»‹nh lÆ°á»£ng â†’ phÃ¹ há»£p há»“i quy tuyáº¿n tÃ­nh (OLS).")


def build_formula(
    df: pd.DataFrame,
    y: str,
    xs: List[str],
    y_binary_event: str | None = None,
) -> Tuple[str, pd.DataFrame, str]:
    tmp = df[[y] + xs].copy().dropna()

    if is_categorical(tmp[y]):
        n_levels = int(tmp[y].nunique())

        if n_levels == 2:
            y_cat = tmp[y].astype("category")
            cats = list(y_cat.cat.categories)
            event = y_binary_event if (y_binary_event in cats) else cats[1]
            tmp["_y01_"] = (tmp[y] == event).astype(int)

            terms = []
            for x in xs:
                terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

            formula = "_y01_ ~ " + " + ".join(terms)
            return formula, tmp, f"logit||Logistic nhá»‹ phÃ¢n: sá»± kiá»‡n (Y=1)='{event}'"

        tmp["_ycat_"] = tmp[y].astype("category")
        tmp["_ycode_"] = tmp["_ycat_"].cat.codes

        terms = []
        for x in xs:
            terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

        formula = "_ycode_ ~ " + " + ".join(terms)
        return formula, tmp, "mnlogit||Multinomial: há»‡ sá»‘ theo nhÃ³m tham chiáº¿u (mÃ£ hoÃ¡ category)"

    tmp[y] = coerce_numeric(tmp[y])
    tmp = tmp.dropna()

    terms = []
    for x in xs:
        terms.append(f"C(Q('{x}'))" if is_categorical(tmp[x]) else f"Q('{x}')")

    formula = f"Q('{y}') ~ " + " + ".join(terms)
    return formula, tmp, "ols||OLS"


def run_model(formula: str, data_used: pd.DataFrame, model_kind: str):
    kind, note = model_kind.split("||", 1)
    if kind == "ols":
        return smf.ols(formula=formula, data=data_used).fit(), note
    if kind == "logit":
        return smf.logit(formula=formula, data=data_used).fit(disp=0), note
    if kind == "mnlogit":
        return smf.mnlogit(formula=formula, data=data_used).fit(disp=0), note
    raise ValueError("Unknown model kind")


def ols_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame({"Há»‡ sá»‘": fit.params, "CI 2.5%": conf[0], "CI 97.5%": conf[1], "p-value": fit.pvalues})
    out.index.name = "Biáº¿n"
    return out.sort_values("p-value")


def logit_or_table(fit) -> pd.DataFrame:
    conf = fit.conf_int()
    out = pd.DataFrame(
        {
            "OR": np.exp(fit.params),
            "CI 2.5%": np.exp(conf[0]),
            "CI 97.5%": np.exp(conf[1]),
            "p-value": fit.pvalues,
        }
    )
    out.index.name = "Biáº¿n"
    return out.sort_values("p-value")


# =========================
# Session state: datasets + dedupe
# =========================
if "datasets" not in st.session_state:
    st.session_state["datasets"] = {}  # key -> df
if "active_name" not in st.session_state:
    st.session_state["active_name"] = None

# pending tables (Excel/RDS multiple)
if "pending_tables" not in st.session_state:
    st.session_state["pending_tables"] = None
if "pending_fname" not in st.session_state:
    st.session_state["pending_fname"] = None
if "pending_file_hash" not in st.session_state:
    st.session_state["pending_file_hash"] = None

# dedupe maps
if "hash_to_key" not in st.session_state:
    st.session_state["hash_to_key"] = {}  # hash -> key
if "key_to_hashes" not in st.session_state:
    st.session_state["key_to_hashes"] = {}  # key -> set(hash)
if "last_upload_hash" not in st.session_state:
    st.session_state["last_upload_hash"] = None


def _register_dataset(key: str, df: pd.DataFrame, hashes: List[str]):
    st.session_state["datasets"][key] = df
    st.session_state["active_name"] = key
    st.session_state["key_to_hashes"].setdefault(key, set())
    for h in hashes:
        st.session_state["hash_to_key"][h] = key
        st.session_state["key_to_hashes"][key].add(h)


def _delete_dataset(key: str):
    st.session_state["datasets"].pop(key, None)
    hashes = st.session_state["key_to_hashes"].pop(key, set())
    for h in list(hashes):
        if st.session_state["hash_to_key"].get(h) == key:
            st.session_state["hash_to_key"].pop(h, None)


# =========================
# UI Header
# =========================
st.markdown(
    f"""
    <div style="padding: 0.25rem 0 0.5rem 0;">
      <h1 style="margin:0;">{APP_TITLE}</h1>
      <div style="color:#6b7280;">Upload dá»¯ liá»‡u â†’ chá»n biáº¿n â†’ (1 X: kiá»ƒm Ä‘á»‹nh cÃ³ kiá»ƒm tra giáº£ Ä‘á»‹nh) | (nhiá»u X: mÃ´ hÃ¬nh há»“i quy)</div>
    </div>
    """,
    unsafe_allow_html=True,
)
st.divider()


# =========================
# Top row (Overview | Upload | File list)
# =========================
col_left, col_mid, col_right = st.columns([2.2, 1.6, 2.2], gap="large")

with col_mid:
    st.subheader("â¬†ï¸ Upload file")
    up = st.file_uploader(
        "Táº£i lÃªn dá»¯ liá»‡u",
        type=["csv", "xlsx", "xls", "sav", "zsav", "dta", "rds"],
        accept_multiple_files=False,
    )

    if up is not None:
        try:
            raw = up.getvalue()
            file_hash = _file_sha256(raw)

            # prevent rerun duplicate
            if st.session_state["last_upload_hash"] != file_hash:
                st.session_state["last_upload_hash"] = file_hash

                if file_hash in st.session_state["hash_to_key"]:
                    existed = st.session_state["hash_to_key"][file_hash]
                    st.session_state["active_name"] = existed
                    st.info(f"File nÃ y Ä‘Ã£ upload trÆ°á»›c Ä‘Ã³ â†’ chuyá»ƒn sang: {existed}")
                else:
                    tables = read_file_safely(up)

                    if len(tables) > 1:
                        st.session_state["pending_tables"] = tables
                        st.session_state["pending_fname"] = up.name
                        st.session_state["pending_file_hash"] = file_hash
                        st.info(f"File cÃ³ {len(tables)} báº£ng (sheet/object). Chá»n 1 báº£ng Ä‘á»ƒ nháº­p.")
                    else:
                        df_new = list(tables.values())[0]
                        base = _safe_name(Path(up.name).stem)
                        key = base
                        i = 2
                        while key in st.session_state["datasets"]:
                            key = f"{base}_{i}"
                            i += 1

                        df_hash = _df_sha256(df_new)
                        _register_dataset(key, df_new, hashes=[file_hash, df_hash])
                        st.success(f"ÄÃ£ táº£i: {key} (rows={df_new.shape[0]}, cols={df_new.shape[1]})")

        except Exception as e:
            st.error(f"KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file: {e}")

    # pending import
    if st.session_state["pending_tables"] is not None:
        tables = st.session_state["pending_tables"]
        fname = st.session_state["pending_fname"] or "file"
        pending_file_hash = st.session_state["pending_file_hash"]

        chosen_table = st.selectbox("Chá»n sheet/object", options=list(tables.keys()))
        c1, c2 = st.columns([1, 1])

        with c1:
            if st.button("âœ… Nháº­p báº£ng Ä‘Ã£ chá»n", use_container_width=True):
                df_new = tables[chosen_table]
                table_hash = _df_sha256(df_new)

                if table_hash in st.session_state["hash_to_key"]:
                    existed = st.session_state["hash_to_key"][table_hash]
                    st.session_state["active_name"] = existed
                    st.info(f"Báº£ng nÃ y Ä‘Ã£ nháº­p trÆ°á»›c Ä‘Ã³ â†’ chuyá»ƒn sang: {existed}")
                else:
                    base = _safe_name(Path(fname).stem)
                    sh = _safe_name(chosen_table)
                    key_base = f"{base}__{sh}"
                    key = key_base
                    i = 2
                    while key in st.session_state["datasets"]:
                        key = f"{key_base}_{i}"
                        i += 1

                    hashes = [table_hash]
                    if pending_file_hash:
                        hashes.append(pending_file_hash)
                    _register_dataset(key, df_new, hashes=hashes)
                    st.success(f"ÄÃ£ nháº­p: {key} (rows={df_new.shape[0]}, cols={df_new.shape[1]})")

                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

        with c2:
            if st.button("âŒ Huá»·", use_container_width=True):
                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.rerun()

with col_right:
    st.subheader("ğŸ“ Danh sÃ¡ch file Ä‘Ã£ upload")
    names = list(st.session_state["datasets"].keys())
    if len(names) == 0:
        st.info("ChÆ°a cÃ³ file nÃ o. HÃ£y upload á»Ÿ cá»™t giá»¯a.")
    else:
        active = st.session_state["active_name"] or names[0]
        chosen = st.radio(
            "Click Ä‘á»ƒ chá»n file",
            options=names,
            index=names.index(active) if active in names else 0,
            label_visibility="collapsed",
        )
        st.session_state["active_name"] = chosen

        c1, c2 = st.columns([1, 1])
        with c1:
            if st.button("ğŸ—‘ï¸ XÃ³a file Ä‘ang chá»n", use_container_width=True):
                _delete_dataset(chosen)
                remaining = list(st.session_state["datasets"].keys())
                st.session_state["active_name"] = remaining[0] if remaining else None
                st.rerun()
        with c2:
            if st.button("ğŸ§¹ XÃ³a táº¥t cáº£", use_container_width=True):
                st.session_state["datasets"] = {}
                st.session_state["active_name"] = None
                st.session_state["pending_tables"] = None
                st.session_state["pending_fname"] = None
                st.session_state["pending_file_hash"] = None
                st.session_state["hash_to_key"] = {}
                st.session_state["key_to_hashes"] = {}
                st.session_state["last_upload_hash"] = None
                st.rerun()

with col_left:
    st.subheader("ğŸ“Œ Tá»•ng quan dá»¯ liá»‡u")
    if st.session_state["active_name"] is None:
        st.info("Upload vÃ  chá»n 1 file Ä‘á»ƒ xem tá»•ng quan.")
    else:
        df = st.session_state["datasets"][st.session_state["active_name"]]
        summ = overall_summary(df)
        st.write(
            f"- **Sá»‘ dÃ²ng:** {summ['Sá»‘ dÃ²ng']}\n"
            f"- **Sá»‘ biáº¿n:** {summ['Sá»‘ biáº¿n']}\n"
            f"- **Biáº¿n Ä‘á»‹nh lÆ°á»£ng:** {summ['Biáº¿n Ä‘á»‹nh lÆ°á»£ng']}\n"
            f"- **Biáº¿n phÃ¢n loáº¡i:** {summ['Biáº¿n phÃ¢n loáº¡i']}\n"
            f"- **Ã” thiáº¿u (NA):** {summ['Ã” thiáº¿u (NA)']}"
        )

st.divider()


# =========================
# Main area
# =========================
if st.session_state["active_name"] is None:
    st.stop()

df = st.session_state["datasets"][st.session_state["active_name"]]
cols = df.columns.tolist()

main_left, main_right = st.columns([2.4, 1.6], gap="large")

with main_left:
    st.subheader("ğŸ§¾ Liá»‡t kÃª biáº¿n & Ä‘áº·c tÃ­nh")
    var_rows = [summarize_variable(df, c) for c in cols]
    var_df = pd.DataFrame(var_rows)

    q = st.text_input("TÃ¬m nhanh tÃªn biáº¿n", value="")
    if q.strip():
        mask = var_df["TÃªn biáº¿n"].str.contains(q.strip(), case=False, na=False)
        var_df = var_df.loc[mask].copy()

    st.dataframe(var_df, use_container_width=True, height=420)

with main_right:
    st.subheader("ğŸ¯ Chá»n biáº¿n phÃ¢n tÃ­ch")
    y = st.selectbox("Chá»n biáº¿n phá»¥ thuá»™c (Y)", options=cols, index=0)
    x = st.multiselect("Chá»n biáº¿n Ä‘á»™c láº­p (cÃ³ thá»ƒ chá»n nhiá»u biáº¿n)", options=[c for c in cols if c != y])

    st.markdown("**Ã‰p kiá»ƒu náº¿u cáº§n** (Ä‘á»ƒ trÃ¡nh nháº­n sai 0/1 thÃ nh sá»‘ Ä‘o):")
    force_opts = ["Tá»± Ä‘á»™ng", "Äá»‹nh lÆ°á»£ng (numeric)", "PhÃ¢n loáº¡i (categorical)"]
    y_force = st.selectbox("Kiá»ƒu Y", options=force_opts, index=0)

    x_force = "Tá»± Ä‘á»™ng"
    if len(x) == 1:
        x_force = st.selectbox("Kiá»ƒu X (chá»‰ Ã¡p dá»¥ng khi chá»n 1 biáº¿n X)", options=force_opts, index=0)

    # logistic event if binary categorical Y
    y_is_cat = var_kind(df[y], y_force) == "cat"
    y_event = None
    if y_is_cat:
        levels = sorted(df[y].dropna().astype(str).unique().tolist())
        if len(levels) == 2:
            y_event = st.selectbox("Chá»n má»©c coi lÃ  'Sá»± kiá»‡n' (Y=1) cho logistic", options=levels, index=1)

    if len(x) == 0:
        st.info("Chá»n Ã­t nháº¥t 1 biáº¿n Ä‘á»™c láº­p Ä‘á»ƒ pháº§n má»m gá»£i Ã½ vÃ  cháº¡y káº¿t quáº£.")
        st.stop()

    # Decide mode
    if len(x) == 1:
        suggestion, explanation, test_kind = suggest_single_x_test(df, y, x[0], y_forced=y_force, x_forced=x_force)
        analysis_mode = "test"
    else:
        tmp_for_suggest = df.copy()
        if y_force == "Äá»‹nh lÆ°á»£ng (numeric)":
            tmp_for_suggest[y] = coerce_numeric(tmp_for_suggest[y])
        elif y_force == "PhÃ¢n loáº¡i (categorical)":
            tmp_for_suggest[y] = tmp_for_suggest[y].astype("string")

        suggestion, explanation = suggest_model(tmp_for_suggest, y, x)
        test_kind = "none"
        analysis_mode = "model"

    st.divider()
    st.subheader("âœ… PhÃ©p kiá»ƒm / mÃ´ hÃ¬nh gá»£i Ã½")
    st.write("**Cháº¿ Ä‘á»™:** " + ("Kiá»ƒm Ä‘á»‹nh (1 biáº¿n Ä‘á»™c láº­p)" if analysis_mode == "test" else "MÃ´ hÃ¬nh há»“i quy (nhiá»u biáº¿n Ä‘á»™c láº­p)"))
    st.write(f"**Gá»£i Ã½:** {suggestion}")

    with st.expander("Giáº£i thÃ­ch táº¡i sao chá»n phÆ°Æ¡ng phÃ¡p nÃ y"):
        st.write(explanation)
        st.write(
            "- Náº¿u chá»‰ chá»n **1 biáº¿n Ä‘á»™c láº­p**, app kiá»ƒm tra **giáº£ Ä‘á»‹nh** (phÃ¢n phá»‘i chuáº©n, Ä‘á»“ng nháº¥t phÆ°Æ¡ng sai) Ä‘á»ƒ chá»n t-test/ANOVA hay Mannâ€“Whitney/Kruskal.\n"
            "- Náº¿u chá»n **nhiá»u biáº¿n Ä‘á»™c láº­p**, app Æ°u tiÃªn **mÃ´ hÃ¬nh há»“i quy** Ä‘á»ƒ **hiá»‡u chá»‰nh (adjust)** Ä‘á»“ng thá»i.\n"
            "- Dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ cháº¡y sáº½ **loáº¡i dÃ²ng thiáº¿u (NA)** theo cÃ¡c biáº¿n Ä‘Ã£ chá»n."
        )

    model_formula = None
    model_data_used = None
    model_kind = None

    if analysis_mode == "model":
        df_model = df.copy()
        if y_force == "Äá»‹nh lÆ°á»£ng (numeric)":
            df_model[y] = coerce_numeric(df_model[y])
        elif y_force == "PhÃ¢n loáº¡i (categorical)":
            df_model[y] = df_model[y].astype("string")

        model_formula, model_data_used, model_kind = build_formula(df_model, y, x, y_binary_event=y_event)

        with st.expander("Xem cÃ´ng thá»©c mÃ´ hÃ¬nh (formula)"):
            st.code(model_formula)
            st.caption(f"Sá»‘ dÃ²ng dÃ¹ng cho mÃ´ hÃ¬nh (sau khi loáº¡i NA): {model_data_used.shape[0]}")

    run = st.button("â–¶ï¸ Cháº¡y kiá»ƒm Ä‘á»‹nh / mÃ´ hÃ¬nh", type="primary", use_container_width=True)


# =========================
# Results area
# =========================
st.divider()
res_left, res_right = st.columns([1.35, 1.0], gap="large")

with res_left:
    st.subheader("ğŸ“Œ Káº¿t quáº£")
    if not run:
        st.info("Nháº¥n **Cháº¡y kiá»ƒm Ä‘á»‹nh / mÃ´ hÃ¬nh** Ä‘á»ƒ xem káº¿t quáº£.")
    else:
        try:
            if analysis_mode == "test":
                x1 = x[0]
                result_df, interp = run_single_x_test(df, y, x1, test_kind=test_kind)
                st.dataframe(result_df, use_container_width=True)
                st.write("ğŸ” **Gá»£i Ã½ diá»…n giáº£i:**")
                st.write(interp)
            else:
                fit, note = run_model(model_formula, model_data_used, model_kind)
                kind = model_kind.split("||", 1)[0]
                st.caption(note)

                if kind == "ols":
                    out = ols_table(fit)
                    st.dataframe(out, use_container_width=True)
                    st.write(
                        "ğŸ” **Gá»£i Ã½ diá»…n giáº£i:**\n"
                        "- Há»‡ sá»‘ > 0: Y tÄƒng khi X tÄƒng (giá»¯ cÃ¡c biáº¿n khÃ¡c khÃ´ng Ä‘á»•i).\n"
                        "- p-value < 0.05: liÃªn quan cÃ³ Ã½ nghÄ©a thá»‘ng kÃª (tuá»³ ngÆ°á»¡ng nghiÃªn cá»©u).\n"
                        "- CI 95% khÃ´ng chá»©a 0: thÆ°á»ng tÆ°Æ¡ng á»©ng cÃ³ Ã½ nghÄ©a."
                    )
                elif kind == "logit":
                    out = logit_or_table(fit)
                    st.dataframe(out, use_container_width=True)
                    st.write(
                        "ğŸ” **Gá»£i Ã½ diá»…n giáº£i:**\n"
                        "- OR > 1: tÄƒng odds xáº£y ra sá»± kiá»‡n (Y=1).\n"
                        "- OR < 1: giáº£m odds.\n"
                        "- p-value < 0.05 vÃ  CI 95% khÃ´ng chá»©a 1: thÆ°á»ng cÃ³ Ã½ nghÄ©a."
                    )
                else:
                    st.write(fit.summary())
                    st.write(
                        "ğŸ” **Gá»£i Ã½ diá»…n giáº£i (Multinomial):**\n"
                        "- Há»‡ sá»‘ Ä‘Æ°á»£c Æ°á»›c lÆ°á»£ng theo **nhÃ³m tham chiáº¿u**.\n"
                        "- Náº¿u muá»‘n RRR = exp(coef) theo tá»«ng nhÃ³m, cÃ³ thá»ƒ bá»• sung báº£ng riÃªng."
                    )
        except Exception as e:
            st.error(f"Lá»—i khi cháº¡y: {e}")
            st.info("Máº¹o: kiá»ƒm tra dá»¯ liá»‡u (NA), biáº¿n phÃ¢n loáº¡i quÃ¡ nhiá»u má»©c, hoáº·c cá»¡ máº«u quÃ¡ nhá».")

with res_right:
    st.subheader("ğŸ“ˆ Biá»ƒu Ä‘á»“ minh hoáº¡")
    if not run:
        st.info("Cháº¡y xong app sáº½ váº½ biá»ƒu Ä‘á»“ minh hoáº¡.")
    else:
        try:
            if analysis_mode == "test":
                x1 = x[0]
                yk = var_kind(df[y], y_force)
                xk = var_kind(df[x1], x_force)

                tmp = df[[y, x1]].dropna().copy()
                if tmp.shape[0] < 3:
                    st.info("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“.")
                else:
                    if yk == "num" and xk == "cat":
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=x1, y=y, points="all", title=f"{y} theo nhÃ³m {x1}")
                        st.plotly_chart(fig, use_container_width=True)

                    elif yk == "cat" and xk == "num":
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.box(tmp, x=y, y=x1, points="all", title=f"{x1} theo nhÃ³m {y}")
                        st.plotly_chart(fig, use_container_width=True)

                    elif yk == "cat" and xk == "cat":
                        tab = pd.crosstab(tmp[y].astype(str), tmp[x1].astype(str))
                        tab2 = tab.div(tab.sum(axis=1), axis=0).reset_index().melt(
                            id_vars=[y], var_name=x1, value_name="Tá»· lá»‡"
                        )
                        fig = px.bar(tab2, x=y, y="Tá»· lá»‡", color=x1, barmode="stack", title=f"Tá»· lá»‡ {x1} theo {y}")
                        st.plotly_chart(fig, use_container_width=True)

                    else:
                        tmp[y] = coerce_numeric(tmp[y])
                        tmp[x1] = coerce_numeric(tmp[x1])
                        tmp = tmp.dropna()
                        fig = px.scatter(tmp, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1} (scatter + trendline)")
                        st.plotly_chart(fig, use_container_width=True)

            else:
                kind = model_kind.split("||", 1)[0]
                fit, _ = run_model(model_formula, model_data_used, model_kind)

                if kind == "ols":
                    x1 = x[0]
                    if (not is_categorical(model_data_used[x1])) and (not is_categorical(model_data_used[y])):
                        fig = px.scatter(model_data_used, x=x1, y=y, trendline="ols", title=f"{y} ~ {x1} (kÃ¨m trendline)")
                    else:
                        if is_categorical(model_data_used[x1]):
                            fig = px.box(model_data_used, x=x1, y=y, points="all", title=f"{y} theo nhÃ³m {x1}")
                        else:
                            fig = px.scatter(model_data_used, x=x1, y=y, title=f"{y} theo {x1}")
                    st.plotly_chart(fig, use_container_width=True)

                    pred = fit.fittedvalues
                    tmp_plot = pd.DataFrame({"Thá»±c táº¿": model_data_used[y], "Dá»± Ä‘oÃ¡n": pred})
                    fig2 = px.scatter(tmp_plot, x="Thá»±c táº¿", y="Dá»± Ä‘oÃ¡n", title="Dá»± Ä‘oÃ¡n vs Thá»±c táº¿")
                    st.plotly_chart(fig2, use_container_width=True)

                elif kind == "logit":
                    p = fit.predict()
                    fig = px.histogram(p, nbins=25, title="PhÃ¢n bá»‘ xÃ¡c suáº¥t dá»± Ä‘oÃ¡n (p)")
                    st.plotly_chart(fig, use_container_width=True)

                    y_true = model_data_used["_y01_"].astype(int)
                    y_pred = (p >= 0.5).astype(int)
                    tp = int(((y_true == 1) & (y_pred == 1)).sum())
                    tn = int(((y_true == 0) & (y_pred == 0)).sum())
                    fp = int(((y_true == 0) & (y_pred == 1)).sum())
                    fn = int(((y_true == 1) & (y_pred == 0)).sum())
                    st.write("**Báº£ng nháº§m láº«n (ngÆ°á»¡ng 0.5):**")
                    st.table(
                        pd.DataFrame(
                            {"Dá»± Ä‘oÃ¡n 0": [tn, fn], "Dá»± Ä‘oÃ¡n 1": [fp, tp]},
                            index=["Thá»±c táº¿ 0", "Thá»±c táº¿ 1"],
                        )
                    )

                else:
                    st.info("Multinomial: biá»ƒu Ä‘á»“ minh hoáº¡ cÃ³ thá»ƒ bá»• sung (RRR, xÃ¡c suáº¥t dá»± Ä‘oÃ¡n).")

        except Exception as e:
            st.warning(f"KhÃ´ng váº½ Ä‘Æ°á»£c biá»ƒu Ä‘á»“: {e}")

st.divider()
st.caption(
    "âš ï¸ LÆ°u Ã½: CÃ´ng cá»¥ há»— trá»£ gá»£i Ã½ vÃ  cháº¡y kiá»ƒm Ä‘á»‹nh/mÃ´ hÃ¬nh cÆ¡ báº£n. "
    "NgÆ°á»i dÃ¹ng cáº§n kiá»ƒm tra giáº£ Ä‘á»‹nh, thiáº¿t káº¿ nghiÃªn cá»©u vÃ  cÃ¡ch mÃ£ hoÃ¡ biáº¿n Ä‘á»ƒ diá»…n giáº£i Ä‘Ãºng."
)
